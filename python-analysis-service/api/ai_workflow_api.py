from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
from sqlalchemy.orm import Session
import asyncio
import uuid
from datetime import datetime
import json
import logging

# åˆå§‹åŒ–logger
logger = logging.getLogger(__name__)

from services.qwen_analyzer import QwenAnalyzer
from services.stock_recommender import StockRecommender
from services.smart_stock_service import SmartStockService
from services.database_service import DatabaseService
from models.database import get_db
from models.workflow_models import (
    WorkflowInstance, WorkflowStep, WorkflowMessage, WorkflowResource,
    WorkflowStatus, StepStatus, StepCategory, ResourceTypeEnum, 
    MessageType, WorkflowResourceType
)
from utils.helpers import clean_text
from services.workflow_persistence_service import WorkflowPersistenceService

router = APIRouter(prefix="/api/v1", tags=["AI Workflow"])

def determine_resource_type_from_content(step_content: str, context: Dict[str, Any] = None) -> tuple[str, list]:
    """
    æ ¹æ®æ­¥éª¤å†…å®¹å’Œä¸Šä¸‹æ–‡æ™ºèƒ½åˆ¤æ–­resourceTypeå’Œresults
    ç°åœ¨æ‰€æœ‰æ­¥éª¤éƒ½æ˜¯"æ­£åœ¨æ€è€ƒ..."ï¼Œæ‰€ä»¥æ ¹æ®æ­¥éª¤é¡ºåºå’Œç”¨æˆ·æ¶ˆæ¯å†…å®¹æ¥åˆ¤æ–­
    """
    # è·å–æ­¥éª¤åºå·å’Œç”¨æˆ·æ¶ˆæ¯
    step_number = context.get('step_number', 1) if context else 1
    user_message = context.get('user_message', '') if context else ''
    user_message_lower = user_message.lower()
    
    results = []
    
    # æ ¹æ®æ­¥éª¤é¡ºåºå’Œç”¨æˆ·æ¶ˆæ¯å†…å®¹æ™ºèƒ½åˆ¤æ–­
    if step_number == 1:
        # ç¬¬ä¸€æ­¥ï¼šç†è§£é—®é¢˜ï¼Œé€šç”¨æ“ä½œ
        resource_type = 'general'
        results = ["ç†è§£ç”¨æˆ·éœ€æ±‚", "åˆ†æé—®é¢˜ç±»å‹", "ç¡®å®šåˆ†ææ–¹å‘"]
    elif step_number == 2:
        # ç¬¬äºŒæ­¥ï¼šæ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­æ˜¯å¦éœ€è¦æ•°æ®æŸ¥è¯¢
        if any(keyword in user_message_lower for keyword in [
            'è‚¡ç¥¨', 'ä»£ç ', 'æ•°æ®', 'è¡Œæƒ…', 'ä»·æ ¼', 'è´¢åŠ¡', 'åˆ†æ', '000', '300', '600'
        ]):
            resource_type = 'database'
            results = ["æŸ¥è¯¢è‚¡ç¥¨åŸºç¡€ä¿¡æ¯", "è·å–å¸‚åœºè¡Œæƒ…æ•°æ®", "æ£€ç´¢å†å²æ•°æ®"]
        else:
            resource_type = 'browser'
            results = ["æœç´¢ç›¸å…³èµ„æ–™", "è·å–æœ€æ–°ä¿¡æ¯", "æ•´ç†ç½‘ç»œèµ„æº"]
    elif step_number == 3:
        # ç¬¬ä¸‰æ­¥ï¼šAIåˆ†æå¤„ç†
        resource_type = 'api'
        results = ["è°ƒç”¨AIåˆ†æå¼•æ“", "è·å–æ™ºèƒ½æ¨è", "å¤„ç†åˆ†æç»“æœ"]
    elif step_number == 4:
        # ç¬¬å››æ­¥ï¼šæ•´ç†ç»“æœ
        resource_type = 'general'
        results = ["æ•´åˆåˆ†ææ•°æ®", "ç”Ÿæˆå›¾è¡¨", "ç»„ç»‡åˆ†æå†…å®¹"]
    else:
        # æœ€åæ­¥éª¤ï¼šç”ŸæˆæŠ¥å‘Š
        resource_type = 'general'
        results = ["åˆ¶å®šæŠ•èµ„å»ºè®®", "è¯„ä¼°é£é™©", "ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"]
    
    return resource_type, results

def determine_step_category_from_message(message: str) -> str:
    """
    æ ¹æ®ç”¨æˆ·æ¶ˆæ¯æ™ºèƒ½åˆ¤æ–­æ­¥éª¤ç±»åˆ«
    """
    message_lower = message.lower()
    
    if any(keyword in message_lower for keyword in [
        'åˆ†æ', 'ç ”ç©¶', 'æ•°æ®', 'æŒ‡æ ‡', 'æŠ€æœ¯é¢', 'åŸºæœ¬é¢'
    ]):
        return 'analysis'
    elif any(keyword in message_lower for keyword in [
        'ç­–ç•¥', 'å»ºè®®', 'é…ç½®', 'æŠ•èµ„', 'ç»„åˆ', 'æ–¹æ¡ˆ'
    ]):
        return 'strategy'
    else:
        return 'general'

def generate_task_title_and_description(message: str) -> tuple[str, str]:
    """
    æ ¹æ®ç”¨æˆ·æ¶ˆæ¯æ™ºèƒ½ç”Ÿæˆä»»åŠ¡æ ‡é¢˜å’Œæè¿°
    """
    message_lower = message.lower()
    
    # æå–å…³é”®ä¿¡æ¯
    symbols = []
    sectors = []
    strategies = []
    
    # æå–è‚¡ç¥¨ä»£ç 
    import re
    stock_pattern = r'[0-9]{6}|[A-Z]{2,5}'
    potential_symbols = re.findall(stock_pattern, message.upper())
    symbols.extend(potential_symbols[:3])  # æœ€å¤šå–3ä¸ª
    
    # è¯†åˆ«è¡Œä¸šæ¿å—
    sector_keywords = {
        'ç§‘æŠ€': ['ç§‘æŠ€', 'æŠ€æœ¯', 'äº’è”ç½‘', 'è½¯ä»¶', 'èŠ¯ç‰‡', 'AI', 'äººå·¥æ™ºèƒ½'],
        'åŒ»è¯': ['åŒ»è¯', 'åŒ»ç–—', 'ç”Ÿç‰©', 'åˆ¶è¯', 'å¥åº·'],
        'é‡‘è': ['é“¶è¡Œ', 'ä¿é™©', 'è¯åˆ¸', 'é‡‘è', 'åˆ¸å•†'],
        'æ–°èƒ½æº': ['æ–°èƒ½æº', 'ç”µåŠ¨è½¦', 'å…‰ä¼', 'é£ç”µ', 'é”‚ç”µæ± ', 'å……ç”µæ¡©'],
        'æ¶ˆè´¹': ['æ¶ˆè´¹', 'é›¶å”®', 'é£Ÿå“', 'é¥®æ–™', 'ç™½é…’', 'å®¶ç”µ'],
        'æˆ¿åœ°äº§': ['æˆ¿åœ°äº§', 'åœ°äº§', 'æˆ¿äº§', 'ç‰©ä¸š'],
        'åˆ¶é€ ä¸š': ['åˆ¶é€ ', 'æœºæ¢°', 'é’¢é“', 'åŒ–å·¥', 'å»ºæ']
    }
    
    for sector, keywords in sector_keywords.items():
        if any(keyword in message_lower for keyword in keywords):
            sectors.append(sector)
    
    # è¯†åˆ«æŠ•èµ„ç­–ç•¥ç±»å‹
    if any(keyword in message_lower for keyword in ['ä»·å€¼', 'ä½ä¼°å€¼', 'åˆ†çº¢', 'è“ç­¹']):
        strategies.append('ä»·å€¼æŠ•èµ„')
    if any(keyword in message_lower for keyword in ['æˆé•¿', 'é«˜æˆé•¿', 'å¢é•¿']):
        strategies.append('æˆé•¿æŠ•èµ„')
    if any(keyword in message_lower for keyword in ['é‡åŒ–', 'æŠ€æœ¯åˆ†æ', 'æŒ‡æ ‡']):
        strategies.append('é‡åŒ–åˆ†æ')
    if any(keyword in message_lower for keyword in ['çŸ­çº¿', 'æ³¢æ®µ']):
        strategies.append('çŸ­æœŸäº¤æ˜“')
    if any(keyword in message_lower for keyword in ['é•¿æœŸ', 'é•¿çº¿']):
        strategies.append('é•¿æœŸæŠ•èµ„')
    
    # ç”Ÿæˆæ ‡é¢˜
    title_parts = []
    
    if symbols:
        title_parts.append(f"{symbols[0]}ç­‰è‚¡ç¥¨")
    elif sectors:
        title_parts.append(f"{sectors[0]}æ¿å—")
    
    if any(keyword in message_lower for keyword in ['åˆ†æ', 'ç ”ç©¶', 'æ•°æ®', 'æŒ‡æ ‡']):
        if title_parts:
            title = f"{title_parts[0]}æ·±åº¦åˆ†æ"
        else:
            title = "å¸‚åœºåˆ†æä»»åŠ¡"
    elif any(keyword in message_lower for keyword in ['ç­–ç•¥', 'å»ºè®®', 'é…ç½®', 'æŠ•èµ„', 'ç»„åˆ']):
        if strategies:
            title = f"{strategies[0]}ç­–ç•¥åˆ¶å®š"
        elif title_parts:
            title = f"{title_parts[0]}æŠ•èµ„ç­–ç•¥"
        else:
            title = "æŠ•èµ„ç­–ç•¥åˆ¶å®š"
    elif any(keyword in message_lower for keyword in ['æ¨è', 'é€‰æ‹©', 'ç­›é€‰']):
        if sectors:
            title = f"{sectors[0]}è‚¡ç¥¨æ¨è"
        else:
            title = "è‚¡ç¥¨æ¨èä»»åŠ¡"
    elif any(keyword in message_lower for keyword in ['é£é™©', 'è¯„ä¼°']):
        title = "é£é™©è¯„ä¼°åˆ†æ"
    elif any(keyword in message_lower for keyword in ['é¢„æµ‹', 'è¶‹åŠ¿', 'èµ°åŠ¿']):
        if title_parts:
            title = f"{title_parts[0]}è¶‹åŠ¿é¢„æµ‹"
        else:
            title = "å¸‚åœºè¶‹åŠ¿é¢„æµ‹"
    else:
        title = "AIæŠ•èµ„å’¨è¯¢"
    
    # ç”Ÿæˆæè¿°ï¼ˆå–ç”¨æˆ·æ¶ˆæ¯çš„å…³é”®éƒ¨åˆ†ï¼Œæœ€å¤š50å­—ç¬¦ï¼‰
    description = message.strip()
    if len(description) > 50:
        description = description[:47] + "..."
    
    # å¦‚æœæ¶ˆæ¯å¤ªçŸ­ï¼Œç”Ÿæˆæ›´è¯¦ç»†çš„æè¿°
    if len(description) < 10:
        if symbols:
            description = f"åˆ†æ{', '.join(symbols[:2])}ç­‰è‚¡ç¥¨çš„æŠ•èµ„ä»·å€¼"
        elif sectors:
            description = f"ç ”ç©¶{', '.join(sectors[:2])}ç­‰è¡Œä¸šçš„æŠ•èµ„æœºä¼š"
        elif strategies:
            description = f"åˆ¶å®š{strategies[0]}ç›¸å…³çš„æŠ•èµ„æ–¹æ¡ˆ"
        else:
            description = "åŸºäºAIçš„æ™ºèƒ½æŠ•èµ„åˆ†æä¸å»ºè®®"
    
    return title, description

# ä¸ºæ­¥éª¤è¡¥å……å¯ç‚¹å‡»URL
def enrich_steps_with_urls(steps: List[Dict[str, Any]], message: str) -> List[Dict[str, Any]]:
    try:
        from urllib.parse import quote
        q = quote(message.strip())
        default_urls = [
            f"https://so.eastmoney.com/web/s?keyword={q}",
            f"https://xueqiu.com/k?q={q}",
            f"https://finance.sina.com.cn/search?search={q}"
        ]
        for step in steps or []:
            urls = step.get('urls') or []
            if not urls:
                rt = (step.get('resourceType') or 'general').lower()
                if rt == 'database':
                    step['urls'] = [
                        f"https://so.eastmoney.com/web/s?keyword={q}",
                        "https://data.eastmoney.com/bbsj/",
                        "https://quote.eastmoney.com/"
                    ]
                elif rt == 'api':
                    step['urls'] = [
                        "https://dashscope.console.aliyun.com/overview",
                        "https://help.aliyun.com/zh/model-studio/getting-started/quick-start",
                        default_urls[0]
                    ]
                else:  # browser/general/å…¶ä»–
                    step['urls'] = default_urls
        return steps
    except Exception:
        return steps

# è¯·æ±‚æ¨¡å‹
class WorkflowStartRequest(BaseModel):
    workflow_id: str
    query: str
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class WorkflowDefinitionRunRequest(BaseModel):
    execution_id: str
    workflow_definition: Dict[str, Any]
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class WorkflowValidationRequest(BaseModel):
    workflow_definition: Dict[str, Any]

class ChatMessageRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class StockAnalysisRequest(BaseModel):
    symbol: str

class StrategyGenerationRequest(BaseModel):
    riskTolerance: str = "medium"
    investmentGoal: str
    timeHorizon: str = "medium"
    sectors: Optional[List[str]] = None
    excludeStocks: Optional[List[str]] = None
    userId: Optional[str] = None

# å“åº”æ¨¡å‹
class AgentStatus(BaseModel):
    id: str
    name: str
    status: str = "idle"  # idle, running, completed, error
    progress: int = 0
    message: Optional[str] = None
    result: Optional[Dict[str, Any]] = None
    startTime: Optional[str] = None
    endTime: Optional[str] = None

class WorkflowResponse(BaseModel):
    workflowId: str
    status: str
    message: str
    agents: Optional[List[AgentStatus]] = None
    results: Optional[Dict[str, Any]] = None

# å…¨å±€å˜é‡å­˜å‚¨å·¥ä½œæµçŠ¶æ€
workflow_storage: Dict[str, Dict[str, Any]] = {}
conversation_storage: Dict[str, List[Dict[str, Any]]] = {}
# æ–°å¢ï¼šå·¥ä½œæµå®šä¹‰æ‰§è¡Œå­˜å‚¨
workflow_execution_storage: Dict[str, Dict[str, Any]] = {}

# åˆå§‹åŒ–æœåŠ¡
qwen_analyzer = QwenAnalyzer()
stock_recommender = StockRecommender()
smart_stock_service = SmartStockService()
db_service = DatabaseService()

@router.post("/workflow/start")
async def start_workflow(request: WorkflowStartRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨AIå·¥ä½œæµ"""
    try:
        workflow_id = request.workflow_id
        
        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        workflow_storage[workflow_id] = {
            "id": workflow_id,
            "status": "running",
            "query": request.query,
            "user_id": request.user_id,
            "context": request.context or {},
            "start_time": datetime.now().isoformat(),
            "agents": get_default_agents(),
            "results": {}
        }
        
        # åœ¨åå°æ‰§è¡Œå·¥ä½œæµ
        background_tasks.add_task(execute_workflow, workflow_id, request.query, request.context)
        
        return {
            "success": True,
            "data": {
                "workflowId": workflow_id,
                "status": "started",
                "message": "AIå·¥ä½œæµå·²å¯åŠ¨",
                "agents": get_default_agents()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å·¥ä½œæµå¤±è´¥: {str(e)}")

@router.get("/workflow/status/{workflow_id}")
async def get_workflow_status(workflow_id: str):
    """è·å–å·¥ä½œæµçŠ¶æ€"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        
        return {
            "success": True,
            "data": {
                "workflowId": workflow_id,
                "status": workflow["status"],
                "progress": calculate_progress(workflow["agents"]),
                "agents": workflow["agents"],
                "results": workflow.get("results", {}),
                "message": workflow.get("message", "")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/workflow/stop/{workflow_id}")
async def stop_workflow(workflow_id: str):
    """åœæ­¢å·¥ä½œæµ"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        workflow["status"] = "stopped"
        workflow["end_time"] = datetime.now().isoformat()
        
        return {
            "success": True,
            "data": {"message": "å·¥ä½œæµå·²åœæ­¢"}
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åœæ­¢å·¥ä½œæµå¤±è´¥: {str(e)}")

@router.get("/workflow/results/{workflow_id}")
async def get_workflow_results(workflow_id: str):
    """è·å–å·¥ä½œæµç»“æœ"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        
        return {
            "success": True,
            "data": workflow.get("results", {})
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµç»“æœå¤±è´¥: {str(e)}")

@router.post("/chat/analyze")
async def analyze_chat_message(request: ChatMessageRequest):
    """åˆ†æèŠå¤©æ¶ˆæ¯å¹¶ç”ŸæˆAIå›å¤ï¼ˆä¸“é—¨ç”¨äºAIåˆ†æï¼‰"""
    try:
        # ä½¿ç”¨ç°æœ‰çš„åˆ†ææœåŠ¡è¿›è¡Œæ™ºèƒ½åˆ†æ
        analysis_result = await perform_intelligent_analysis(request.message, request.context)
        
        return {
            "success": True,
            "data": {
                "response": analysis_result["response"],
                "analysis": analysis_result.get("analysis"),
                "recommendations": analysis_result.get("recommendations", [])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")

@router.get("/chat/stream")
async def stream_chat_message(
    message: str,
    conversation_id: str = None,
    context: str = "{}",
    workflow_id: str = None,  # æ–°å¢ï¼šç›´æ¥æ¥æ”¶å·¥ä½œæµID
    db: Session = Depends(get_db)
):
    """æµå¼å¯¹è¯æ¥å£ - åˆ†æ®µå¼è¾“å‡ºAIå›å¤"""
    try:
        # è§£æå‚æ•°
        conversation_id = conversation_id or f"conv_{uuid.uuid4()}"
        try:
            context_dict = json.loads(context) if context else {}
        except:
            context_dict = {}

        # åˆå§‹åŒ–å·¥ä½œæµæŒä¹…åŒ–æœåŠ¡
        persistence_service = WorkflowPersistenceService(db)

        # åˆå§‹åŒ–å¯¹è¯å†å²
        if conversation_id not in conversation_storage:
            conversation_storage[conversation_id] = []

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        user_message = {
            "id": f"msg_{uuid.uuid4()}",
            "type": "user",
            "content": message,
            "timestamp": datetime.now().isoformat()
        }
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        if workflow_id:
            persistence_service.save_message(workflow_id, {
                "messageId": user_message["id"],
                "type": "user", 
                "content": message,
                "status": "sent"
            })

        # åˆ›å»ºAIæ¶ˆæ¯ID
        ai_message_id = f"msg_{uuid.uuid4()}"

        async def generate_streaming_response():
            """ç”Ÿæˆæµå¼å“åº”"""
            try:
                # 1. å‘é€å¼€å§‹ä¿¡å· - ç«‹å³å‘é€ï¼Œç¡®ä¿å‰ç«¯èƒ½æ”¶åˆ°
                yield f"data: {json.dumps({'type': 'start', 'messageId': ai_message_id})}\n\n"
                
                # çŸ­æš‚å»¶è¿Ÿç¡®ä¿startäº‹ä»¶è¢«å¤„ç†
                await asyncio.sleep(0.1)
                
                # ä¿å­˜AIæ¶ˆæ¯å¼€å§‹åˆ°æ•°æ®åº“
                if workflow_id:
                    persistence_service.save_message(workflow_id, {
                        "messageId": ai_message_id,
                        "type": "assistant",
                        "content": "æ­£åœ¨æ€è€ƒä¸­...",
                        "status": "started"
                    })
                
                # 2. åŸºäºæ¶ˆæ¯å†…å®¹è·¯ç”±åˆ°ä¸åŒçš„å¤„ç†é€»è¾‘
                message_lower = message.lower()
                context = context_dict
                
                # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                try:
                    print(f"ğŸš€ å¼€å§‹è·¯ç”±æ¶ˆæ¯å¤„ç†, message_loweråŒ…å«å…³é”®è¯æ£€æŸ¥:")
                    print(f"   æ˜¯å¦åŒ…å«åˆ†æå…³é”®è¯: {any(keyword in message_lower for keyword in ['åˆ†æ', 'è‚¡ç¥¨', 'æŠ•èµ„', 'å¸‚åœº'])}")
                    print(f"   æ˜¯å¦åŒ…å«ç­–ç•¥å…³é”®è¯: {any(keyword in message_lower for keyword in ['ç­–ç•¥', 'å»ºè®®', 'æ¨è'])}")
                    
                    if any(keyword in message_lower for keyword in ['åˆ†æ', 'è‚¡ç¥¨', 'æŠ•èµ„', 'å¸‚åœº']):
                        # è‚¡ç¥¨åˆ†æç›¸å…³çš„åˆ†æ®µå“åº”
                        print(f"ğŸ“Š è·¯ç”±åˆ°åˆ†ææµ, workflow_id: {workflow_id}")
                        async for chunk in generate_analysis_stream(message, context, workflow_id, persistence_service, ai_message_id):
                            yield chunk
                    elif any(keyword in message_lower for keyword in ['ç­–ç•¥', 'å»ºè®®', 'æ¨è']):
                        # ç­–ç•¥å»ºè®®ç›¸å…³çš„åˆ†æ®µå“åº”
                        print(f"ğŸ“ˆ è·¯ç”±åˆ°ç­–ç•¥æµ, workflow_id: {workflow_id}")
                        async for chunk in generate_strategy_stream(message, context, workflow_id, persistence_service, ai_message_id):
                            yield chunk
                    else:
                        # é€šç”¨å¯¹è¯çš„åˆ†æ®µå“åº”
                        print(f"ğŸ’¬ è·¯ç”±åˆ°é€šç”¨æµ, workflow_id: {workflow_id}")
                        async for chunk in generate_general_stream(message, context, workflow_id, persistence_service, ai_message_id):
                            yield chunk
                except asyncio.TimeoutError:
                    # è¶…æ—¶å¤„ç†
                    yield f"data: {json.dumps({'type': 'error', 'error': 'å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                    return
                except Exception as stream_error:
                    # æµå¼å¤„ç†é”™è¯¯
                    yield f"data: {json.dumps({'type': 'error', 'error': f'å¤„ç†å¤±è´¥: {str(stream_error)}'})}\n\n"
                    return
                
                # 3. å‘é€å®Œæˆä¿¡å·
                yield f"data: {json.dumps({'type': 'complete', 'messageId': ai_message_id})}\n\n"
                
                # 4. ä¿å­˜AIæ¶ˆæ¯å®ŒæˆçŠ¶æ€åˆ°æ•°æ®åº“
                if workflow_id:
                    persistence_service.save_message(workflow_id, {
                        "messageId": ai_message_id,
                        "type": "assistant", 
                        "content": "åˆ†æå®Œæˆ",
                        "status": "completed"
                    })
                
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"
        
        return StreamingResponse(
            generate_streaming_response(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æµå¼å¯¹è¯å¤±è´¥: {str(e)}")

@router.post("/chat/message")
async def send_chat_message(request: ChatMessageRequest):
    """å‘é€èŠå¤©æ¶ˆæ¯ï¼ˆä¿ç•™åŸæœ‰æ¥å£å…¼å®¹æ€§ï¼‰"""
    try:
        conversation_id = request.conversation_id or f"conv_{uuid.uuid4()}"
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        if conversation_id not in conversation_storage:
            conversation_storage[conversation_id] = []
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        user_message = {
            "id": f"msg_{uuid.uuid4()}",
            "type": "user",
            "content": request.message,
            "timestamp": datetime.now().isoformat()
        }
        conversation_storage[conversation_id].append(user_message)
        
        # ç”ŸæˆAIå›å¤
        ai_response = await generate_ai_response(request.message, request.context)
        
        ai_message = {
            "id": f"msg_{uuid.uuid4()}",
            "type": "assistant",
            "content": ai_response,
            "timestamp": datetime.now().isoformat()
        }
        conversation_storage[conversation_id].append(ai_message)
        
        return {
            "success": True,
            "data": {
                "message": ai_message,
                "conversationId": conversation_id
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‘é€èŠå¤©æ¶ˆæ¯å¤±è´¥: {str(e)}")

@router.get("/chat/history/{conversation_id}")
async def get_chat_history(conversation_id: str):
    """è·å–èŠå¤©å†å²"""
    try:
        history = conversation_storage.get(conversation_id, [])
        
        return {
            "success": True,
            "data": history
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–èŠå¤©å†å²å¤±è´¥: {str(e)}")

@router.get("/agents")
async def get_agents():
    """è·å–æ™ºèƒ½ä½“é…ç½®"""
    try:
        agents = get_default_agents()
        
        return {
            "success": True,
            "data": agents
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ™ºèƒ½ä½“é…ç½®å¤±è´¥: {str(e)}")

@router.get("/workflow/history/{user_id}")
async def get_workflow_history(user_id: str):
    """è·å–ç”¨æˆ·å·¥ä½œæµå†å²"""
    try:
        # ä»å­˜å‚¨ä¸­ç­›é€‰ç”¨æˆ·çš„å·¥ä½œæµ
        user_workflows = [
            workflow for workflow in workflow_storage.values()
            if workflow.get("user_id") == user_id
        ]
        
        return {
            "success": True,
            "data": {
                "workflows": user_workflows,
                "total": len(user_workflows),
                "page": 1,
                "limit": 10
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµå†å²å¤±è´¥: {str(e)}")

@router.post("/analyze/stock")
async def analyze_stock(request: StockAnalysisRequest):
    """åˆ†æè‚¡ç¥¨ - ä½¿ç”¨è½»é‡çº§åˆ†æï¼Œä¸ä¾èµ–æ•°æ®åº“"""
    try:
        # ä½¿ç”¨é¦–é¡µä¸“ç”¨çš„è½»é‡çº§åˆ†ææ–¹æ³•
        analysis_result = qwen_analyzer.analyze_stock_for_homepage(request.symbol)
        
        return {
            "success": True,
            "data": {
                "analysis": analysis_result,
                "recommendations": [f"åŸºäºAIåˆ†æï¼Œ{request.symbol}å…·æœ‰æŠ•èµ„ä»·å€¼"]
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è‚¡ç¥¨åˆ†æå¤±è´¥: {str(e)}")

@router.post("/generate/strategy")
async def generate_strategy(request: StrategyGenerationRequest):
    """ç”ŸæˆæŠ•èµ„ç­–ç•¥"""
    try:
        # åŸºäºç”¨æˆ·åå¥½ç”Ÿæˆç­–ç•¥
        strategies = await generate_investment_strategies(request)
        
        return {
            "success": True,
            "data": {
                "strategies": strategies,
                "reasoning": f"åŸºäºæ‚¨çš„é£é™©åå¥½({request.riskTolerance})å’ŒæŠ•èµ„ç›®æ ‡ç”Ÿæˆç­–ç•¥"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç­–ç•¥ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.get("/market/insights")
async def get_market_insights():
    """è·å–å¸‚åœºæ´å¯Ÿ"""
    try:
        insights = await generate_market_insights()
        
        return {
            "success": True,
            "data": insights
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¸‚åœºæ´å¯Ÿå¤±è´¥: {str(e)}")

# æ–°å¢å·¥ä½œæµç”»å¸ƒç›¸å…³APIç«¯ç‚¹

@router.post("/workflow/definition/run")
async def run_workflow_definition(request: WorkflowDefinitionRunRequest, background_tasks: BackgroundTasks):
    """è¿è¡Œå·¥ä½œæµå®šä¹‰"""
    try:
        execution_id = request.execution_id
        workflow_definition = request.workflow_definition
        
        # éªŒè¯å·¥ä½œæµå®šä¹‰
        validation_result = validate_workflow_definition_internal(workflow_definition)
        if not validation_result["valid"]:
            raise HTTPException(status_code=400, detail=f"å·¥ä½œæµå®šä¹‰æ— æ•ˆ: {validation_result['errors']}")
        
        # åˆå§‹åŒ–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€
        workflow_execution_storage[execution_id] = {
            "execution_id": execution_id,
            "workflow_definition": workflow_definition,
            "user_id": request.user_id,
            "context": request.context or {},
            "status": "running",
            "progress": 0,
            "start_time": datetime.now().isoformat(),
            "node_statuses": initialize_node_statuses(workflow_definition.get("nodes", [])),
            "results": {}
        }
        
        # åœ¨åå°æ‰§è¡Œå·¥ä½œæµå®šä¹‰
        background_tasks.add_task(execute_workflow_definition, execution_id, workflow_definition, request.context)
        
        return {
            "success": True,
            "data": {
                "execution_id": execution_id,
                "status": "running",
                "message": "å·¥ä½œæµå®šä¹‰å¼€å§‹æ‰§è¡Œ",
                "node_statuses": workflow_execution_storage[execution_id]["node_statuses"]
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¿è¡Œå·¥ä½œæµå®šä¹‰å¤±è´¥: {str(e)}")

@router.get("/workflow/execution/status/{execution_id}")
async def get_workflow_execution_status(execution_id: str):
    """è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        
        return {
            "success": True,
            "data": {
                "execution_id": execution_id,
                "status": execution["status"],
                "progress": execution["progress"],
                "node_statuses": execution["node_statuses"],
                "results": execution.get("results", {}),
                "current_node": execution.get("current_node"),
                "message": execution.get("message", "")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/workflow/execution/stop/{execution_id}")
async def stop_workflow_execution(execution_id: str):
    """åœæ­¢å·¥ä½œæµæ‰§è¡Œ"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        execution["status"] = "stopped"
        execution["end_time"] = datetime.now().isoformat()
        
        return {
            "success": True,
            "data": {"message": "å·¥ä½œæµæ‰§è¡Œå·²åœæ­¢"}
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åœæ­¢å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")

@router.get("/workflow/execution/results/{execution_id}")
async def get_workflow_execution_results(execution_id: str):
    """è·å–å·¥ä½œæµæ‰§è¡Œç»“æœ"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        
        return {
            "success": True,
            "data": execution.get("results", {})
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµæ‰§è¡Œç»“æœå¤±è´¥: {str(e)}")

@router.post("/workflow/definition/validate")
async def validate_workflow_definition(request: WorkflowValidationRequest):
    """éªŒè¯å·¥ä½œæµå®šä¹‰"""
    try:
        workflow_definition = request.workflow_definition
        validation_result = validate_workflow_definition_internal(workflow_definition)
        
        return {
            "success": validation_result["valid"],
            "data": {
                "valid": validation_result["valid"],
                "errors": validation_result["errors"],
                "warnings": validation_result.get("warnings", [])
            },
            "message": "éªŒè¯å®Œæˆ" if validation_result["valid"] else "å·¥ä½œæµå®šä¹‰å­˜åœ¨é”™è¯¯"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"éªŒè¯å·¥ä½œæµå®šä¹‰å¤±è´¥: {str(e)}")

# è¾…åŠ©å‡½æ•°
def get_default_agents():
    """è·å–é»˜è®¤æ™ºèƒ½ä½“é…ç½®"""
    return [
        {
            "id": "data-collector",
            "name": "æ•°æ®æ”¶é›†æ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "analyzer",
            "name": "åˆ†ææ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "strategy-generator",
            "name": "ç­–ç•¥ç”Ÿæˆæ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "risk-assessor",
            "name": "é£é™©è¯„ä¼°æ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "executor",
            "name": "æ‰§è¡Œæ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        }
    ]

def calculate_progress(agents):
    """è®¡ç®—æ€»ä½“è¿›åº¦"""
    if not agents:
        return 0
    
    total_progress = sum(agent.get("progress", 0) for agent in agents)
    return total_progress // len(agents)

async def execute_workflow(workflow_id: str, query: str, context: Dict[str, Any]):
    """æ‰§è¡Œå·¥ä½œæµ"""
    try:
        workflow = workflow_storage[workflow_id]
        agents = workflow["agents"]
        
        # æ­¥éª¤1: æ•°æ®æ”¶é›†
        await update_agent_status(workflow_id, "data-collector", "running", 0, "æ­£åœ¨æ”¶é›†å¸‚åœºæ•°æ®...")
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        await update_agent_status(workflow_id, "data-collector", "completed", 100, "å¸‚åœºæ•°æ®æ”¶é›†å®Œæˆ")
        
        # æ­¥éª¤2: æ™ºèƒ½åˆ†æ
        await update_agent_status(workflow_id, "analyzer", "running", 0, "æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ...")
        analysis_result = await perform_analysis(query)
        await update_agent_status(workflow_id, "analyzer", "completed", 100, "æ™ºèƒ½åˆ†æå®Œæˆ")
        
        # æ­¥éª¤3: ç­–ç•¥ç”Ÿæˆ
        await update_agent_status(workflow_id, "strategy-generator", "running", 0, "æ­£åœ¨ç”ŸæˆæŠ•èµ„ç­–ç•¥...")
        await asyncio.sleep(2)
        await update_agent_status(workflow_id, "strategy-generator", "completed", 100, "æŠ•èµ„ç­–ç•¥ç”Ÿæˆå®Œæˆ")
        
        # æ­¥éª¤4: é£é™©è¯„ä¼°
        await update_agent_status(workflow_id, "risk-assessor", "running", 0, "æ­£åœ¨è¯„ä¼°é£é™©...")
        await asyncio.sleep(1.5)
        await update_agent_status(workflow_id, "risk-assessor", "completed", 100, "é£é™©è¯„ä¼°å®Œæˆ")
        
        # æ­¥éª¤5: æ‰§è¡Œ
        await update_agent_status(workflow_id, "executor", "running", 0, "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        await asyncio.sleep(1)
        await update_agent_status(workflow_id, "executor", "completed", 100, "æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # å®Œæˆå·¥ä½œæµ
        workflow["status"] = "completed"
        workflow["end_time"] = datetime.now().isoformat()
        workflow["results"] = analysis_result
        
    except Exception as e:
        print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        workflow = workflow_storage.get(workflow_id)
        if workflow:
            workflow["status"] = "error"
            workflow["message"] = str(e)

async def update_agent_status(workflow_id: str, agent_id: str, status: str, progress: int, message: str):
    """æ›´æ–°æ™ºèƒ½ä½“çŠ¶æ€"""
    workflow = workflow_storage.get(workflow_id)
    if workflow:
        agents = workflow["agents"]
        for agent in agents:
            if agent["id"] == agent_id:
                agent["status"] = status
                agent["progress"] = progress
                agent["message"] = message
                if status == "running":
                    agent["startTime"] = datetime.now().isoformat()
                elif status in ["completed", "error"]:
                    agent["endTime"] = datetime.now().isoformat()
                break

async def perform_analysis(query: str):
    """æ‰§è¡Œåˆ†æ"""
    try:
        # è°ƒç”¨ç°æœ‰çš„åˆ†ææœåŠ¡
        result = stock_recommender.recommend_stocks_by_query(query)
        
        return {
            "marketAnalysis": {
                "trend": "éœ‡è¡ä¸Šè¡Œ",
                "sentiment": "è°¨æ…ä¹è§‚",
                "volatility": "ä¸­ç­‰",
                "keyFactors": ["æ”¿ç­–æ”¯æŒ", "ä¸šç»©æ”¹å–„", "èµ„é‡‘æµå…¥"]
            },
            "stockRecommendations": result.get("recommendations", []),
            "keywords": result.get("extracted_keywords", []),
            "summary": f"åŸºäºæŸ¥è¯¢'{query}'çš„åˆ†æç»“æœ"
        }
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        return {
            "marketAnalysis": {
                "trend": "æ•°æ®è·å–ä¸­",
                "sentiment": "ä¸­æ€§",
                "volatility": "æœªçŸ¥",
                "keyFactors": []
            },
            "stockRecommendations": [],
            "summary": "åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        }

async def perform_intelligent_analysis(message: str, context: Dict[str, Any] = None):
    """æ‰§è¡Œæ™ºèƒ½åˆ†æï¼ˆä¸“é—¨ç”¨äºAIåˆ†æçš„æ ¸å¿ƒå‡½æ•°ï¼‰"""
    try:
        print(f"å¼€å§‹æ™ºèƒ½åˆ†æ: {message}")
        
        # å¤„ç†ä¸Šä¸‹æ–‡ä¿¡æ¯
        enhanced_message = message
        if context:
            enhanced_message = enhance_message_with_context(message, context)
            print(f"å¢å¼ºåçš„æ¶ˆæ¯: {enhanced_message}")
        
        # ä½¿ç”¨ç°æœ‰çš„è‚¡ç¥¨æ¨èæœåŠ¡è¿›è¡Œåˆ†æ
        analysis_result = stock_recommender.recommend_stocks_by_query(enhanced_message)
        
        # å¦‚æœæœ‰æ¨èç»“æœï¼Œç”Ÿæˆè¯¦ç»†å›å¤
        if analysis_result and analysis_result.get("recommendations"):
            recommendations = analysis_result["recommendations"][:5]  # å–å‰5ä¸ªæ¨è
            keywords = analysis_result.get("keywords", [])
            
            # ç”Ÿæˆæ™ºèƒ½å›å¤
            response = f"åŸºäºAIåˆ†æï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†ä»¥ä¸‹æŠ•èµ„å»ºè®®ï¼š\n\n"
            
            if keywords:
                response += f"ğŸ” **å…³é”®åˆ†æè¦ç´ **\n"
                for keyword in keywords[:3]:
                    response += f"â€¢ {keyword.get('text', keyword)}\n"
                response += "\n"
            
            response += f"ğŸ“ˆ **æ¨èè‚¡ç¥¨** ({len(recommendations)}åª)\n"
            for i, stock in enumerate(recommendations, 1):
                response += f"**{i}. {stock.get('symbol', 'N/A')} - {stock.get('name', 'æœªçŸ¥')}**\n"
                response += f"â€¢ åŒ¹é…åº¦: {stock.get('matchScore', stock.get('score', 85))}åˆ†\n"
                response += f"â€¢ æ¨èç†ç”±: {stock.get('reason', 'åŸºäºAIåˆ†ææ¨è')}\n"
                if stock.get('sector'):
                    response += f"â€¢ æ‰€å±è¡Œä¸š: {stock.get('sector')}\n"
                response += "\n"
            
            response += "ğŸ’¡ **æŠ•èµ„å»ºè®®**\n"
            response += "â€¢ å»ºè®®åˆ†æ•£æŠ•èµ„ï¼Œæ§åˆ¶å•ä¸€æ ‡çš„æƒé‡\n"
            response += "â€¢ å¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€å’Œæ”¿ç­–å˜åŒ–\n"
            response += "â€¢ è®¾ç½®åˆç†çš„æ­¢æŸç‚¹ä½\n\n"
            response += "éœ€è¦æˆ‘è¯¦ç»†åˆ†ææŸåªå…·ä½“è‚¡ç¥¨å—ï¼Ÿ"
            
            return {
                "response": clean_text(response),
                "analysis": analysis_result,
                "recommendations": recommendations
            }
        else:
            # å¦‚æœæ²¡æœ‰å…·ä½“æ¨èï¼Œæä¾›é€šç”¨åˆ†æ
            response = await generate_general_analysis_response(message)
            return {
                "response": clean_text(response),
                "analysis": {"type": "general", "query": message},
                "recommendations": []
            }
            
    except Exception as e:
        print(f"æ™ºèƒ½åˆ†æå¤±è´¥: {e}")
        return {
            "response": "æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚æˆ‘ä¼šå°½å¿«ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŠ•èµ„åˆ†æã€‚",
            "analysis": {"error": str(e)},
            "recommendations": []
        }

async def generate_general_analysis_response(message: str):
    """ç”Ÿæˆé€šç”¨åˆ†æå›å¤"""
    try:
        # ä½¿ç”¨Qwenåˆ†æå™¨è¿›è¡Œå…³é”®è¯åˆ†æ
        keywords_result = await qwen_analyzer.analyze_keywords(message)
        
        if keywords_result and keywords_result.get("keywords"):
            keywords = keywords_result["keywords"]
            
            response = f"åŸºäºæ‚¨çš„æŸ¥è¯¢ã€Œ{message}ã€ï¼Œæˆ‘è¿›è¡Œäº†ä»¥ä¸‹åˆ†æï¼š\n\n"
            response += "ğŸ” **å…³é”®æŠ•èµ„è¦ç´ è¯†åˆ«**\n"
            
            for keyword in keywords[:5]:
                if isinstance(keyword, dict):
                    text = keyword.get('text', keyword.get('keyword', ''))
                    confidence = keyword.get('confidence', 0)
                    if confidence > 0:
                        response += f"â€¢ {text} (ç›¸å…³åº¦: {int(confidence * 100)}%)\n"
                    else:
                        response += f"â€¢ {text}\n"
                else:
                    response += f"â€¢ {keyword}\n"
            
            response += "\nğŸ“Š **æŠ•èµ„å»ºè®®æ–¹å‘**\n"
            
            # æ ¹æ®å…³é”®è¯æä¾›ç›¸åº”å»ºè®®
            keyword_texts = [k.get('text', k) if isinstance(k, dict) else str(k) for k in keywords]
            keyword_str = ' '.join(keyword_texts).lower()
            
            if any(word in keyword_str for word in ['ç§‘æŠ€', 'æŠ€æœ¯', 'äº’è”ç½‘', 'è½¯ä»¶']):
                response += "â€¢ å…³æ³¨ç§‘æŠ€æ¿å—çš„æŠ•èµ„æœºä¼š\nâ€¢ é‡ç‚¹å…³æ³¨åˆ›æ–°èƒ½åŠ›å¼ºçš„å…¬å¸\nâ€¢ æ³¨æ„ä¼°å€¼åˆç†æ€§\n"
            elif any(word in keyword_str for word in ['é‡‘è', 'é“¶è¡Œ', 'ä¿é™©']):
                response += "â€¢ å…³æ³¨é‡‘èæ¿å—çš„ä»·å€¼æŠ•èµ„æœºä¼š\nâ€¢ é‡ç‚¹å…³æ³¨åˆ†çº¢ç¨³å®šçš„ä¼˜è´¨é“¶è¡Œè‚¡\nâ€¢ æ³¨æ„æ”¿ç­–å½±å“\n"
            elif any(word in keyword_str for word in ['åŒ»è¯', 'åŒ»ç–—', 'ç”Ÿç‰©']):
                response += "â€¢ å…³æ³¨åŒ»è¯æ¿å—çš„é•¿æœŸæŠ•èµ„ä»·å€¼\nâ€¢ é‡ç‚¹å…³æ³¨åˆ›æ–°è¯å’ŒåŒ»ç–—å™¨æ¢°\nâ€¢ æ³¨æ„æ”¿ç­–å’Œå®¡æ‰¹é£é™©\n"
            else:
                response += "â€¢ å»ºè®®å¤šå…ƒåŒ–æŠ•èµ„ï¼Œåˆ†æ•£é£é™©\nâ€¢ å…³æ³¨åŸºæœ¬é¢è‰¯å¥½çš„ä¼˜è´¨å…¬å¸\nâ€¢ ç»“åˆæŠ€æœ¯åˆ†æç¡®å®šä¹°å…¥æ—¶æœº\n"
            
            response += "\nğŸ’¡ å¦‚éœ€å…·ä½“çš„è‚¡ç¥¨æ¨èï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨çš„é£é™©åå¥½å’ŒæŠ•èµ„æœŸé™ã€‚"
            
            return clean_text(response)
        else:
            return clean_text(generate_fallback_response(message))
            
    except Exception as e:
        print(f"é€šç”¨åˆ†æå¤±è´¥: {e}")
        return clean_text(generate_fallback_response(message))

def generate_fallback_response(message: str):
    """ç”Ÿæˆé™çº§å›å¤"""
    response = f"""æˆ‘ç†è§£æ‚¨å…³äºã€Œ{message}ã€çš„å’¨è¯¢ã€‚

ğŸ¯ **æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä»¥ä¸‹æœåŠ¡ï¼š**
â€¢ ä¸ªè‚¡åˆ†æå’Œæ¨è
â€¢ è¡Œä¸šæ¿å—æŠ•èµ„å»ºè®®  
â€¢ æŠ•èµ„ç­–ç•¥åˆ¶å®š
â€¢ é£é™©è¯„ä¼°å’Œç®¡ç†
â€¢ å¸‚åœºè¶‹åŠ¿åˆ†æ

ğŸ’¡ **å»ºè®®æ‚¨å¯ä»¥è¿™æ ·æé—®ï¼š**
â€¢ "æ¨èä¸€äº›ç§‘æŠ€è‚¡"
â€¢ "åˆ†æä¸€ä¸‹é“¶è¡Œæ¿å—"
â€¢ "æˆ‘æƒ³è¦ä½é£é™©çš„æŠ•èµ„å»ºè®®"
â€¢ "å¸®æˆ‘åˆ†æ000001è¿™åªè‚¡ç¥¨"

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŠ•èµ„åˆ†æï¼"""
    return clean_text(response)

async def generate_analysis_stream(message: str, context: Dict[str, Any], workflow_id: str, persistence_service: WorkflowPersistenceService, ai_message_id: str):
    """ç”Ÿæˆè‚¡ç¥¨åˆ†æçš„æµå¼å“åº”"""
    
    print(f"ğŸ“Š è¿›å…¥generate_analysis_streamå‡½æ•°, workflow_id: {workflow_id}, message: {message[:50]}...")
    
    # ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆåˆ†ææ­¥éª¤
    analysis_steps = await generate_smart_analysis_steps(message, context)
    analysis_steps = enrich_steps_with_urls(analysis_steps, message)
    
    category = determine_step_category_from_message(message)
    
    for i, step_info in enumerate(analysis_steps):
        step_context = {
            'step_number': i + 1,
            'user_message': message,
            **(context or {})
        }
        
        # ä»AIç”Ÿæˆçš„æ­¥éª¤ä¿¡æ¯ä¸­æå–èµ„æºç±»å‹å’Œç»“æœ
        resource_type = step_info.get('resourceType', 'general')
        results = step_info.get('results', [])
        step_content = step_info.get('content', f'æ‰§è¡Œæ­¥éª¤ {i+1}')
        
        step_data = {
            'type': 'progress', 
            'content': step_content, 
            'step': i+1, 
            'totalSteps': len(analysis_steps), 
            'stepId': f'step_{i+1}', 
            'category': category,
            'resourceType': resource_type,
            'results': results,
            'executionDetails': step_info.get('executionDetails', {}),
            'urls': step_info.get('urls', []),
            'files': step_info.get('files', [])
        }
        
        # ä¿å­˜æ­¥éª¤åˆ°æ•°æ®åº“
        if workflow_id:
            try:
                persistence_service.save_step(workflow_id, {
                    'step_id': f'step_{i+1}',
                    'step_number': i + 1,
                    'content': step_content,
                    'category': category,
                    'resource_type': resource_type,
                    'status': 'running',
                    'results': results,
                    'execution_details': step_info.get('executionDetails', {}),
                    'urls': step_info.get('urls', []),
                    'files': step_info.get('files', [])
                })
                
                # ã€æ–°å¢ã€‘å®æ—¶ä¿å­˜æ€è€ƒè¿‡ç¨‹æ¶ˆæ¯åˆ°æ•°æ®åº“
                step_message_id = f"step_msg_{i+1}_{uuid.uuid4()}"
                persistence_service.save_message(workflow_id, {
                    "messageId": step_message_id,
                    "type": "task",
                    "content": f"æ­£åœ¨æ‰§è¡Œï¼š{step_content}",
                    "status": "thinking",
                    "data": step_data
                })
                
                # ã€æ–°å¢ã€‘ä¿å­˜æ­¥éª¤èµ„æºåˆ°æ•°æ®åº“
                print(f"ğŸ”„ å‡†å¤‡ä¿å­˜æ­¥éª¤èµ„æº: step_{i+1}, workflow_id: {workflow_id}")
                persistence_service.save_resources(workflow_id, f'step_{i+1}', {
                    'content': step_content,
                    'category': category,
                    'resourceType': resource_type,
                    'results': results,
                    'executionDetails': step_info.get('executionDetails', {}),
                    'urls': step_info.get('urls', []),
                    'files': step_info.get('files', []),
                    'stepId': f'step_{i+1}'
                })
                print(f"âœ… æ­¥éª¤èµ„æºä¿å­˜è°ƒç”¨å®Œæˆ")
            except Exception as e:
                print(f"ä¿å­˜æ­¥éª¤åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        yield f"data: {json.dumps(step_data)}\n\n"
        
        # ã€æ–°å¢ã€‘æ­¥éª¤å‘é€åç«‹å³æ¨é€èµ„æºæ›´æ–°äº‹ä»¶
        if workflow_id:
            print(f"ğŸ”„ å‘é€èµ„æºæ›´æ–°æ¨é€: æ­¥éª¤ {i+1}, å·¥ä½œæµID: {workflow_id}")
            yield f"data: {json.dumps({'type': 'resource_updated', 'workflowId': workflow_id, 'trigger': 'step_thinking', 'stepNumber': i+1})}\n\n"
        
        # ä½¿ç”¨æ›´çŸ­çš„é—´éš”ï¼Œå‡å°‘é˜»å¡æ„Ÿ
        await asyncio.sleep(0.5)
        
        # æ ‡è®°æ­¥éª¤å®Œæˆ
        if workflow_id:
            try:
                persistence_service.complete_step(workflow_id, f'step_{i+1}')
                
                # ã€æ–°å¢ã€‘ä¿å­˜æ­¥éª¤å®ŒæˆçŠ¶æ€åˆ°æ¶ˆæ¯
                completion_message_id = f"step_complete_{i+1}_{uuid.uuid4()}"
                persistence_service.save_message(workflow_id, {
                    "messageId": completion_message_id,
                    "type": "result",
                    "content": f"æ­¥éª¤å®Œæˆï¼š{step_content}",
                    "status": "completed",
                    "data": {"stepId": f'step_{i+1}', "results": results}
                })
                
                # ã€æ–°å¢ã€‘æ­¥éª¤å®Œæˆæ—¶æ¨é€èµ„æºæ›´æ–°äº‹ä»¶
                yield f"data: {json.dumps({'type': 'resource_updated', 'workflowId': workflow_id, 'messageId': completion_message_id, 'trigger': 'step_completed'})}\n\n"
            except Exception as e:
                print(f"æ ‡è®°æ­¥éª¤å®Œæˆå¤±è´¥: {e}")
    
    # ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆåˆ†æå†…å®¹
    try:
        # æ„å»ºåˆ†ææç¤ºè¯ï¼ˆç”±AIè‡ªå®šç»“æ„ä¸æ®µè½æ•°é‡ï¼Œä¸å¼ºåˆ¶5ç‚¹ï¼‰
        analysis_prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„æŠ•èµ„é¡¾é—®ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜åšâ€œè‡ªé€‚åº”ç»“æ„â€çš„æŠ•èµ„åˆ†æï¼š

ç”¨æˆ·é—®é¢˜ï¼š{message}

è¦æ±‚ï¼š
- å…ˆåˆ¤æ–­é—®é¢˜å¤æ‚åº¦ï¼ŒåŠ¨æ€å†³å®šåˆ†æå±‚çº§ä¸æ®µè½æ•°é‡ï¼ˆå¸¸è§ä¸º2-6æ®µï¼‰ã€‚
- æŒ‰éœ€è¦†ç›–ï¼šé—®é¢˜æ¾„æ¸…/å…³é”®è¦ç‚¹ã€å¿…è¦çš„æ•°æ®ä¸äº‹å®ä¾æ®ã€æŠ€æœ¯é¢ä¸åŸºæœ¬é¢ä¸­ä¸é—®é¢˜é«˜åº¦ç›¸å…³çš„éƒ¨åˆ†ã€ä¸»è¦é£é™©ã€å¯æ‰§è¡Œå»ºè®®ã€‚
- åªè¾“å‡ºç»“è®ºä¸æ¨ç†ï¼Œä¸è¾“å‡ºâ€œæ‰§è¡Œæ­¥éª¤â€æˆ–â€œæˆ‘æ­£åœ¨æ€è€ƒâ€ç­‰è¿‡ç¨‹æ€§è¯è¯­ã€‚
- ä¸­æ–‡å›ç­”ï¼Œç»“æ„æ¸…æ™°ï¼Œåˆ—è¡¨å’Œå°æ ‡é¢˜è‡ªå®šï¼Œé¿å…æ¨¡æ¿åŒ–é‡å¤ã€‚
"""
        
        # è°ƒç”¨é€šä¹‰åƒé—®API - æ·»åŠ è¶…æ—¶ä¿æŠ¤
        try:
            ai_response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: qwen_analyzer.analyze_text(analysis_prompt, max_tokens=2000)
                ),
                timeout=30.0  # 30ç§’è¶…æ—¶
            )
        except asyncio.TimeoutError:
            print("é€šä¹‰åƒé—®åˆ†æAPIè¶…æ—¶ï¼Œä½¿ç”¨é™çº§å›å¤ (fallback)")
            ai_response = None
        except Exception as api_error:
            print(f"é€šä¹‰åƒé—®åˆ†æAPIè°ƒç”¨å¤±è´¥: {api_error}, å°†ä½¿ç”¨fallback")
            ai_response = None
        
        if ai_response and ai_response.strip():
            # å°†AIå›å¤åˆ†æ®µè¾“å‡ºï¼Œæ¯æ®µé—´éš”æ›´çŸ­
            analysis_parts = ai_response.split('\n\n')
            
            for part in analysis_parts:
                if part.strip():
                    part_content = part.strip()
                    content_data = {'type': 'content', 'content': part_content, 'stepId': 'ai_analysis', 'category': 'result'}
                    
                    # ã€æ–°å¢ã€‘å®æ—¶ä¿å­˜AIåˆ†æå†…å®¹åˆ°æ•°æ®åº“
                    if workflow_id:
                        try:
                            part_message_id = f"ai_content_{uuid.uuid4()}"
                            persistence_service.save_message(workflow_id, {
                                "messageId": part_message_id,
                                "type": "assistant",
                                "content": part_content,
                                "status": "streaming",
                                "data": content_data
                            })
                            
                            # ã€æ–°å¢ã€‘AIå†…å®¹æ›´æ–°æ—¶æ¨é€èµ„æºæ›´æ–°äº‹ä»¶
                            yield f"data: {json.dumps({'type': 'resource_updated', 'workflowId': workflow_id, 'messageId': part_message_id, 'trigger': 'ai_content'})}\n\n"
                        except Exception as e:
                            print(f"ä¿å­˜AIå†…å®¹åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                    
                    yield f"data: {json.dumps(content_data)}\n\n"
                    await asyncio.sleep(0.3)  # å‡å°‘é—´éš”æ—¶é—´
                else:
                    yield f"data: {json.dumps({'type': 'content', 'content': '', 'stepId': 'ai_analysis'})}\n\n"
                    await asyncio.sleep(0.05)  # ç©ºè¡Œé—´éš”å¾ˆçŸ­
        else:
            # é™çº§å›å¤
            fallback_response = "ã€AIæœåŠ¡æš‚ä¸å¯ç”¨ï¼Œä»¥ä¸‹ä¸ºç®€è¦å»ºè®®ã€‘\n\n" + generate_fallback_analysis_response(message)
            
            # ã€æ–°å¢ã€‘ä¿å­˜é™çº§å›å¤åˆ°æ•°æ®åº“
            if workflow_id:
                try:
                    fallback_message_id = f"fallback_{uuid.uuid4()}"
                    persistence_service.save_message(workflow_id, {
                        "messageId": fallback_message_id,
                        "type": "assistant",
                        "content": fallback_response,
                        "status": "fallback"
                    })
                except Exception as e:
                    print(f"ä¿å­˜é™çº§å›å¤åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
            yield f"data: {json.dumps({'type': 'content', 'content': fallback_response, 'stepId': 'fallback_analysis'})}\n\n"

    except Exception as e:
        print(f"ç”Ÿæˆåˆ†æå›å¤å¤±è´¥: {e}")
        error_msg = "æŠ±æ­‰ï¼Œåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…æä¾›æ›´å…·ä½“çš„åˆ†æéœ€æ±‚ã€‚"

        # ã€æ–°å¢ã€‘ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
        if workflow_id:
            try:
                error_message_id = f"error_{uuid.uuid4()}"
                persistence_service.save_message(workflow_id, {
                    "messageId": error_message_id,
                    "type": "system",
                    "content": error_msg,
                    "status": "error"
                })
            except Exception as e:
                print(f"ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥: {e}")

        yield f"data: {json.dumps({'type': 'content', 'content': error_msg, 'stepId': 'error', 'category': 'error'})}\n\n"

async def generate_strategy_stream(message: str, context: Dict[str, Any], workflow_id: str, persistence_service: WorkflowPersistenceService, ai_message_id: str):
    """ç”ŸæˆæŠ•èµ„ç­–ç•¥çš„æµå¼å“åº”"""
    
    # ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆç­–ç•¥æ­¥éª¤
    strategy_steps = await generate_smart_strategy_steps(message, context)
    strategy_steps = enrich_steps_with_urls(strategy_steps, message)
    
    category = determine_step_category_from_message(message)
    
    for i, step_info in enumerate(strategy_steps):
        step_context = {
            'step_number': i + 1,
            'user_message': message,
            **(context or {})
        }
        
        # ä»AIç”Ÿæˆçš„æ­¥éª¤ä¿¡æ¯ä¸­æå–èµ„æºç±»å‹å’Œç»“æœ
        resource_type = step_info.get('resourceType', 'general')
        results = step_info.get('results', [])
        step_content = step_info.get('content', f'æ‰§è¡Œæ­¥éª¤ {i+1}')
        
        step_data = {
            'type': 'progress', 
            'content': step_content, 
            'step': i+1, 
            'totalSteps': len(strategy_steps), 
            'stepId': f'strategy_step_{i+1}', 
            'category': category,
            'resourceType': resource_type,
            'results': results,
            'executionDetails': step_info.get('executionDetails', {}),
            'urls': step_info.get('urls', []),
            'files': step_info.get('files', [])
        }
        
        # ä¿å­˜æ­¥éª¤åˆ°æ•°æ®åº“
        if workflow_id:
            try:
                persistence_service.save_step(workflow_id, {
                    'step_id': f'strategy_step_{i+1}',
                    'step_number': i + 1,
                    'content': step_content,
                    'category': category,
                    'resource_type': resource_type,
                    'status': 'running',
                    'results': results,
                    'execution_details': step_info.get('executionDetails', {}),
                    'urls': step_info.get('urls', []),
                    'files': step_info.get('files', [])
                })
            except Exception as e:
                print(f"ä¿å­˜ç­–ç•¥æ­¥éª¤åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        yield f"data: {json.dumps(step_data)}\n\n"
        await asyncio.sleep(0.4)  # å‡å°‘å»¶è¿Ÿ
        
        # æ ‡è®°æ­¥éª¤å®Œæˆ
        if workflow_id:
            try:
                persistence_service.complete_step(workflow_id, f'strategy_step_{i+1}')
            except Exception as e:
                print(f"æ ‡è®°ç­–ç•¥æ­¥éª¤å®Œæˆå¤±è´¥: {e}")
    
    # ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆç­–ç•¥å†…å®¹
    try:
        # æ„å»ºç­–ç•¥æç¤ºè¯
        strategy_prompt = f"""
è¯·ä½œä¸ºä¸“ä¸šçš„æŠ•èµ„ç­–ç•¥é¡¾é—®ï¼Œé’ˆå¯¹ç”¨æˆ·çš„éœ€æ±‚åˆ¶å®šæŠ•èµ„ç­–ç•¥ï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{message}

è¯·ä»¥â€œè‡ªé€‚åº”ç»“æ„â€ç»™å‡ºç­–ç•¥å»ºè®®ï¼šæ ¹æ®å¤æ‚åº¦åŠ¨æ€å†³å®šæ®µè½ä¸è¦ç‚¹æ•°é‡ï¼ˆ2-6æ®µçš†å¯ï¼‰ã€‚æŒ‰éœ€è¦†ç›–ï¼šç­–ç•¥ç›®æ ‡ä¸æ ¸å¿ƒæ€è·¯ã€å…³é”®æ“ä½œå»ºè®®ã€é£é™©æ§åˆ¶è¦ç‚¹ã€é¢„æœŸåŒºé—´/å‘¨æœŸã€æ‰§è¡Œæ³¨æ„äº‹é¡¹ã€‚ä¸è¦è¾“å‡ºâ€œæ‰§è¡Œæ­¥éª¤â€æˆ–è¿‡ç¨‹æ€§å™è¿°ï¼Œä»…ç»™å‡ºç»“è®ºä¸å¯æ‰§è¡Œå»ºè®®ã€‚
"""
        
        # è°ƒç”¨é€šä¹‰åƒé—®API - æ·»åŠ è¶…æ—¶ä¿æŠ¤
        try:
            ai_response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: qwen_analyzer.analyze_text(strategy_prompt, max_tokens=2000)
                ),
                timeout=30.0  # 30ç§’è¶…æ—¶
            )
        except asyncio.TimeoutError:
            print("é€šä¹‰åƒé—®ç­–ç•¥APIè¶…æ—¶ï¼Œä½¿ç”¨é™çº§å›å¤")
            ai_response = None
        except Exception as api_error:
            print(f"é€šä¹‰åƒé—®ç­–ç•¥APIè°ƒç”¨å¤±è´¥: {api_error}")
            ai_response = None
        
        if ai_response and ai_response.strip():
            # å°†AIå›å¤åˆ†æ®µè¾“å‡º
            strategy_parts = ai_response.split('\n\n')
            
            for part in strategy_parts:
                if part.strip():
                    yield f"data: {json.dumps({'type': 'content', 'content': part.strip(), 'stepId': 'ai_strategy', 'category': 'result'})}\n\n"
                    await asyncio.sleep(0.3)
                else:
                    yield f"data: {json.dumps({'type': 'content', 'content': '', 'stepId': 'ai_strategy'})}\n\n"
                    await asyncio.sleep(0.05)
        else:
            # é™çº§å›å¤
            fallback_response = "ã€AIæœåŠ¡æš‚ä¸å¯ç”¨ï¼Œä»¥ä¸‹ä¸ºé™çº§ç­–ç•¥æ¡†æ¶ã€‘\n\n" + generate_fallback_strategy_response(message)
            yield f"data: {json.dumps({'type': 'content', 'content': fallback_response, 'stepId': 'fallback_strategy'})}\n\n"


    except Exception as e:
        print(f"ç”Ÿæˆç­–ç•¥å›å¤å¤±è´¥: {e}")
        error_msg = "æŠ±æ­‰ï¼Œç­–ç•¥æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…æä¾›æ›´å…·ä½“çš„ç­–ç•¥éœ€æ±‚ã€‚"

        yield f"data: {json.dumps({'type': 'content', 'content': error_msg, 'stepId': 'error', 'category': 'error'})}\n\n"

async def generate_general_stream(message: str, context: Dict[str, Any], workflow_id: str, persistence_service: WorkflowPersistenceService, ai_message_id: str):
    """ç”Ÿæˆé€šç”¨å¯¹è¯çš„æµå¼å“åº”"""
    
    # ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆé€šç”¨æ­¥éª¤
    general_steps = await generate_smart_general_steps(message, context)
    general_steps = enrich_steps_with_urls(general_steps, message)
    
    category = determine_step_category_from_message(message)
    
    for i, step_info in enumerate(general_steps):
        step_context = {
            'step_number': i + 1,
            'user_message': message,
            **(context or {})
        }
        
        # ä»AIç”Ÿæˆçš„æ­¥éª¤ä¿¡æ¯ä¸­æå–èµ„æºç±»å‹å’Œç»“æœ
        resource_type = step_info.get('resourceType', 'general')
        results = step_info.get('results', [])
        step_content = step_info.get('content', f'æ‰§è¡Œæ­¥éª¤ {i+1}')
        
        step_data = {
            'type': 'progress', 
            'content': step_content, 
            'step': i+1, 
            'totalSteps': len(general_steps), 
            'stepId': f'general_step_{i+1}', 
            'category': category,
            'resourceType': resource_type,
            'results': results,
            'executionDetails': step_info.get('executionDetails', {}),
            'urls': step_info.get('urls', []),
            'files': step_info.get('files', [])
        }
        
        # ä¿å­˜æ­¥éª¤åˆ°æ•°æ®åº“
        if workflow_id:
            try:
                persistence_service.save_step(workflow_id, {
                    'step_id': f'general_step_{i+1}',
                    'step_number': i + 1,
                    'content': step_content,
                    'category': category,
                    'resource_type': resource_type,
                    'status': 'running',
                    'results': results,
                    'execution_details': step_info.get('executionDetails', {}),
                    'urls': step_info.get('urls', []),
                    'files': step_info.get('files', [])
                })
            except Exception as e:
                print(f"ä¿å­˜é€šç”¨æ­¥éª¤åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        yield f"data: {json.dumps(step_data)}\n\n"
        await asyncio.sleep(0.3)  # å‡å°‘å»¶è¿Ÿ
        
        # æ ‡è®°æ­¥éª¤å®Œæˆ
        if workflow_id:
            try:
                persistence_service.complete_step(workflow_id, f'general_step_{i+1}')
            except Exception as e:
                print(f"æ ‡è®°é€šç”¨æ­¥éª¤å®Œæˆå¤±è´¥: {e}")
    
    # ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆé€šç”¨å›å¤ - æ·»åŠ è¶…æ—¶å’Œé™çº§æœºåˆ¶
    try:
        # æ„å»ºé€šç”¨å¯¹è¯æç¤ºè¯
        general_prompt = f"""
è¯·ä½œä¸ºAIåŠ©æ‰‹ï¼Œé’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜æä¾›ä¸“ä¸šã€æœ‰ç”¨çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{message}

è¯·æä¾›ï¼š
1. å¯¹é—®é¢˜çš„ç†è§£å’Œåˆ†æ
2. è¯¦ç»†çš„è§£ç­”æˆ–å»ºè®®
3. ç›¸å…³çš„è¡¥å……ä¿¡æ¯
4. åç»­å¯èƒ½éœ€è¦çš„è¡ŒåŠ¨å»ºè®®

è¯·ç¡®ä¿å›ç­”å‡†ç¡®ã€æœ‰ç”¨ä¸”æ˜“äºç†è§£ã€‚
"""
        
        # è°ƒç”¨é€šä¹‰åƒé—®API - æ·»åŠ è¶…æ—¶ä¿æŠ¤
        try:
            ai_response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: qwen_analyzer.analyze_text(general_prompt, max_tokens=1500)
                ),
                timeout=30.0  # 30ç§’è¶…æ—¶
            )
        except asyncio.TimeoutError:
            print("é€šä¹‰åƒé—®APIè¶…æ—¶ï¼Œä½¿ç”¨é™çº§å›å¤")
            ai_response = None
        except Exception as api_error:
            print(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {api_error}")
            ai_response = None
        
        if ai_response and ai_response.strip():
            # å°†AIå›å¤åˆ†æ®µè¾“å‡º
            general_parts = ai_response.split('\n\n')
            
            for part in general_parts:
                if part.strip():
                    yield f"data: {json.dumps({'type': 'content', 'content': part.strip(), 'stepId': 'ai_general', 'category': 'result'})}\n\n"
                    await asyncio.sleep(0.3)
                else:
                    yield f"data: {json.dumps({'type': 'content', 'content': '', 'stepId': 'ai_general'})}\n\n"
                    await asyncio.sleep(0.05)
        else:
            # é™çº§å›å¤ - æä¾›æ›´æœ‰ç”¨çš„å†…å®¹
            fallback_response = generate_fallback_general_response(message)
            yield f"data: {json.dumps({'type': 'content', 'content': fallback_response, 'stepId': 'fallback_general'})}\n\n"
                
    except Exception as e:
        print(f"ç”ŸæˆAIå›å¤å¤±è´¥: {e}")
        error_msg = "æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…æä¾›æ›´å…·ä½“çš„é—®é¢˜æè¿°ã€‚"

        yield f"data: {json.dumps({'type': 'content', 'content': error_msg, 'stepId': 'error', 'category': 'error'})}\n\n"

def generate_fallback_general_response(message: str) -> str:
    """ç”Ÿæˆé™çº§çš„é€šç”¨å›å¤"""
    message_lower = message.lower()
    
    if any(keyword in message_lower for keyword in ['è‚¡ç¥¨', 'æŠ•èµ„', 'åŸºé‡‘', 'ç†è´¢']):
        return f"""æ„Ÿè°¢æ‚¨å…³äº"{message}"çš„å’¨è¯¢ã€‚

æˆ‘ç†è§£æ‚¨å¯¹æŠ•èµ„ç†è´¢æ–¹é¢çš„å…³æ³¨ï¼Œå»ºè®®æ‚¨å¯ä»¥ï¼š

1. **æ·±å…¥ç ”ç©¶**: æŸ¥çœ‹ç›¸å…³å…¬å¸çš„è´¢åŠ¡æŠ¥è¡¨å’Œè¡Œä¸šåˆ†æ
2. **é£é™©è¯„ä¼°**: äº†è§£æŠ•èµ„äº§å“çš„é£é™©ç­‰çº§å’Œè‡ªå·±çš„é£é™©æ‰¿å—èƒ½åŠ›  
3. **ä¸“ä¸šå’¨è¯¢**: å’¨è¯¢ä¸“ä¸šçš„æŠ•èµ„é¡¾é—®è·å–ä¸ªæ€§åŒ–å»ºè®®
4. **åˆ†æ•£æŠ•èµ„**: ä¸è¦æŠŠæ‰€æœ‰èµ„é‡‘æŠ•å…¥å•ä¸€æ ‡çš„

è¯·æ³¨æ„æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚å»ºè®®åœ¨å……åˆ†äº†è§£çš„åŸºç¡€ä¸Šåšå‡ºæŠ•èµ„é€‰æ‹©ã€‚"""
    
    elif any(keyword in message_lower for keyword in ['æ•°æ®', 'åˆ†æ', 'æŸ¥è¯¢']):
        return f"""å…³äºæ‚¨æåˆ°çš„"{message}"ï¼Œæˆ‘æ¥ä¸ºæ‚¨æä¾›ä¸€äº›åˆ†ææ€è·¯ï¼š

1. **æ•°æ®æ”¶é›†**: é¦–å…ˆæ˜ç¡®éœ€è¦ä»€ä¹ˆç±»å‹çš„æ•°æ®
2. **æ•°æ®éªŒè¯**: ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§
3. **åˆ†ææ–¹æ³•**: é€‰æ‹©åˆé€‚çš„åˆ†æå·¥å…·å’Œæ–¹æ³•
4. **ç»“æœè§£è¯»**: æ­£ç¡®ç†è§£åˆ†æç»“æœçš„å«ä¹‰

å¦‚æœæ‚¨éœ€è¦æ›´å…·ä½“çš„å¸®åŠ©ï¼Œè¯·æä¾›æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œæˆ‘å°†ä¸ºæ‚¨æä¾›æ›´ç²¾å‡†çš„å»ºè®®ã€‚"""
    
    else:
        return f"""æ„Ÿè°¢æ‚¨çš„é—®é¢˜ï¼š"{message}"

æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œå»ºè®®æ‚¨å¯ä»¥ï¼š

1. **æ˜ç¡®ç›®æ ‡**: è¿›ä¸€æ­¥æ˜ç¡®æ‚¨æƒ³è¦è§£å†³çš„å…·ä½“é—®é¢˜
2. **æ”¶é›†ä¿¡æ¯**: æŸ¥æ‰¾ç›¸å…³çš„èµ„æ–™å’Œæ•°æ®
3. **å¤šæ–¹å’¨è¯¢**: å¯»æ±‚ä¸“ä¸šäººå£«çš„æ„è§å’Œå»ºè®®
4. **å®è·µéªŒè¯**: é€šè¿‡å®é™…æ“ä½œæ¥éªŒè¯æ–¹æ¡ˆçš„å¯è¡Œæ€§

å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šèƒŒæ™¯ä¿¡æ¯ï¼Œæˆ‘å°†èƒ½å¤Ÿä¸ºæ‚¨æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„å¸®åŠ©ã€‚"""

# æ–°å¢ï¼šAIæ™ºèƒ½æ­¥éª¤ç”Ÿæˆå‡½æ•°
async def generate_smart_analysis_steps(message: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆåˆ†ææ­¥éª¤"""
    try:
        # æ„å»ºæ­¥éª¤ç”Ÿæˆæç¤ºè¯
        step_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æŠ•èµ„åˆ†æAIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜çš„å¤æ‚ç¨‹åº¦ï¼Œè®¾è®¡åˆé€‚æ•°é‡çš„æ‰§è¡Œæ­¥éª¤ï¼ˆé€šå¸¸2-6ä¸ªæ­¥éª¤ï¼‰ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{message}

è¯·åˆ†æé—®é¢˜å¤æ‚åº¦å¹¶å†³å®šæ­¥éª¤æ•°é‡ï¼š
- ç®€å•é—®é¢˜ï¼ˆå¦‚å•ä¸€æ¦‚å¿µè§£é‡Šï¼‰ï¼š2-3ä¸ªæ­¥éª¤
- ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚å•åªè‚¡ç¥¨åˆ†æï¼‰ï¼š3-4ä¸ªæ­¥éª¤  
- å¤æ‚é—®é¢˜ï¼ˆå¦‚è¡Œä¸šåˆ†æã€ç­–ç•¥åˆ¶å®šï¼‰ï¼š4-6ä¸ªæ­¥éª¤

æ¯ä¸ªæ­¥éª¤å¿…é¡»åŒ…å«ï¼š
1. content: å…·ä½“çš„æ‰§è¡Œæè¿°ï¼ˆæ˜ç¡®è¯´æ˜è¦åšä»€ä¹ˆï¼Œä¸è¦ç”¨"æ­£åœ¨æ€è€ƒ"ç­‰æ¨¡ç³Šè¯æ±‡ï¼‰
2. resourceType: browserï¼ˆç½‘ç»œæœç´¢ï¼‰/databaseï¼ˆæ•°æ®æŸ¥è¯¢ï¼‰/apiï¼ˆAIåˆ†æï¼‰/generalï¼ˆé€šç”¨å¤„ç†ï¼‰
3. results: è¯¥æ­¥éª¤çš„é¢„æœŸäº§å‡º
4. executionDetails: æ‰§è¡Œçš„æŠ€æœ¯ç»†èŠ‚
5. urls: ç›¸å…³é“¾æ¥ï¼ˆé€šå¸¸ä¸ºç©ºæ•°ç»„ï¼‰
6. files: ç›¸å…³æ–‡ä»¶ï¼ˆé€šå¸¸ä¸ºç©ºæ•°ç»„ï¼‰

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ï¼Œæ ¹æ®é—®é¢˜å®é™…éœ€è¦ç¡®å®šæ­¥éª¤æ•°é‡ï¼š

[
  {{
    "content": "è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å’Œè´¢åŠ¡æ•°æ®",
    "resourceType": "database", 
    "results": ["åŸºæœ¬ä¿¡æ¯", "è´¢åŠ¡æŒ‡æ ‡"],
    "executionDetails": {{"dataSource": "è‚¡ç¥¨æ•°æ®åº“", "queryType": "åŸºç¡€æ•°æ®"}},
    "urls": [],
    "files": []
  }}
]
"""
        
        # è°ƒç”¨AIç”Ÿæˆæ­¥éª¤
        ai_response = await asyncio.get_event_loop().run_in_executor(
            None, 
            lambda: qwen_analyzer.analyze_text(step_prompt, max_tokens=1000)
        )
        
        if ai_response:
            try:
                # å°è¯•è§£æJSONå“åº”
                import re
                json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
                if json_match:
                    steps_data = json.loads(json_match.group())
                    return steps_data
            except:
                pass
        
        # æ ¹æ®ç”¨æˆ·é—®é¢˜ç”Ÿæˆæ›´å…·ä½“çš„é»˜è®¤åˆ†ææ­¥éª¤
        user_msg_lower = message.lower()
        
        # åˆ†æé—®é¢˜å¤æ‚åº¦
        def get_complexity_level():
            # ç®€å•é—®é¢˜æ ‡è¯†
            simple_indicators = ['æ˜¯ä»€ä¹ˆ', 'å®šä¹‰', 'è§£é‡Š', 'æ¦‚å¿µ', 'ç®€å•']
            # å¤æ‚é—®é¢˜æ ‡è¯†  
            complex_indicators = ['è¡Œä¸š', 'æ¿å—', 'æ¯”è¾ƒ', 'ç­–ç•¥', 'ç»„åˆ', 'æ·±åº¦', 'å…¨é¢', 'è¯¦ç»†']
            
            if any(indicator in user_msg_lower for indicator in simple_indicators):
                return 'simple'  # 2-3æ­¥
            elif any(indicator in user_msg_lower for indicator in complex_indicators):
                return 'complex'  # 4-6æ­¥
            else:
                return 'medium'   # 3-4æ­¥
        
        complexity = get_complexity_level()
        
        # æ£€æµ‹ç”¨æˆ·é—®é¢˜ç±»å‹ï¼Œç”Ÿæˆé’ˆå¯¹æ€§çš„æ­¥éª¤
        if any(keyword in user_msg_lower for keyword in ['è‚¡ç¥¨', 'ä»£ç ', '000', '300', '600']):
            # è‚¡ç¥¨åˆ†æç±»æ­¥éª¤
            if complexity == 'simple':
                # ç®€å•è‚¡ç¥¨æŸ¥è¯¢ï¼š2-3æ­¥ï¼Œæ¯æ­¥éƒ½æœ‰å®é™…èµ„æº
                return [
                    {
                        "content": f"æœç´¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼š{message[:20]}...",
                        "resourceType": "browser",
                        "results": ["è‚¡ç¥¨åŸºæœ¬é¢", "å®æ—¶ä»·æ ¼"],
                        "executionDetails": {"taskType": "è‚¡ç¥¨æŸ¥è¯¢", "complexity": "ç®€å•"},
                        "urls": [
                            "https://finance.sina.com.cn",
                            "https://quote.eastmoney.com",
                            "https://xueqiu.com"
                        ],
                        "files": []
                    },
                    {
                        "content": "AIç”Ÿæˆç®€è¦åˆ†æç»“è®ºå¹¶åˆ¶ä½œå›¾è¡¨",
                        "resourceType": "api",
                        "results": ["åŸºç¡€è¯„ä¼°", "ç®€è¦å»ºè®®", "ä»·æ ¼è¶‹åŠ¿å›¾"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "analysisType": "å¿«é€Ÿåˆ†æ"},
                        "urls": [],
                        "files": ["è‚¡ç¥¨ä»·æ ¼è¶‹åŠ¿å›¾.png", "åŸºæœ¬é¢åˆ†ææŠ¥å‘Š.pdf"]
                    }
                ]
            elif complexity == 'complex':
                # æ·±åº¦è‚¡ç¥¨åˆ†æï¼š5-6æ­¥ï¼Œæ¯æ­¥éƒ½æœ‰ä¸°å¯Œèµ„æº
                return [
                    {
                        "content": f"å…¨é¢æœç´¢è‚¡ç¥¨ä¿¡æ¯ï¼š{message[:20]}...",
                        "resourceType": "browser",
                        "results": ["éœ€æ±‚æ¡†æ¶", "åˆ†æç»´åº¦"],
                        "executionDetails": {"taskType": "è‚¡ç¥¨æ·±åº¦åˆ†æ", "complexity": "å¤æ‚"},
                        "urls": [
                            "https://finance.sina.com.cn",
                            "https://quote.eastmoney.com", 
                            "https://data.eastmoney.com",
                            "https://xueqiu.com"
                        ],
                        "files": []
                    },
                    {
                        "content": "è·å–è‚¡ç¥¨åŸºç¡€æ•°æ®å’Œè´¢åŠ¡æŒ‡æ ‡",
                        "resourceType": "database",
                        "results": ["åŸºæœ¬ä¿¡æ¯", "è´¢åŠ¡æ•°æ®", "å†å²ä»·æ ¼"],
                        "executionDetails": {"dataSource": "è‚¡ç¥¨æ•°æ®åº“", "scope": "å…¨é¢æ•°æ®"},
                        "urls": [
                            "https://data.eastmoney.com/bbsj/",
                            "https://finance.sina.com.cn/realstock/"
                        ],
                        "files": ["è´¢åŠ¡æ•°æ®æŠ¥è¡¨.xlsx"]
                    },
                    {
                        "content": "æœç´¢ç›¸å…³æ–°é—»å’Œå¸‚åœºåŠ¨æ€",
                        "resourceType": "browser",
                        "results": ["æœ€æ–°æ–°é—»", "è¡Œä¸šåŠ¨æ€", "å¸‚åœºæƒ…ç»ª"],
                        "executionDetails": {"source": "è´¢ç»åª’ä½“", "focus": "å®æ—¶èµ„è®¯"},
                        "urls": [
                            "https://finance.sina.com.cn/news/",
                            "https://finance.qq.com/",
                            "https://www.21jingji.com/",
                            "https://wallstreetcn.com/"
                        ],
                        "files": ["æ–°é—»æ‘˜è¦.pdf"]
                    },
                    {
                        "content": "AIæ·±åº¦æŠ€æœ¯å’ŒåŸºæœ¬é¢åˆ†æ",
                        "resourceType": "api",
                        "results": ["æŠ€æœ¯æŒ‡æ ‡", "è´¢åŠ¡åˆ†æ", "ä¼°å€¼æ¨¡å‹"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "analysisType": "æ·±åº¦åˆ†æ"},
                        "urls": [
                            "https://data.eastmoney.com/zjlx/",
                            "https://finance.sina.com.cn/realstock/company/"
                        ],
                        "files": ["æŠ€æœ¯åˆ†æå›¾è¡¨.png", "ä¼°å€¼æ¨¡å‹.xlsx"]
                    },
                    {
                        "content": "ç”Ÿæˆè¯¦ç»†æŠ•èµ„å»ºè®®æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨",
                        "resourceType": "general",
                        "results": ["æŠ•èµ„è¯„çº§", "ç›®æ ‡ä»·ä½", "é£é™©æç¤º", "æ“ä½œå»ºè®®", "ç»¼åˆå›¾è¡¨"],
                        "executionDetails": {"reportType": "æ·±åº¦åˆ†ææŠ¥å‘Š"},
                        "urls": [],
                        "files": ["æŠ•èµ„åˆ†ææŠ¥å‘Š.pdf", "è‚¡ä»·é¢„æµ‹å›¾è¡¨.png", "é£é™©æ”¶ç›Šåˆ†æå›¾.png"]
                    }
                ]
            else:
                # ä¸­ç­‰å¤æ‚åº¦ï¼š3-4æ­¥ï¼Œé€‚é‡èµ„æº
                return [
                    {
                        "content": f"æœç´¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼š{message[:20]}...",
                        "resourceType": "browser",
                        "results": ["éœ€æ±‚ç†è§£", "åˆ†æè¦ç‚¹"],
                        "executionDetails": {"taskType": "è‚¡ç¥¨åˆ†æ", "complexity": "ä¸­ç­‰"},
                        "urls": [
                            "https://finance.sina.com.cn",
                            "https://quote.eastmoney.com"
                        ],
                        "files": []
                    },
                    {
                        "content": "æŸ¥è¯¢è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å’Œå®æ—¶è¡Œæƒ…æ•°æ®",
                        "resourceType": "database",
                        "results": ["è‚¡ç¥¨åŸºæœ¬é¢", "å®æ—¶ä»·æ ¼", "æˆäº¤é‡"],
                        "executionDetails": {"dataSource": "è‚¡ç¥¨æ•°æ®åº“", "queryType": "å®æ—¶æ•°æ®"},
                        "urls": [
                            "https://data.eastmoney.com/hsgt/"
                        ],
                        "files": ["å®æ—¶è¡Œæƒ…æ•°æ®.csv"]
                    },
                    {
                        "content": "è°ƒç”¨AIå¼•æ“è¿›è¡Œæ™ºèƒ½åˆ†æ",
                        "resourceType": "api",
                        "results": ["æŠ€æœ¯æŒ‡æ ‡", "è¶‹åŠ¿åˆ†æ", "AIè¯„åˆ†"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "analysisType": "æŠ€æœ¯+åŸºæœ¬é¢"},
                        "urls": [],
                        "files": ["åˆ†æå›¾è¡¨.png"]
                    },
                    {
                        "content": "æ•´åˆåˆ†ææ•°æ®ï¼Œç”ŸæˆæŠ•èµ„å»ºè®®æŠ¥å‘Š",
                        "resourceType": "general",
                        "results": ["ç»¼åˆè¯„çº§", "æŠ•èµ„å»ºè®®", "é£é™©æç¤º", "è¶‹åŠ¿å›¾è¡¨"],
                        "executionDetails": {"reportType": "ç»¼åˆåˆ†ææŠ¥å‘Š"},
                        "urls": [],
                        "files": ["æŠ•èµ„å»ºè®®æŠ¥å‘Š.pdf", "ä»·æ ¼è¶‹åŠ¿é¢„æµ‹å›¾.png"]
                    }
                ]
        elif any(keyword in user_msg_lower for keyword in ['æ¿å—', 'è¡Œä¸š', 'é¢†åŸŸ']):
            # è¡Œä¸šæ¿å—åˆ†ææ­¥éª¤ï¼ˆå¤æ‚åº¦å¤©ç„¶è¾ƒé«˜ï¼‰
            if complexity == 'simple':
                # ç®€å•è¡Œä¸šæ¦‚è§ˆï¼š2-3æ­¥ï¼ŒåŒ…å«å®é™…èµ„æº
                return [
                    {
                        "content": f"æœç´¢è¡Œä¸šåŸºæœ¬ä¿¡æ¯ï¼š{message[:20]}...",
                        "resourceType": "browser", 
                        "results": ["è¡Œä¸šå®šä½", "åŸºæœ¬æ¦‚å†µ"],
                        "executionDetails": {"taskType": "è¡Œä¸šæ¦‚è§ˆ", "complexity": "ç®€å•"},
                        "urls": [
                            "https://finance.sina.com.cn/stock/",
                            "https://data.eastmoney.com/bkzj/",
                            "https://www.cninfo.com.cn/"
                        ],
                        "files": []
                    },
                    {
                        "content": "AIç”Ÿæˆè¡Œä¸šåŸºç¡€åˆ†æå’Œå›¾è¡¨",
                        "resourceType": "api",
                        "results": ["è¡Œä¸šç‰¹ç‚¹", "åŸºæœ¬å‰æ™¯", "è¡Œä¸šå¯¹æ¯”å›¾"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "analysisType": "è¡Œä¸šæ¦‚è§ˆ"},
                        "urls": [],
                        "files": ["è¡Œä¸šæ¦‚è§ˆå›¾è¡¨.png", "è¡Œä¸šåˆ†ææŠ¥å‘Š.pdf"]
                    }
                ]
            else:
                # ä¸­ç­‰å¤æ‚åº¦ä»¥ä¸Šï¼š4-6æ­¥ï¼Œä¸°å¯Œèµ„æº
                steps = [
                    {
                        "content": f"å…¨é¢æœç´¢è¡Œä¸šä¿¡æ¯ï¼š{message[:20]}...",
                        "resourceType": "browser", 
                        "results": ["è¡Œä¸šå®šä½", "åˆ†æèŒƒå›´"],
                        "executionDetails": {"taskType": "è¡Œä¸šåˆ†æ", "complexity": complexity},
                        "urls": [
                            "https://finance.sina.com.cn/stock/",
                            "https://data.eastmoney.com/bkzj/",
                            "https://www.cninfo.com.cn/",
                            "https://www.21jingji.com/"
                        ],
                        "files": []
                    },
                    {
                        "content": "æœç´¢è¡Œä¸šç›¸å…³ä¿¡æ¯å’Œæœ€æ–°åŠ¨æ€",
                        "resourceType": "browser",
                        "results": ["è¡Œä¸šæ–°é—»", "æ”¿ç­–åŠ¨å‘", "å¸‚åœºçƒ­ç‚¹"],
                        "executionDetails": {"source": "è´¢ç»ç½‘ç«™", "keywords": "è¡Œä¸šåˆ†æ"},
                        "urls": [
                            "https://finance.sina.com.cn/news/",
                            "https://finance.qq.com/",
                            "https://wallstreetcn.com/",
                            "https://www.yicai.com/"
                        ],
                        "files": ["è¡Œä¸šæ–°é—»æ‘˜è¦.pdf"]
                    },
                    {
                        "content": "è·å–è¡Œä¸šå†…é‡ç‚¹è‚¡ç¥¨æ•°æ®",
                        "resourceType": "database",
                        "results": ["é¾™å¤´è‚¡ç¥¨", "è¡Œä¸šæŒ‡æ•°", "æ¿å—èµ„é‡‘æµå‘"],
                        "executionDetails": {"dataSource": "è¡Œä¸šæ•°æ®åº“"},
                        "urls": [
                            "https://data.eastmoney.com/bkzj/",
                            "https://finance.sina.com.cn/realstock/company/"
                        ],
                        "files": ["è¡Œä¸šè‚¡ç¥¨æ•°æ®.xlsx", "èµ„é‡‘æµå‘å›¾.png"]
                    },
                    {
                        "content": "AIæ·±åº¦åˆ†æè¡Œä¸šæŠ•èµ„ä»·å€¼",
                        "resourceType": "api",
                        "results": ["è¡Œä¸šå‰æ™¯", "æŠ•èµ„æœºä¼š", "é£é™©å› ç´ ", "å¯¹æ¯”å›¾è¡¨"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "focus": "è¡Œä¸šæŠ•èµ„ä»·å€¼"},
                        "urls": [
                            "https://data.eastmoney.com/zjlx/"
                        ],
                        "files": ["è¡Œä¸šåˆ†æå›¾è¡¨.png", "æŠ•èµ„ä»·å€¼è¯„ä¼°.pdf"]
                    }
                ]
                
                # å¤æ‚åˆ†æå¢åŠ é¢å¤–æ­¥éª¤
                if complexity == 'complex':
                    steps.extend([
                        {
                            "content": "åˆ†æè¡Œä¸šç«äº‰æ ¼å±€å’Œäº§ä¸šé“¾",
                            "resourceType": "database",
                            "results": ["ç«äº‰æ ¼å±€", "äº§ä¸šé“¾åˆ†æ", "ä¾›éœ€å…³ç³»"],
                            "executionDetails": {"dataSource": "äº§ä¸šæ•°æ®åº“", "scope": "å…¨äº§ä¸šé“¾"},
                            "urls": [
                                "https://www.chyxx.com/",
                                "https://www.askci.com/"
                            ],
                            "files": ["äº§ä¸šé“¾åˆ†æå›¾.png", "ç«äº‰æ ¼å±€æŠ¥å‘Š.pdf"]
                        },
                        {
                            "content": "ç”Ÿæˆè¡Œä¸šæŠ•èµ„ç­–ç•¥å’Œé…ç½®å»ºè®®",
                            "resourceType": "general",
                            "results": ["æŠ•èµ„ç­–ç•¥", "æ ‡çš„æ¨è", "é…ç½®æƒé‡", "æ—¶æœºåˆ¤æ–­", "ç­–ç•¥å›¾è¡¨"],
                            "executionDetails": {"reportType": "è¡Œä¸šæŠ•èµ„ç­–ç•¥æŠ¥å‘Š"},
                            "urls": [],
                            "files": ["è¡Œä¸šæŠ•èµ„ç­–ç•¥.pdf", "é…ç½®å»ºè®®å›¾è¡¨.png", "æŠ•èµ„æ—¶æœºåˆ†æå›¾.png"]
                        }
                    ])
                return steps
        elif any(keyword in user_msg_lower for keyword in ['ç­–ç•¥', 'é…ç½®', 'ç»„åˆ']):
            # æŠ•èµ„ç­–ç•¥åˆ¶å®šæ­¥éª¤
            return [
                {
                    "content": f"åˆ†ææŠ•èµ„éœ€æ±‚ï¼š{message[:20]}...",
                    "resourceType": "general",
                    "results": ["æŠ•èµ„ç›®æ ‡", "é£é™©åå¥½"],
                    "executionDetails": {"taskType": "ç­–ç•¥åˆ¶å®š"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "è°ƒç ”å¸‚åœºç¯å¢ƒå’ŒæŠ•èµ„æœºä¼š",
                    "resourceType": "browser",
                    "results": ["å¸‚åœºè¶‹åŠ¿", "çƒ­ç‚¹æœºä¼š", "ä¸“å®¶è§‚ç‚¹"],
                    "executionDetails": {"source": "è´¢ç»åª’ä½“", "focus": "æŠ•èµ„æœºä¼š"},
                    "urls": [
                        "https://finance.sina.com.cn/news/",
                        "https://wallstreetcn.com/",
                        "https://www.yicai.com/"
                    ],
                    "files": []
                },
                {
                    "content": "æ„å»ºé‡åŒ–åˆ†ææ¨¡å‹",
                    "resourceType": "api",
                    "results": ["é‡åŒ–æŒ‡æ ‡", "é£é™©è¯„ä¼°", "æ”¶ç›Šé¢„æµ‹"],
                    "executionDetails": {"model": "é‡åŒ–åˆ†æ", "method": "AIå»ºæ¨¡"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "åˆ¶å®šä¸ªæ€§åŒ–æŠ•èµ„ç­–ç•¥æ–¹æ¡ˆ",
                    "resourceType": "general",
                    "results": ["ç­–ç•¥æ–¹æ¡ˆ", "é…ç½®å»ºè®®", "æ‰§è¡Œè®¡åˆ’"],
                    "executionDetails": {"deliverable": "ç­–ç•¥æŠ¥å‘Š"},
                    "urls": [],
                    "files": []
                }
            ]
        else:
            # é€šç”¨æŠ•èµ„å’¨è¯¢æ­¥éª¤
            return [
                {
                    "content": f"æœç´¢ç›¸å…³æŠ•èµ„ä¿¡æ¯ï¼š{message[:20]}...",
                    "resourceType": "browser",
                    "results": ["æŠ•èµ„ç›®æ ‡", "é£é™©åå¥½"],
                    "executionDetails": {"taskType": "æŠ•èµ„å’¨è¯¢"},
                    "urls": [
                        "https://finance.sina.com.cn/",
                        "https://www.eastmoney.com/",
                        "https://xueqiu.com/"
                    ],
                    "files": []
                },
                {
                    "content": "æ”¶é›†å¸‚åœºä¿¡æ¯å’Œä¸“ä¸šè§‚ç‚¹",
                    "resourceType": "browser",
                    "results": ["å¸‚åœºè¶‹åŠ¿", "æŠ•èµ„æœºä¼š", "ä¸“å®¶è§‚ç‚¹"],
                    "executionDetails": {"source": "è´¢ç»åª’ä½“", "focus": "æŠ•èµ„æœºä¼š"},
                    "urls": [
                        "https://finance.qq.com/",
                        "https://wallstreetcn.com/",
                        "https://www.21jingji.com/",
                        "https://www.yicai.com/"
                    ],
                    "files": ["å¸‚åœºè§‚ç‚¹æ‘˜è¦.pdf"]
                },
                {
                    "content": "è¿ç”¨AIæ™ºèƒ½åˆ†æå¼•æ“",
                    "resourceType": "api",
                    "results": ["æ™ºèƒ½åˆ†æ", "ä¸“ä¸šå»ºè®®", "é£é™©è¯„ä¼°å›¾"],
                    "executionDetails": {"engine": "é€šä¹‰åƒé—®"},
                    "urls": [],
                    "files": ["æ™ºèƒ½åˆ†æå›¾è¡¨.png"]
                },
                {
                    "content": "æä¾›ä¸“ä¸šæŠ•èµ„å’¨è¯¢ç­”æ¡ˆå’Œå¯è§†åŒ–æŠ¥å‘Š",
                    "resourceType": "general",
                    "results": ["ä¸“ä¸šè§£ç­”", "å®ç”¨å»ºè®®", "æŠ•èµ„ç­–ç•¥å›¾"],
                    "executionDetails": {"deliverable": "å’¨è¯¢æŠ¥å‘Š"},
                    "urls": [],
                    "files": ["æŠ•èµ„å’¨è¯¢æŠ¥å‘Š.pdf", "ç­–ç•¥å»ºè®®å›¾è¡¨.png", "é£é™©æ”¶ç›Šåˆ†æ.png"]
                }
            ]
        
    except Exception as e:
        print(f"AIæ­¥éª¤ç”Ÿæˆå¤±è´¥: {e}")
        # è¿”å›é»˜è®¤æ­¥éª¤
        return [
            {
                "content": "å¼€å§‹æ•°æ®åˆ†æ",
                "resourceType": "general",
                "results": [],
                "executionDetails": {},
                "urls": [],
                "files": []
            }
        ]

async def generate_smart_strategy_steps(message: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆç­–ç•¥æ­¥éª¤"""
    try:
        step_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æŠ•èµ„ç­–ç•¥AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚çš„å¤æ‚ç¨‹åº¦ï¼Œè®¾è®¡åˆé€‚æ•°é‡çš„æ‰§è¡Œæ­¥éª¤ï¼ˆé€šå¸¸2-6ä¸ªæ­¥éª¤ï¼‰ï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{message}

è¯·åˆ†æç­–ç•¥å¤æ‚åº¦å¹¶å†³å®šæ­¥éª¤æ•°é‡ï¼š
- ç®€å•ç­–ç•¥ï¼ˆå¦‚åŸºç¡€é…ç½®å»ºè®®ï¼‰ï¼š2-3ä¸ªæ­¥éª¤
- ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚æŠ•èµ„ç»„åˆæ„å»ºï¼‰ï¼š3-4ä¸ªæ­¥éª¤  
- å¤æ‚ç­–ç•¥ï¼ˆå¦‚å¤šèµ„äº§é…ç½®ã€é‡åŒ–ç­–ç•¥ï¼‰ï¼š4-6ä¸ªæ­¥éª¤

æ¯ä¸ªæ­¥éª¤å¿…é¡»åŒ…å«ï¼š
1. content: å…·ä½“çš„ç­–ç•¥æ‰§è¡Œæè¿°
2. resourceType: browserï¼ˆå¸‚åœºè°ƒç ”ï¼‰/databaseï¼ˆæ•°æ®åˆ†æï¼‰/apiï¼ˆAIç­–ç•¥ç”Ÿæˆï¼‰/generalï¼ˆç­–ç•¥æ•´åˆï¼‰
3. results: è¯¥æ­¥éª¤çš„ç­–ç•¥äº§å‡º
4. executionDetails: ç­–ç•¥æ‰§è¡Œçš„æŠ€æœ¯ç»†èŠ‚

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ï¼Œæ ¹æ®ç­–ç•¥å®é™…å¤æ‚åº¦ç¡®å®šæ­¥éª¤æ•°é‡ï¼š

[
  {{
    "content": "åˆ†æå¸‚åœºè¶‹åŠ¿å’ŒæŠ•èµ„æœºä¼š",
    "resourceType": "browser",
    "results": ["å¸‚åœºè¶‹åŠ¿", "æŠ•èµ„æœºä¼š"],
    "executionDetails": {{"method": "å¸‚åœºè°ƒç ”", "scope": "å…¨å¸‚åœºåˆ†æ"}},
    "urls": [],
    "files": []
  }}
]
"""
        
        ai_response = await asyncio.get_event_loop().run_in_executor(
            None, 
            lambda: qwen_analyzer.analyze_text(step_prompt, max_tokens=1000)
        )
        
        if ai_response:
            try:
                import re
                json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
                if json_match:
                    steps_data = json.loads(json_match.group())
                    return steps_data
            except:
                pass
        
        # æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæ›´å…·ä½“çš„é»˜è®¤ç­–ç•¥æ­¥éª¤
        user_msg_lower = message.lower()
        
        if any(keyword in user_msg_lower for keyword in ['é…ç½®', 'ç»„åˆ', 'èµ„äº§']):
            # èµ„äº§é…ç½®ç­–ç•¥
            return [
                {
                    "content": f"åˆ†æé…ç½®éœ€æ±‚ï¼š{message[:20]}...",
                    "resourceType": "general",
                    "results": ["é…ç½®ç›®æ ‡", "çº¦æŸæ¡ä»¶"],
                    "executionDetails": {"strategyType": "èµ„äº§é…ç½®"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "ç ”ç©¶å„ç±»èµ„äº§çš„å†å²è¡¨ç°",
                    "resourceType": "database",
                    "results": ["å†å²æ”¶ç›Š", "æ³¢åŠ¨æ€§åˆ†æ", "ç›¸å…³æ€§æ•°æ®"],
                    "executionDetails": {"dataSource": "èµ„äº§æ•°æ®åº“", "period": "å†å²æ•°æ®"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "è¿ç”¨AIä¼˜åŒ–é…ç½®æ¨¡å‹",
                    "resourceType": "api",
                    "results": ["æœ€ä¼˜æƒé‡", "é£é™©æ”¶ç›Šæ¯”", "é…ç½®å»ºè®®"],
                    "executionDetails": {"model": "èµ„äº§é…ç½®æ¨¡å‹", "optimizer": "AIç®—æ³•"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "åˆ¶å®šåŠ¨æ€è°ƒæ•´ç­–ç•¥å’Œç›‘æ§æ–¹æ¡ˆ",
                    "resourceType": "general",
                    "results": ["è°ƒæ•´è§„åˆ™", "ç›‘æ§æŒ‡æ ‡", "æ‰§è¡Œæ—¶é—´è¡¨"],
                    "executionDetails": {"deliverable": "é…ç½®ç­–ç•¥æ–¹æ¡ˆ"},
                    "urls": [],
                    "files": []
                }
            ]
        elif any(keyword in user_msg_lower for keyword in ['é‡åŒ–', 'ç®—æ³•', 'æ¨¡å‹']):
            # é‡åŒ–ç­–ç•¥
            return [
                {
                    "content": f"è®¾è®¡é‡åŒ–ç­–ç•¥æ¡†æ¶ï¼š{message[:20]}...",
                    "resourceType": "general",
                    "results": ["ç­–ç•¥é€»è¾‘", "å‚æ•°è®¾ç½®"],
                    "executionDetails": {"strategyType": "é‡åŒ–ç­–ç•¥"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "è·å–å†å²æ•°æ®è¿›è¡Œå›æµ‹",
                    "resourceType": "database",
                    "results": ["ä»·æ ¼æ•°æ®", "æŒ‡æ ‡æ•°æ®", "å›æµ‹ç»“æœ"],
                    "executionDetails": {"dataSource": "é‡åŒ–æ•°æ®åº“", "method": "å†å²å›æµ‹"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "AIä¼˜åŒ–ç­–ç•¥å‚æ•°",
                    "resourceType": "api", 
                    "results": ["æœ€ä¼˜å‚æ•°", "ç»©æ•ˆè¯„ä¼°", "é£é™©æŒ‡æ ‡"],
                    "executionDetails": {"optimizer": "AIå‚æ•°ä¼˜åŒ–", "method": "æœºå™¨å­¦ä¹ "},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "ç”Ÿæˆé‡åŒ–ç­–ç•¥æ‰§è¡Œæ–¹æ¡ˆ",
                    "resourceType": "general",
                    "results": ["äº¤æ˜“ä¿¡å·", "é£æ§è§„åˆ™", "å®ç›˜å»ºè®®"],
                    "executionDetails": {"deliverable": "é‡åŒ–ç­–ç•¥æŠ¥å‘Š"},
                    "urls": [],
                    "files": []
                }
            ]
        else:
            # é€šç”¨æŠ•èµ„ç­–ç•¥
            return [
                {
                    "content": f"åˆ¶å®šæŠ•èµ„ç­–ç•¥ç›®æ ‡ï¼š{message[:20]}...",
                    "resourceType": "general",
                    "results": ["æŠ•èµ„ç›®æ ‡", "é£é™©åå¥½"],
                    "executionDetails": {"strategyType": "æŠ•èµ„ç­–ç•¥"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "ç ”ç©¶å¸‚åœºæœºä¼šå’Œè¶‹åŠ¿",
                    "resourceType": "browser",
                    "results": ["å¸‚åœºè¶‹åŠ¿", "æŠ•èµ„æœºä¼š", "ä¸“å®¶è§‚ç‚¹"],
                    "executionDetails": {"source": "æŠ•ç ”æŠ¥å‘Š", "focus": "å¸‚åœºæœºä¼š"},
                    "urls": [
                        "https://finance.qq.com/",
                        "https://wallstreetcn.com/",
                        "https://www.yicai.com/"
                    ],
                    "files": []
                },
                {
                    "content": "AIæ™ºèƒ½ç­›é€‰æŠ•èµ„æ ‡çš„",
                    "resourceType": "api",
                    "results": ["æ¨èæ ‡çš„", "è¯„åˆ†æ’å", "æŠ•èµ„é€»è¾‘"],
                    "executionDetails": {"engine": "AIç­›é€‰ç®—æ³•", "criteria": "å¤šå› å­æ¨¡å‹"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "åˆ¶å®šå®Œæ•´æŠ•èµ„ç­–ç•¥æ–¹æ¡ˆ",
                    "resourceType": "general",
                    "results": ["ç­–ç•¥æ–¹æ¡ˆ", "ä»“ä½ç®¡ç†", "é£é™©æ§åˆ¶"],
                    "executionDetails": {"deliverable": "æŠ•èµ„ç­–ç•¥æŠ¥å‘Š"},
                    "urls": [],
                    "files": []
                }
            ]
        
    except Exception as e:
        print(f"AIç­–ç•¥æ­¥éª¤ç”Ÿæˆå¤±è´¥: {e}")
        return [
            {
                "content": "å¼€å§‹ç­–ç•¥åˆ¶å®š",
                "resourceType": "general",
                "results": [],
                "executionDetails": {},
                "urls": [],
                "files": []
            }
        ]

async def generate_smart_general_steps(message: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä½¿ç”¨AIæ™ºèƒ½ç”Ÿæˆé€šç”¨æ­¥éª¤"""
    try:
        step_prompt = f"""
ä½œä¸ºæ™ºèƒ½AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜çš„å¤æ‚ç¨‹åº¦ï¼Œè®¾è®¡åˆé€‚æ•°é‡çš„æ‰§è¡Œæ­¥éª¤ï¼ˆé€šå¸¸2-5ä¸ªæ­¥éª¤ï¼‰ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{message}

è¯·åˆ†æé—®é¢˜å¤æ‚åº¦å¹¶å†³å®šæ­¥éª¤æ•°é‡ï¼š
- ç®€å•é—®é¢˜ï¼ˆå¦‚æ¦‚å¿µè§£é‡Šã€åŸºç¡€æŸ¥è¯¢ï¼‰ï¼š2-3ä¸ªæ­¥éª¤
- ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚æ“ä½œæŒ‡å¯¼ã€æ¯”è¾ƒåˆ†æï¼‰ï¼š3-4ä¸ªæ­¥éª¤  
- å¤æ‚é—®é¢˜ï¼ˆå¦‚ç»¼åˆç ”ç©¶ã€å¤šç»´åˆ†æï¼‰ï¼š4-5ä¸ªæ­¥éª¤

æ¯ä¸ªæ­¥éª¤å¿…é¡»åŒ…å«ï¼š
1. content: å…·ä½“çš„æ‰§è¡Œæè¿°ï¼ˆè¯´æ˜è¦åšä»€ä¹ˆå…·ä½“æ“ä½œï¼‰
2. resourceType: browserï¼ˆä¿¡æ¯æœç´¢ï¼‰/databaseï¼ˆæ•°æ®æŸ¥è¯¢ï¼‰/apiï¼ˆAIåˆ†æï¼‰/generalï¼ˆé€šç”¨å¤„ç†ï¼‰
3. results: è¯¥æ­¥éª¤çš„é¢„æœŸäº§å‡º
4. executionDetails: æ‰§è¡Œçš„æŠ€æœ¯ç»†èŠ‚

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ï¼Œæ ¹æ®é—®é¢˜å®é™…å¤æ‚åº¦ç¡®å®šæ­¥éª¤æ•°é‡ã€‚
"""
        
        ai_response = await asyncio.get_event_loop().run_in_executor(
            None, 
            lambda: qwen_analyzer.analyze_text(step_prompt, max_tokens=800)
        )
        
        if ai_response:
            try:
                import re
                json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
                if json_match:
                    steps_data = json.loads(json_match.group())
                    return steps_data
            except:
                pass
        
        # æ ¹æ®ç”¨æˆ·é—®é¢˜ç”Ÿæˆæ›´å…·ä½“çš„é»˜è®¤é€šç”¨æ­¥éª¤
        user_msg_lower = message.lower()
        
        if any(keyword in user_msg_lower for keyword in ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ–¹æ³•', 'æ­¥éª¤']):
            # æ“ä½œæŒ‡å¯¼ç±»é—®é¢˜
            return [
                {
                    "content": f"åˆ†ææ“ä½œéœ€æ±‚ï¼š{message[:25]}...",
                    "resourceType": "general",
                    "results": ["éœ€æ±‚ç†è§£", "æ“ä½œæ¡†æ¶"],
                    "executionDetails": {"questionType": "æ“ä½œæŒ‡å¯¼"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "æœç´¢ç›¸å…³æ“ä½œæŒ‡å—å’Œæœ€ä½³å®è·µ",
                    "resourceType": "browser",
                    "results": ["æ“ä½œæŒ‡å—", "å®è·µæ¡ˆä¾‹", "ä¸“å®¶å»ºè®®"],
                    "executionDetails": {"source": "ä¸“ä¸šæŒ‡å—", "focus": "å®ç”¨æ–¹æ³•"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "AIæ™ºèƒ½æ•´ç†æ“ä½œæ­¥éª¤",
                    "resourceType": "api",
                    "results": ["è¯¦ç»†æ­¥éª¤", "æ³¨æ„äº‹é¡¹", "é£é™©æç¤º"],
                    "executionDetails": {"engine": "é€šä¹‰åƒé—®", "outputType": "æ“ä½œæŒ‡å—"},
                    "urls": [],
                    "files": []
                }
            ]
        elif any(keyword in user_msg_lower for keyword in ['ä»€ä¹ˆ', 'å®šä¹‰', 'è§£é‡Š', 'æ¦‚å¿µ']):
            # æ¦‚å¿µè§£é‡Šç±»é—®é¢˜
            return [
                {
                    "content": f"è¯†åˆ«å…³é”®æ¦‚å¿µï¼š{message[:25]}...",
                    "resourceType": "general",
                    "results": ["æ¦‚å¿µè¯†åˆ«", "è§£é‡Šç»´åº¦"],
                    "executionDetails": {"questionType": "æ¦‚å¿µè§£é‡Š"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "æŸ¥æ‰¾æƒå¨å®šä¹‰å’Œä¸“ä¸šè§£é‡Š",
                    "resourceType": "browser",
                    "results": ["æƒå¨å®šä¹‰", "ä¸“ä¸šè§£é‡Š", "å®é™…åº”ç”¨"],
                    "executionDetails": {"source": "ä¸“ä¸šèµ„æ–™", "focus": "å‡†ç¡®å®šä¹‰"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "AIç”Ÿæˆé€šä¿—æ˜“æ‡‚çš„è§£é‡Š",
                    "resourceType": "api",
                    "results": ["ç®€æ˜è§£é‡Š", "å®ä¾‹è¯´æ˜", "ç›¸å…³çŸ¥è¯†"],
                    "executionDetails": {"engine": "é€šä¹‰åƒé—®", "style": "é€šä¿—æ˜“æ‡‚"},
                    "urls": [],
                    "files": []
                }
            ]
        elif any(keyword in user_msg_lower for keyword in ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'åŒºåˆ«', 'é€‰æ‹©']):
            # æ¯”è¾ƒé€‰æ‹©ç±»é—®é¢˜
            return [
                {
                    "content": f"æ˜ç¡®æ¯”è¾ƒå¯¹è±¡ï¼š{message[:25]}...",
                    "resourceType": "general",
                    "results": ["æ¯”è¾ƒç»´åº¦", "è¯„ä¼°æ ‡å‡†"],
                    "executionDetails": {"questionType": "æ¯”è¾ƒåˆ†æ"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "æ”¶é›†å„æ–¹é¢çš„è¯¦ç»†ä¿¡æ¯",
                    "resourceType": "browser",
                    "results": ["è¯¦ç»†ä¿¡æ¯", "å®¢è§‚æ•°æ®", "ç”¨æˆ·è¯„ä»·"],
                    "executionDetails": {"source": "å¤šæ¸ é“ä¿¡æ¯", "method": "å…¨é¢è°ƒç ”"},
                    "urls": [],
                    "files": []
                },
                {
                    "content": "AIæ™ºèƒ½å¯¹æ¯”åˆ†æå’Œå»ºè®®",
                    "resourceType": "api",
                    "results": ["å¯¹æ¯”è¡¨æ ¼", "ä¼˜ç¼ºç‚¹åˆ†æ", "é€‰æ‹©å»ºè®®"],
                    "executionDetails": {"engine": "é€šä¹‰åƒé—®", "outputType": "å¯¹æ¯”åˆ†æ"},
                    "urls": [],
                    "files": []
                }
            ]
        else:
            # é€šç”¨å’¨è¯¢ç±»é—®é¢˜
            if complexity == 'simple':
                # ç®€å•é—®é¢˜ï¼š2æ­¥å³å¯
                return [
                    {
                        "content": f"ç†è§£é—®é¢˜éœ€æ±‚ï¼š{message[:25]}...",
                        "resourceType": "general",
                        "results": ["é—®é¢˜åˆ†æ"],
                        "executionDetails": {"questionType": "ç®€å•å’¨è¯¢", "complexity": "ç®€å•"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "AIå¿«é€Ÿç”Ÿæˆè§£ç­”",
                        "resourceType": "api",
                        "results": ["ç›´æ¥è§£ç­”"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "style": "å¿«é€Ÿå‡†ç¡®"},
                        "urls": [],
                        "files": []
                    }
                ]
            elif complexity == 'complex':
                # å¤æ‚é—®é¢˜ï¼š4-5æ­¥
                return [
                    {
                        "content": f"æ·±åº¦ç†è§£é—®é¢˜èƒŒæ™¯ï¼š{message[:25]}...",
                        "resourceType": "general",
                        "results": ["é—®é¢˜åˆ†æ", "èƒŒæ™¯ç ”ç©¶", "è§£ç­”æ¡†æ¶"],
                        "executionDetails": {"questionType": "å¤æ‚å’¨è¯¢", "complexity": "å¤æ‚"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "å…¨é¢æœç´¢ç›¸å…³çŸ¥è¯†å’Œèµ„æ–™",
                        "resourceType": "browser",
                        "results": ["æƒå¨èµ„æ–™", "æœ€æ–°ä¿¡æ¯", "å¤šè§’åº¦è§‚ç‚¹"],
                        "executionDetails": {"source": "å…¨ç½‘æœç´¢", "scope": "å¤šç»´åº¦ä¿¡æ¯"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "æ”¶é›†ä¸“ä¸šæ•°æ®å’Œæ¡ˆä¾‹",
                        "resourceType": "database",
                        "results": ["ä¸“ä¸šæ•°æ®", "å®é™…æ¡ˆä¾‹", "ç»Ÿè®¡ä¿¡æ¯"],
                        "executionDetails": {"dataSource": "ä¸“ä¸šæ•°æ®åº“", "focus": "å®è¯æ”¯æ’‘"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "AIæ·±åº¦åˆ†æå’Œç»¼åˆæ•´ç†",
                        "resourceType": "api",
                        "results": ["æ·±åº¦åˆ†æ", "ç»¼åˆç»“è®º", "å®ç”¨å»ºè®®"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "analysisType": "æ·±åº¦ç»¼åˆ"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "ç”Ÿæˆè¯¦ç»†è§£ç­”æŠ¥å‘Š",
                        "resourceType": "general",
                        "results": ["å®Œæ•´è§£ç­”", "å»¶ä¼¸æ€è€ƒ", "è¡ŒåŠ¨å»ºè®®"],
                        "executionDetails": {"deliverable": "ç»¼åˆè§£ç­”æŠ¥å‘Š"},
                        "urls": [],
                        "files": []
                    }
                ]
            else:
                # ä¸­ç­‰å¤æ‚åº¦ï¼š3æ­¥
                return [
                    {
                        "content": f"ç†è§£å’¨è¯¢é—®é¢˜ï¼š{message[:25]}...",
                        "resourceType": "general",
                        "results": ["é—®é¢˜åˆ†æ", "è§£ç­”æ–¹å‘"],
                        "executionDetails": {"questionType": "é€šç”¨å’¨è¯¢", "complexity": "ä¸­ç­‰"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "æœç´¢ç›¸å…³çŸ¥è¯†å’Œä¿¡æ¯",
                        "resourceType": "browser",
                        "results": ["ç›¸å…³çŸ¥è¯†", "æœ€æ–°ä¿¡æ¯", "ä¸“ä¸šè§‚ç‚¹"],
                        "executionDetails": {"source": "çŸ¥è¯†åº“æœç´¢", "scope": "å…¨é¢ä¿¡æ¯"},
                        "urls": [],
                        "files": []
                    },
                    {
                        "content": "AIæ™ºèƒ½ç”Ÿæˆä¸“ä¸šè§£ç­”",
                        "resourceType": "api",
                        "results": ["ä¸“ä¸šè§£ç­”", "å®ç”¨å»ºè®®", "å»¶ä¼¸çŸ¥è¯†"],
                        "executionDetails": {"engine": "é€šä¹‰åƒé—®", "style": "ä¸“ä¸šå‡†ç¡®"},
                        "urls": [],
                        "files": []
                    }
                ]
        
    except Exception as e:
        print(f"AIé€šç”¨æ­¥éª¤ç”Ÿæˆå¤±è´¥: {e}")
        return [
            {
                "content": "å¼€å§‹å¤„ç†è¯·æ±‚",
                "resourceType": "general",
                "results": [],
                "executionDetails": {},
                "urls": [],
                "files": []
            }
        ]

async def generate_ai_response(message: str, context: Dict[str, Any] = None):
    """ç”ŸæˆAIå›å¤ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
    try:
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„AIå¯¹è¯é€»è¾‘
        if "å·¥ä½œæµç»“æœ" in message:
            return "åŸºäºå·¥ä½œæµåˆ†æç»“æœï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†è¯¦ç»†çš„æŠ•èµ„å»ºè®®æŠ¥å‘Šã€‚"
        else:
            return f"æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ï¼š{message}ã€‚è®©æˆ‘ä¸ºæ‚¨åˆ†æä¸€ä¸‹ç›¸å…³çš„æŠ•èµ„æœºä¼šã€‚"
    except Exception as e:
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"

async def generate_investment_strategies(request: StrategyGenerationRequest):
    """ç”ŸæˆæŠ•èµ„ç­–ç•¥"""
    strategies = []
    
    if request.riskTolerance == "low":
        strategies.append({
            "name": "ç¨³å¥ä»·å€¼æŠ•èµ„ç­–ç•¥",
            "description": "ä¸“æ³¨äºä½ä¼°å€¼ã€é«˜åˆ†çº¢çš„è“ç­¹è‚¡",
            "expectedReturn": "8-12%",
            "riskLevel": "low",
            "stocks": ["000001", "600036", "000002"],
            "allocation": {"000001": 0.4, "600036": 0.3, "000002": 0.3}
        })
    elif request.riskTolerance == "high":
        strategies.append({
            "name": "æˆé•¿è‚¡æŠ•èµ„ç­–ç•¥",
            "description": "å…³æ³¨é«˜æˆé•¿æ€§çš„ç§‘æŠ€å’Œæ–°å…´è¡Œä¸šè‚¡ç¥¨",
            "expectedReturn": "15-25%",
            "riskLevel": "high",
            "stocks": ["000858", "002415", "300059"],
            "allocation": {"000858": 0.4, "002415": 0.3, "300059": 0.3}
        })
    else:
        strategies.append({
            "name": "å‡è¡¡æŠ•èµ„ç­–ç•¥",
            "description": "å¹³è¡¡æˆé•¿æ€§å’Œç¨³å®šæ€§",
            "expectedReturn": "10-18%",
            "riskLevel": "medium",
            "stocks": ["000001", "000858", "600036"],
            "allocation": {"000001": 0.3, "000858": 0.4, "600036": 0.3}
        })
    
    return strategies

def enhance_message_with_context(message: str, context: Dict[str, Any]) -> str:
    """ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯å¢å¼ºæ¶ˆæ¯"""
    enhanced_message = message
    
    # å¤„ç†å¯¹è¯å†å²
    if context.get("conversationHistory"):
        conversation_history = context["conversationHistory"]
        
        # æå–ä¹‹å‰çš„ç”¨æˆ·æŸ¥è¯¢
        previous_queries = [
            msg["content"] for msg in conversation_history 
            if msg.get("type") == "user" and msg.get("content") != message
        ]
        
        if previous_queries:
            # å¦‚æœå½“å‰æ¶ˆæ¯å¾ˆçŸ­æˆ–è€…æ˜¯ç»§ç»­æ€§çš„é—®é¢˜ï¼Œç»“åˆä¹‹å‰çš„æŸ¥è¯¢
            if len(message) < 10 or any(word in message.lower() for word in ['ç»§ç»­', 'è¿˜æœ‰', 'å…¶ä»–', 'è¯¦ç»†', 'æ›´å¤š']):
                last_query = previous_queries[-1] if previous_queries else ""
                enhanced_message = f"åŸºäºä¹‹å‰çš„æŸ¥è¯¢'{last_query}'ï¼Œç”¨æˆ·ç°åœ¨é—®ï¼š{message}"
                print(f"æ£€æµ‹åˆ°ç»§ç»­æ€§å¯¹è¯ï¼Œå¢å¼ºæ¶ˆæ¯: {enhanced_message}")
            
            # å¦‚æœæ˜¯ç›¸å…³çš„æŠ•èµ„é—®é¢˜ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡
            elif any(word in message.lower() for word in ['æ¨è', 'åˆ†æ', 'å»ºè®®', 'è‚¡ç¥¨', 'æŠ•èµ„']):
                recent_topics = extract_topics_from_queries(previous_queries)
                if recent_topics:
                    enhanced_message = f"{message}ã€‚ä¸Šä¸‹æ–‡ï¼šç”¨æˆ·ä¹‹å‰è¯¢é—®è¿‡{', '.join(recent_topics[:2])}ç›¸å…³é—®é¢˜"
                    print(f"æ·»åŠ æŠ•èµ„è¯é¢˜ä¸Šä¸‹æ–‡: {enhanced_message}")
    
    # å¤„ç†ä¹‹å‰çš„æŸ¥è¯¢æ‘˜è¦
    if context.get("previousQueries"):
        previous_queries = context["previousQueries"]
        if previous_queries and len(message) < 15:
            # å¯¹äºç®€çŸ­çš„æ¶ˆæ¯ï¼Œæ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
            enhanced_message = f"{message}ã€‚å‚è€ƒä¹‹å‰çš„æŸ¥è¯¢ï¼š{previous_queries[-1]}"
            print(f"ä¸ºç®€çŸ­æ¶ˆæ¯æ·»åŠ æŸ¥è¯¢ä¸Šä¸‹æ–‡: {enhanced_message}")
    
    # å¤„ç†ç”¨æˆ·åå¥½
    if context.get("userPreferences"):
        preferences = context["userPreferences"]
        risk_tolerance = preferences.get("riskTolerance", "medium")
        trading_experience = preferences.get("tradingExperience", "intermediate")
        
        # ä¸ºæŠ•èµ„ç›¸å…³æŸ¥è¯¢æ·»åŠ ç”¨æˆ·åå¥½ä¿¡æ¯
        if any(word in message.lower() for word in ['æ¨è', 'å»ºè®®', 'é€‰æ‹©', 'æŠ•èµ„']):
            enhanced_message = f"{enhanced_message}ã€‚ç”¨æˆ·é£é™©åå¥½ï¼š{risk_tolerance}ï¼Œäº¤æ˜“ç»éªŒï¼š{trading_experience}"
            print(f"æ·»åŠ ç”¨æˆ·åå¥½ä¸Šä¸‹æ–‡: é£é™©åå¥½={risk_tolerance}, ç»éªŒ={trading_experience}")
    
    return enhanced_message

def extract_topics_from_queries(queries: List[str]) -> List[str]:
    """ä»æŸ¥è¯¢ä¸­æå–æŠ•èµ„è¯é¢˜"""
    topics = []
    
    # å¸¸è§çš„æŠ•èµ„è¯é¢˜å…³é”®è¯
    topic_keywords = {
        "ç§‘æŠ€è‚¡": ["ç§‘æŠ€", "æŠ€æœ¯", "äº’è”ç½‘", "è½¯ä»¶", "èŠ¯ç‰‡", "AI", "äººå·¥æ™ºèƒ½"],
        "é‡‘èè‚¡": ["é“¶è¡Œ", "ä¿é™©", "è¯åˆ¸", "é‡‘è"],
        "åŒ»è¯è‚¡": ["åŒ»è¯", "åŒ»ç–—", "ç”Ÿç‰©", "åˆ¶è¯"],
        "æ–°èƒ½æº": ["æ–°èƒ½æº", "ç”µåŠ¨è½¦", "å…‰ä¼", "é£ç”µ", "é”‚ç”µæ± "],
        "æ¶ˆè´¹è‚¡": ["æ¶ˆè´¹", "é›¶å”®", "é£Ÿå“", "é¥®æ–™"],
        "æˆ¿åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "æˆ¿äº§"],
        "ä»·å€¼æŠ•èµ„": ["ä»·å€¼", "ä½ä¼°å€¼", "åˆ†çº¢", "è“ç­¹"],
        "æˆé•¿æŠ•èµ„": ["æˆé•¿", "é«˜æˆé•¿", "å¢é•¿"],
        "ä½é£é™©æŠ•èµ„": ["ä½é£é™©", "ç¨³å¥", "ä¿å®ˆ", "å®‰å…¨"]
    }
    
    for query in queries:
        query_lower = query.lower()
        for topic, keywords in topic_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                if topic not in topics:
                    topics.append(topic)
                break
    
    return topics

async def generate_market_insights():
    """ç”Ÿæˆå¸‚åœºæ´å¯Ÿ"""
    return {
        "insights": [
            {
                "title": "ç§‘æŠ€è‚¡æŠ•èµ„æœºä¼š",
                "content": "å½“å‰ç§‘æŠ€è‚¡ä¼°å€¼åˆç†ï¼Œæ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§",
                "type": "bullish",
                "confidence": 0.75,
                "timestamp": datetime.now().isoformat()
            },
            {
                "title": "æ–°èƒ½æºæ¿å—å‰æ™¯",
                "content": "æ–°èƒ½æºæ”¿ç­–æŒç»­åˆ©å¥½ï¼Œé•¿æœŸæŠ•èµ„ä»·å€¼æ˜¾è‘—",
                "type": "bullish",
                "confidence": 0.8,
                "timestamp": datetime.now().isoformat()
            },
            {
                "title": "é‡‘èè‚¡ç¨³å¥è¡¨ç°",
                "content": "é“¶è¡Œè‚¡ä¼°å€¼åä½ï¼Œåˆ†çº¢æ”¶ç›Šç¨³å®š",
                "type": "neutral",
                "confidence": 0.65,
                "timestamp": datetime.now().isoformat()
            }
        ],
        "marketSummary": {
            "trend": "éœ‡è¡ä¸Šè¡Œ",
            "sentiment": "è°¨æ…ä¹è§‚",
            "volatility": "ä¸­ç­‰",
            "keyFactors": ["æ”¿ç­–æ”¯æŒ", "ä¸šç»©æ”¹å–„", "èµ„é‡‘æµå…¥", "ä¼°å€¼ä¿®å¤"]
        }
    }

# æ–°å¢å·¥ä½œæµç”»å¸ƒç›¸å…³è¾…åŠ©å‡½æ•°

def initialize_node_statuses(nodes: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€"""
    node_statuses = {}
    
    for node in nodes:
        node_statuses[node["id"]] = {
            "id": node["id"],
            "name": node["name"],
            "type": node["type"],
            "status": "idle",
            "progress": 0,
            "start_time": None,
            "end_time": None,
            "result": None,
            "error": None
        }
    
    return node_statuses

def validate_workflow_definition_internal(workflow_definition: Dict[str, Any]) -> Dict[str, Any]:
    """å†…éƒ¨å·¥ä½œæµå®šä¹‰éªŒè¯å‡½æ•°"""
    errors = []
    warnings = []
    
    try:
        # åŸºæœ¬éªŒè¯
        if not workflow_definition.get("name"):
            errors.append("å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º")
        
        nodes = workflow_definition.get("nodes", [])
        connections = workflow_definition.get("connections", [])
        
        if not nodes:
            errors.append("å·¥ä½œæµå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹")
        
        # èŠ‚ç‚¹éªŒè¯
        node_ids = set()
        for node in nodes:
            if not node.get("id"):
                errors.append("èŠ‚ç‚¹å¿…é¡»æœ‰å”¯ä¸€ID")
                continue
            
            if node["id"] in node_ids:
                errors.append(f"èŠ‚ç‚¹IDé‡å¤: {node['id']}")
            node_ids.add(node["id"])
            
            if not node.get("type"):
                errors.append(f"èŠ‚ç‚¹{node['id']}ç¼ºå°‘ç±»å‹å®šä¹‰")
            
            if not node.get("name"):
                errors.append(f"èŠ‚ç‚¹{node['id']}ç¼ºå°‘åç§°")
        
        # è¿æ¥éªŒè¯
        for connection in connections:
            if not connection.get("sourceId") or not connection.get("targetId"):
                errors.append("è¿æ¥å¿…é¡»æŒ‡å®šæºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹")
                continue
            
            if connection["sourceId"] not in node_ids:
                errors.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„æºèŠ‚ç‚¹: {connection['sourceId']}")
            
            if connection["targetId"] not in node_ids:
                errors.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„ç›®æ ‡èŠ‚ç‚¹: {connection['targetId']}")
        
        # å¾ªç¯ä¾èµ–æ£€æŸ¥
        if has_cyclic_dependency(nodes, connections):
            errors.append("å·¥ä½œæµå­˜åœ¨å¾ªç¯ä¾èµ–")
        
        # è­¦å‘Šæ£€æŸ¥
        if len(nodes) > 10:
            warnings.append("å·¥ä½œæµèŠ‚ç‚¹æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½å½±å“æ‰§è¡Œæ€§èƒ½")
        
        isolated_nodes = find_isolated_nodes(nodes, connections)
        if isolated_nodes:
            warnings.append(f"å‘ç°å­¤ç«‹èŠ‚ç‚¹: {', '.join(isolated_nodes)}")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }
        
    except Exception as e:
        return {
            "valid": False,
            "errors": [f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"],
            "warnings": []
        }

def has_cyclic_dependency(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> bool:
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯ä¾èµ–"""
    try:
        # æ„å»ºé‚»æ¥è¡¨
        graph = {}
        for node in nodes:
            graph[node["id"]] = []
        
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id and target_id and source_id in graph:
                graph[source_id].append(target_id)
        
        # DFSæ£€æŸ¥å¾ªç¯
        visited = set()
        recursion_stack = set()
        
        def has_cycle(node_id: str) -> bool:
            visited.add(node_id)
            recursion_stack.add(node_id)
            
            for neighbor in graph.get(node_id, []):
                if neighbor not in visited:
                    if has_cycle(neighbor):
                        return True
                elif neighbor in recursion_stack:
                    return True
            
            recursion_stack.remove(node_id)
            return False
        
        for node_id in graph:
            if node_id not in visited:
                if has_cycle(node_id):
                    return True
        
        return False
        
    except Exception as e:
        print(f"å¾ªç¯ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}")
        return False

def find_isolated_nodes(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> List[str]:
    """æŸ¥æ‰¾å­¤ç«‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰è¿æ¥çš„èŠ‚ç‚¹ï¼‰"""
    try:
        connected_nodes = set()
        
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id:
                connected_nodes.add(source_id)
            if target_id:
                connected_nodes.add(target_id)
        
        isolated_nodes = []
        for node in nodes:
            if node["id"] not in connected_nodes:
                isolated_nodes.append(node["id"])
        
        return isolated_nodes
        
    except Exception as e:
        print(f"æŸ¥æ‰¾å­¤ç«‹èŠ‚ç‚¹å¤±è´¥: {e}")
        return []

async def execute_workflow_definition(execution_id: str, workflow_definition: Dict[str, Any], context: Dict[str, Any]):
    """æ‰§è¡Œå·¥ä½œæµå®šä¹‰"""
    try:
        execution = workflow_execution_storage[execution_id]
        nodes = workflow_definition.get("nodes", [])
        connections = workflow_definition.get("connections", [])
        
        # è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œé¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰
        execution_order = calculate_execution_order(nodes, connections)
        
        print(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµå®šä¹‰: {execution_id}, èŠ‚ç‚¹æ‰§è¡Œé¡ºåº: {execution_order}")
        
        # æŒ‰é¡ºåºæ‰§è¡ŒèŠ‚ç‚¹
        for i, node_id in enumerate(execution_order):
            node = next((n for n in nodes if n["id"] == node_id), None)
            if not node:
                continue
            
            # æ›´æ–°å½“å‰æ‰§è¡ŒèŠ‚ç‚¹
            execution["current_node"] = node_id
            execution["progress"] = int((i / len(execution_order)) * 90)  # ç•™10%ç»™æœ€ç»ˆå¤„ç†
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            await update_node_status(execution_id, node_id, "running", 0, f"æ­£åœ¨æ‰§è¡Œ{node['name']}...")
            
            # æ‰§è¡ŒèŠ‚ç‚¹
            node_result = await execute_single_node(node, execution, context)
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
            if node_result.get("success", True):
                await update_node_status(execution_id, node_id, "completed", 100, f"{node['name']}æ‰§è¡Œå®Œæˆ")
                execution["node_statuses"][node_id]["result"] = node_result
            else:
                await update_node_status(execution_id, node_id, "error", 0, f"{node['name']}æ‰§è¡Œå¤±è´¥: {node_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                execution["node_statuses"][node_id]["error"] = node_result.get("error")
                # å¦‚æœèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢æ•´ä¸ªå·¥ä½œæµ
                execution["status"] = "error"
                execution["message"] = f"èŠ‚ç‚¹{node['name']}æ‰§è¡Œå¤±è´¥"
                return
            
            # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            await asyncio.sleep(1)
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        final_results = await generate_workflow_final_results(execution_id, workflow_definition, execution)
        
        # å®Œæˆå·¥ä½œæµæ‰§è¡Œ
        execution["status"] = "completed"
        execution["progress"] = 100
        execution["end_time"] = datetime.now().isoformat()
        execution["results"] = final_results
        execution["message"] = "å·¥ä½œæµæ‰§è¡Œå®Œæˆ"
        
        print(f"å·¥ä½œæµå®šä¹‰æ‰§è¡Œå®Œæˆ: {execution_id}")
        
    except Exception as e:
        print(f"å·¥ä½œæµå®šä¹‰æ‰§è¡Œå¤±è´¥: {execution_id}, é”™è¯¯: {e}")
        execution = workflow_execution_storage.get(execution_id)
        if execution:
            execution["status"] = "error"
            execution["message"] = str(e)
            execution["end_time"] = datetime.now().isoformat()

def calculate_execution_order(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> List[str]:
    """è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œé¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰"""
    try:
        # æ„å»ºä¾èµ–å›¾
        in_degree = {}
        graph = {}
        
        # åˆå§‹åŒ–
        for node in nodes:
            node_id = node["id"]
            in_degree[node_id] = 0
            graph[node_id] = []
        
        # æ„å»ºå›¾å’Œè®¡ç®—å…¥åº¦
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id and target_id:
                graph[source_id].append(target_id)
                in_degree[target_id] += 1
        
        # æ‹“æ‰‘æ’åº
        queue = [node_id for node_id, degree in in_degree.items() if degree == 0]
        result = []
        
        while queue:
            current = queue.pop(0)
            result.append(current)
            
            for neighbor in graph[current]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        # å¦‚æœç»“æœé•¿åº¦ä¸ç­‰äºèŠ‚ç‚¹æ•°é‡ï¼Œè¯´æ˜å­˜åœ¨å¾ªç¯ä¾èµ–
        if len(result) != len(nodes):
            print("è­¦å‘Š: æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œä½¿ç”¨èŠ‚ç‚¹å®šä¹‰é¡ºåº")
            return [node["id"] for node in nodes]
        
        return result
        
    except Exception as e:
        print(f"è®¡ç®—æ‰§è¡Œé¡ºåºå¤±è´¥: {e}")
        # é™çº§æ–¹æ¡ˆï¼šæŒ‰èŠ‚ç‚¹å®šä¹‰é¡ºåºæ‰§è¡Œ
        return [node["id"] for node in nodes]

async def update_node_status(execution_id: str, node_id: str, status: str, progress: int, message: str):
    """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€"""
    execution = workflow_execution_storage.get(execution_id)
    if execution and node_id in execution["node_statuses"]:
        node_status = execution["node_statuses"][node_id]
        node_status["status"] = status
        node_status["progress"] = progress
        node_status["message"] = message
        
        if status == "running":
            node_status["start_time"] = datetime.now().isoformat()
        elif status in ["completed", "error"]:
            node_status["end_time"] = datetime.now().isoformat()

async def execute_single_node(node: Dict[str, Any], execution: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
    try:
        node_type = node.get("type")
        node_config = node.get("config", {})
        
        print(f"æ‰§è¡ŒèŠ‚ç‚¹: {node['id']} ({node_type})")
        
        if node_type == "data":
            return await execute_data_node(node, node_config, context)
        elif node_type == "analysis":
            return await execute_analysis_node(node, node_config, context)
        elif node_type == "strategy":
            return await execute_strategy_node(node, node_config, context)
        elif node_type == "risk":
            return await execute_risk_node(node, node_config, context)
        elif node_type == "output":
            return await execute_output_node(node, node_config, context)
        else:
            return await execute_custom_node(node, node_config, context)
            
    except Exception as e:
        print(f"æ‰§è¡ŒèŠ‚ç‚¹å¤±è´¥: {node['id']}, é”™è¯¯: {e}")
        return {
            "success": False,
            "error": str(e),
            "node_id": node["id"]
        }

async def execute_data_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæ•°æ®æ”¶é›†èŠ‚ç‚¹"""
    try:
        data_sources = config.get("dataSources", ["stock_price"])
        time_range = config.get("timeRange", "1y")
        symbols = config.get("symbols", [])
        
        # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†
        await asyncio.sleep(1)
        
        collected_data = {
            "sources": data_sources,
            "timeRange": time_range,
            "symbols": symbols,
            "recordCount": len(symbols) * 252 if symbols else 1000,
            "collectedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": collected_data,
            "message": f"æˆåŠŸæ”¶é›†{len(data_sources)}ä¸ªæ•°æ®æºçš„æ•°æ®"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_analysis_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œåˆ†æèŠ‚ç‚¹"""
    try:
        indicators = config.get("indicators", ["RSI", "MACD"])
        period = config.get("period", 20)
        
        # æ¨¡æ‹Ÿåˆ†æå¤„ç†
        await asyncio.sleep(1.5)
        
        analysis_result = {
            "indicators": indicators,
            "period": period,
            "signals": {
                "bullish": len(indicators) * 2,
                "bearish": len(indicators),
                "neutral": len(indicators) * 3
            },
            "confidence": 0.75,
            "analyzedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": analysis_result,
            "message": f"å®Œæˆ{len(indicators)}ä¸ªæŒ‡æ ‡çš„åˆ†æ"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_strategy_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œç­–ç•¥ç”ŸæˆèŠ‚ç‚¹"""
    try:
        strategy_type = config.get("strategyType", "momentum")
        risk_level = config.get("riskLevel", "medium")
        time_horizon = config.get("timeHorizon", "medium_term")
        
        # æ¨¡æ‹Ÿç­–ç•¥ç”Ÿæˆ
        await asyncio.sleep(2)
        
        strategy_result = {
            "strategyType": strategy_type,
            "riskLevel": risk_level,
            "timeHorizon": time_horizon,
            "recommendations": [
                {
                    "action": "buy",
                    "symbol": "AAPL",
                    "weight": 0.3,
                    "confidence": 0.8
                },
                {
                    "action": "hold",
                    "symbol": "MSFT",
                    "weight": 0.4,
                    "confidence": 0.7
                }
            ],
            "expectedReturn": "12-18%",
            "generatedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": strategy_result,
            "message": f"ç”Ÿæˆ{strategy_type}ç­–ç•¥ï¼ŒåŒ…å«{len(strategy_result['recommendations'])}ä¸ªå»ºè®®"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_risk_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œé£é™©è¯„ä¼°èŠ‚ç‚¹"""
    try:
        risk_metrics = config.get("riskMetrics", ["VaR", "Sharpe"])
        backtest_period = config.get("backtestPeriod", "2y")
        
        # æ¨¡æ‹Ÿé£é™©è¯„ä¼°
        await asyncio.sleep(1.5)
        
        risk_result = {
            "metrics": risk_metrics,
            "backtestPeriod": backtest_period,
            "riskAssessment": {
                "VaR": 0.05,
                "Sharpe": 1.2,
                "MaxDrawdown": 0.15,
                "Volatility": 0.18
            },
            "riskLevel": "medium",
            "assessedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": risk_result,
            "message": f"å®Œæˆ{len(risk_metrics)}ä¸ªé£é™©æŒ‡æ ‡çš„è¯„ä¼°"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_output_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œè¾“å‡ºèŠ‚ç‚¹"""
    try:
        output_format = config.get("outputFormat", "detailed_report")
        include_charts = config.get("includeCharts", True)
        
        # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
        await asyncio.sleep(1)
        
        output_result = {
            "format": output_format,
            "includeCharts": include_charts,
            "report": {
                "title": "AIå·¥ä½œæµåˆ†ææŠ¥å‘Š",
                "summary": "åŸºäºå¤šèŠ‚ç‚¹åˆ†æç”Ÿæˆçš„æŠ•èµ„å»ºè®®æŠ¥å‘Š",
                "sections": ["å¸‚åœºåˆ†æ", "ç­–ç•¥å»ºè®®", "é£é™©è¯„ä¼°", "æ‰§è¡Œå»ºè®®"],
                "generatedAt": datetime.now().isoformat()
            }
        }
        
        return {
            "success": True,
            "data": output_result,
            "message": f"ç”Ÿæˆ{output_format}æ ¼å¼çš„åˆ†ææŠ¥å‘Š"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_custom_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œè‡ªå®šä¹‰èŠ‚ç‚¹"""
    try:
        # æ¨¡æ‹Ÿè‡ªå®šä¹‰èŠ‚ç‚¹å¤„ç†
        await asyncio.sleep(1)
        
        custom_result = {
            "nodeId": node["id"],
            "nodeName": node["name"],
            "config": config,
            "processedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": custom_result,
            "message": f"å®Œæˆè‡ªå®šä¹‰èŠ‚ç‚¹{node['name']}çš„å¤„ç†"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def generate_workflow_final_results(execution_id: str, workflow_definition: Dict[str, Any], execution: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆå·¥ä½œæµæœ€ç»ˆç»“æœ"""
    try:
        workflow_name = workflow_definition.get("name", "æœªå‘½åå·¥ä½œæµ")
        nodes = workflow_definition.get("nodes", [])
        node_statuses = execution.get("node_statuses", {})
        
        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„ç»“æœ
        node_results = {}
        for node_id, status in node_statuses.items():
            if status.get("result"):
                node_results[node_id] = status["result"]
        
        # ç”Ÿæˆç»¼åˆåˆ†æç»“æœ
        final_results = {
            "workflowName": workflow_name,
            "executionId": execution_id,
            "executionSummary": {
                "totalNodes": len(nodes),
                "completedNodes": len([s for s in node_statuses.values() if s["status"] == "completed"]),
                "failedNodes": len([s for s in node_statuses.values() if s["status"] == "error"]),
                "executionTime": calculate_execution_time(execution)
            },
            "nodeResults": node_results,
            "recommendations": extract_recommendations_from_results(node_results),
            "riskAssessment": extract_risk_assessment_from_results(node_results),
            "marketInsights": extract_market_insights_from_results(node_results),
            "generatedAt": datetime.now().isoformat()
        }
        
        return final_results
        
    except Exception as e:
        print(f"ç”Ÿæˆæœ€ç»ˆç»“æœå¤±è´¥: {e}")
        return {
            "workflowName": workflow_definition.get("name", "æœªå‘½åå·¥ä½œæµ"),
            "executionId": execution_id,
            "error": str(e),
            "generatedAt": datetime.now().isoformat()
        }

def calculate_execution_time(execution: Dict[str, Any]) -> str:
    """è®¡ç®—æ‰§è¡Œæ—¶é—´"""
    try:
        start_time = execution.get("start_time")
        end_time = execution.get("end_time")
        
        if start_time and end_time:
            start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            duration = end_dt - start_dt
            return f"{duration.total_seconds():.1f}ç§’"
        else:
            return "è®¡ç®—ä¸­..."
            
    except Exception as e:
        print(f"è®¡ç®—æ‰§è¡Œæ—¶é—´å¤±è´¥: {e}")
        return "æœªçŸ¥"

def extract_recommendations_from_results(node_results: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–æ¨è"""
    recommendations = []
    
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»ç­–ç•¥èŠ‚ç‚¹æå–æ¨è
                if "recommendations" in data:
                    recommendations.extend(data["recommendations"])
                
                # ä»åˆ†æèŠ‚ç‚¹æå–ä¿¡å·
                elif "signals" in data:
                    signals = data["signals"]
                    if signals.get("bullish", 0) > signals.get("bearish", 0):
                        recommendations.append({
                            "type": "market_signal",
                            "action": "ç§¯æå…³æ³¨",
                            "reason": "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºç§¯æä¿¡å·",
                            "confidence": data.get("confidence", 0.5)
                        })
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ¨èï¼Œç”Ÿæˆé€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append({
                "type": "general",
                "action": "æŒç»­å…³æ³¨",
                "reason": "åŸºäºå·¥ä½œæµåˆ†æç»“æœ",
                "confidence": 0.6
            })
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªæ¨è
        
    except Exception as e:
        print(f"æå–æ¨èå¤±è´¥: {e}")
        return []

def extract_risk_assessment_from_results(node_results: Dict[str, Any]) -> Dict[str, Any]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–é£é™©è¯„ä¼°"""
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»é£é™©èŠ‚ç‚¹æå–é£é™©è¯„ä¼°
                if "riskAssessment" in data:
                    return {
                        "overallRisk": data.get("riskLevel", "medium"),
                        "metrics": data["riskAssessment"],
                        "assessment": "åŸºäºé‡åŒ–é£é™©æ¨¡å‹è¯„ä¼°"
                    }
        
        # é»˜è®¤é£é™©è¯„ä¼°
        return {
            "overallRisk": "medium",
            "metrics": {"VaR": 0.05, "Sharpe": 1.0},
            "assessment": "åŸºäºå·¥ä½œæµç»¼åˆè¯„ä¼°"
        }
        
    except Exception as e:
        print(f"æå–é£é™©è¯„ä¼°å¤±è´¥: {e}")
        return {"overallRisk": "unknown", "assessment": "é£é™©è¯„ä¼°ä¸å¯ç”¨"}

def extract_market_insights_from_results(node_results: Dict[str, Any]) -> List[str]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–å¸‚åœºæ´å¯Ÿ"""
    insights = []
    
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»åˆ†æèŠ‚ç‚¹æå–æ´å¯Ÿ
                if "signals" in data:
                    signals = data["signals"]
                    total_signals = sum(signals.values())
                    if total_signals > 0:
                        bullish_pct = signals.get("bullish", 0) / total_signals * 100
                        if bullish_pct > 50:
                            insights.append(f"æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤º{bullish_pct:.0f}%çš„ç§¯æä¿¡å·")
                        elif bullish_pct < 30:
                            insights.append(f"æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºè°¨æ…ä¿¡å·ï¼Œå»ºè®®è§‚æœ›")
                
                # ä»ç­–ç•¥èŠ‚ç‚¹æå–æ´å¯Ÿ
                elif "expectedReturn" in data:
                    insights.append(f"é¢„æœŸæ”¶ç›Šç‡: {data['expectedReturn']}")
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ´å¯Ÿï¼Œæ·»åŠ é€šç”¨æ´å¯Ÿ
        if not insights:
            insights.append("å¸‚åœºå¤„äºæ­£å¸¸æ³¢åŠ¨èŒƒå›´å†…")
            insights.append("å»ºè®®ä¿æŒå¤šå…ƒåŒ–æŠ•èµ„ç­–ç•¥")
        
        return insights[:3]  # æœ€å¤šè¿”å›3ä¸ªæ´å¯Ÿ
        
    except Exception as e:
        print(f"æå–å¸‚åœºæ´å¯Ÿå¤±è´¥: {e}")
        return ["å¸‚åœºåˆ†ææš‚æ—¶ä¸å¯ç”¨"]

def generate_fallback_analysis_response(message: str) -> str:
    """ç”Ÿæˆé™çº§çš„åˆ†æå›å¤"""
    return f"""åŸºäºæ‚¨çš„é—®é¢˜ "{message}"ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹ç®€è¦å»ºè®®ï¼š

## ğŸ“Š åˆ†ææ€è·¯

**1. åŸºæœ¬é¢åˆ†æ**
- æŸ¥çœ‹å…¬å¸è´¢åŠ¡æŠ¥è¡¨å’Œç»è¥çŠ¶å†µ
- äº†è§£è¡Œä¸šå‘å±•è¶‹åŠ¿å’Œç«äº‰æ ¼å±€  
- å…³æ³¨å®è§‚ç»æµç¯å¢ƒå½±å“

**2. æŠ€æœ¯é¢åˆ†æ**
- è§‚å¯Ÿä»·æ ¼èµ°åŠ¿å’Œæˆäº¤é‡å˜åŒ–
- åˆ†æå…³é”®æŠ€æœ¯æŒ‡æ ‡ä¿¡å·
- è¯†åˆ«æ”¯æ’‘é˜»åŠ›ä½ç½®

**3. é£é™©è¯„ä¼°**
- è¯„ä¼°å¸‚åœºé£é™©å’Œä¸ªè‚¡é£é™©
- è€ƒè™‘æ”¿ç­–é£é™©å’Œè¡Œä¸šé£é™©
- åˆ¶å®šé£é™©æ§åˆ¶ç­–ç•¥

**4. æŠ•èµ„å»ºè®®**
- æ ¹æ®é£é™©æ‰¿å—èƒ½åŠ›é€‰æ‹©æŠ•èµ„ç­–ç•¥
- å»ºè®®é€‚å½“åˆ†æ•£æŠ•èµ„é™ä½é£é™©
- è®¾ç½®åˆç†çš„æ­¢ç›ˆæ­¢æŸç‚¹ä½

ğŸ’¡ **æ¸©é¦¨æç¤º**: æŠ•èµ„æœ‰é£é™©ï¼Œå»ºè®®æ‚¨ç»“åˆè‡ªèº«æƒ…å†µå’Œæ›´å¤šä¿¡æ¯åšå‡ºè°¨æ…å†³ç­–ã€‚"""

def generate_fallback_strategy_response(message: str) -> str:
    """ç”Ÿæˆé™çº§çš„ç­–ç•¥å›å¤"""
    return f"""é’ˆå¯¹æ‚¨çš„ç­–ç•¥éœ€æ±‚ "{message}"ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹å»ºè®®æ¡†æ¶ï¼š

## ğŸ¯ ç­–ç•¥åˆ¶å®šæŒ‡å—

**1. ç›®æ ‡è®¾å®š**
- æ˜ç¡®æŠ•èµ„ç›®æ ‡å’Œé¢„æœŸæ”¶ç›Š
- è®¾å®šå¯æ¥å—çš„é£é™©æ°´å¹³
- ç¡®å®šæŠ•èµ„æ—¶é—´å‘¨æœŸ

**2. èµ„äº§é…ç½®**
- è‚¡ç¥¨ã€å€ºåˆ¸ã€åŸºé‡‘ç­‰çš„æ¯”ä¾‹é…ç½®
- è¡Œä¸šæ¿å—çš„åˆ†æ•£é…ç½®
- æ ¹æ®å¸‚åœºæƒ…å†µåŠ¨æ€è°ƒæ•´

**3. æ“ä½œç­–ç•¥**
- é€‰æ‹©åˆé€‚çš„ä¹°å…¥æ—¶æœº
- åˆ¶å®šåˆ†æ‰¹å»ºä»“è®¡åˆ’
- è®¾ç½®æ­¢ç›ˆæ­¢æŸè§„åˆ™

**4. é£é™©ç®¡ç†**
- æ§åˆ¶å•åªè‚¡ç¥¨çš„ä»“ä½æ¯”ä¾‹
- è®¾ç½®æœ€å¤§æŸå¤±å®¹å¿åº¦
- å®šæœŸè¯„ä¼°å’Œè°ƒæ•´ç­–ç•¥

**5. æ‰§è¡Œçºªå¾‹**
- ä¸¥æ ¼æŒ‰ç…§ç­–ç•¥æ‰§è¡Œ
- é¿å…æƒ…ç»ªåŒ–äº¤æ˜“
- å®šæœŸæ€»ç»“å’Œä¼˜åŒ–

ğŸ“ˆ **å»ºè®®**: ä»»ä½•æŠ•èµ„ç­–ç•¥éƒ½éœ€è¦æ ¹æ®å¸‚åœºå˜åŒ–å’Œä¸ªäººæƒ…å†µåŠæ—¶è°ƒæ•´ã€‚"""