from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import asyncio
import uuid
from datetime import datetime
import json
import logging

from services.qwen_analyzer import QwenAnalyzer
from services.stock_recommender import StockRecommender
from services.smart_stock_service import SmartStockService
from services.database_service import DatabaseService
from utils.helpers import clean_text

router = APIRouter(prefix="/api/v1", tags=["AI Workflow"])

# è¯·æ±‚æ¨¡å‹
class WorkflowStartRequest(BaseModel):
    workflow_id: str
    query: str
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class WorkflowDefinitionRunRequest(BaseModel):
    execution_id: str
    workflow_definition: Dict[str, Any]
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class WorkflowValidationRequest(BaseModel):
    workflow_definition: Dict[str, Any]

class ChatMessageRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    user_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class StockAnalysisRequest(BaseModel):
    symbol: str

class StrategyGenerationRequest(BaseModel):
    riskTolerance: str = "medium"
    investmentGoal: str
    timeHorizon: str = "medium"
    sectors: Optional[List[str]] = None
    excludeStocks: Optional[List[str]] = None
    userId: Optional[str] = None

# å“åº”æ¨¡å‹
class AgentStatus(BaseModel):
    id: str
    name: str
    status: str = "idle"  # idle, running, completed, error
    progress: int = 0
    message: Optional[str] = None
    result: Optional[Dict[str, Any]] = None
    startTime: Optional[str] = None
    endTime: Optional[str] = None

class WorkflowResponse(BaseModel):
    workflowId: str
    status: str
    message: str
    agents: Optional[List[AgentStatus]] = None
    results: Optional[Dict[str, Any]] = None

# å…¨å±€å˜é‡å­˜å‚¨å·¥ä½œæµçŠ¶æ€
workflow_storage: Dict[str, Dict[str, Any]] = {}
conversation_storage: Dict[str, List[Dict[str, Any]]] = {}
# æ–°å¢ï¼šå·¥ä½œæµå®šä¹‰æ‰§è¡Œå­˜å‚¨
workflow_execution_storage: Dict[str, Dict[str, Any]] = {}

# åˆå§‹åŒ–æœåŠ¡
qwen_analyzer = QwenAnalyzer()
stock_recommender = StockRecommender()
smart_stock_service = SmartStockService()
db_service = DatabaseService()

@router.post("/workflow/start")
async def start_workflow(request: WorkflowStartRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨AIå·¥ä½œæµ"""
    try:
        workflow_id = request.workflow_id
        
        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        workflow_storage[workflow_id] = {
            "id": workflow_id,
            "status": "running",
            "query": request.query,
            "user_id": request.user_id,
            "context": request.context or {},
            "start_time": datetime.now().isoformat(),
            "agents": get_default_agents(),
            "results": {}
        }
        
        # åœ¨åå°æ‰§è¡Œå·¥ä½œæµ
        background_tasks.add_task(execute_workflow, workflow_id, request.query, request.context)
        
        return {
            "success": True,
            "data": {
                "workflowId": workflow_id,
                "status": "started",
                "message": "AIå·¥ä½œæµå·²å¯åŠ¨",
                "agents": get_default_agents()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å·¥ä½œæµå¤±è´¥: {str(e)}")

@router.get("/workflow/status/{workflow_id}")
async def get_workflow_status(workflow_id: str):
    """è·å–å·¥ä½œæµçŠ¶æ€"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        
        return {
            "success": True,
            "data": {
                "workflowId": workflow_id,
                "status": workflow["status"],
                "progress": calculate_progress(workflow["agents"]),
                "agents": workflow["agents"],
                "results": workflow.get("results", {}),
                "message": workflow.get("message", "")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/workflow/stop/{workflow_id}")
async def stop_workflow(workflow_id: str):
    """åœæ­¢å·¥ä½œæµ"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        workflow["status"] = "stopped"
        workflow["end_time"] = datetime.now().isoformat()
        
        return {
            "success": True,
            "data": {"message": "å·¥ä½œæµå·²åœæ­¢"}
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åœæ­¢å·¥ä½œæµå¤±è´¥: {str(e)}")

@router.get("/workflow/results/{workflow_id}")
async def get_workflow_results(workflow_id: str):
    """è·å–å·¥ä½œæµç»“æœ"""
    try:
        if workflow_id not in workflow_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµä¸å­˜åœ¨")
        
        workflow = workflow_storage[workflow_id]
        
        return {
            "success": True,
            "data": workflow.get("results", {})
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµç»“æœå¤±è´¥: {str(e)}")

@router.post("/chat/analyze")
async def analyze_chat_message(request: ChatMessageRequest):
    """åˆ†æèŠå¤©æ¶ˆæ¯å¹¶ç”ŸæˆAIå›å¤ï¼ˆä¸“é—¨ç”¨äºAIåˆ†æï¼‰"""
    try:
        # ä½¿ç”¨ç°æœ‰çš„åˆ†ææœåŠ¡è¿›è¡Œæ™ºèƒ½åˆ†æ
        analysis_result = await perform_intelligent_analysis(request.message, request.context)
        
        return {
            "success": True,
            "data": {
                "response": analysis_result["response"],
                "analysis": analysis_result.get("analysis"),
                "recommendations": analysis_result.get("recommendations", [])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")

@router.post("/chat/message")
async def send_chat_message(request: ChatMessageRequest):
    """å‘é€èŠå¤©æ¶ˆæ¯ï¼ˆä¿ç•™åŸæœ‰æ¥å£å…¼å®¹æ€§ï¼‰"""
    try:
        conversation_id = request.conversation_id or f"conv_{uuid.uuid4()}"
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        if conversation_id not in conversation_storage:
            conversation_storage[conversation_id] = []
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        user_message = {
            "id": f"msg_{uuid.uuid4()}",
            "type": "user",
            "content": request.message,
            "timestamp": datetime.now().isoformat()
        }
        conversation_storage[conversation_id].append(user_message)
        
        # ç”ŸæˆAIå›å¤
        ai_response = await generate_ai_response(request.message, request.context)
        
        ai_message = {
            "id": f"msg_{uuid.uuid4()}",
            "type": "assistant",
            "content": ai_response,
            "timestamp": datetime.now().isoformat()
        }
        conversation_storage[conversation_id].append(ai_message)
        
        return {
            "success": True,
            "data": {
                "message": ai_message,
                "conversationId": conversation_id
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‘é€èŠå¤©æ¶ˆæ¯å¤±è´¥: {str(e)}")

@router.get("/chat/history/{conversation_id}")
async def get_chat_history(conversation_id: str):
    """è·å–èŠå¤©å†å²"""
    try:
        history = conversation_storage.get(conversation_id, [])
        
        return {
            "success": True,
            "data": history
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–èŠå¤©å†å²å¤±è´¥: {str(e)}")

@router.get("/agents")
async def get_agents():
    """è·å–æ™ºèƒ½ä½“é…ç½®"""
    try:
        agents = get_default_agents()
        
        return {
            "success": True,
            "data": agents
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ™ºèƒ½ä½“é…ç½®å¤±è´¥: {str(e)}")

@router.get("/workflow/history/{user_id}")
async def get_workflow_history(user_id: str):
    """è·å–ç”¨æˆ·å·¥ä½œæµå†å²"""
    try:
        # ä»å­˜å‚¨ä¸­ç­›é€‰ç”¨æˆ·çš„å·¥ä½œæµ
        user_workflows = [
            workflow for workflow in workflow_storage.values()
            if workflow.get("user_id") == user_id
        ]
        
        return {
            "success": True,
            "data": {
                "workflows": user_workflows,
                "total": len(user_workflows),
                "page": 1,
                "limit": 10
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµå†å²å¤±è´¥: {str(e)}")

@router.post("/analyze/stock")
async def analyze_stock(request: StockAnalysisRequest):
    """åˆ†æè‚¡ç¥¨ - ä½¿ç”¨è½»é‡çº§åˆ†æï¼Œä¸ä¾èµ–æ•°æ®åº“"""
    try:
        # ä½¿ç”¨é¦–é¡µä¸“ç”¨çš„è½»é‡çº§åˆ†ææ–¹æ³•
        analysis_result = qwen_analyzer.analyze_stock_for_homepage(request.symbol)
        
        return {
            "success": True,
            "data": {
                "analysis": analysis_result,
                "recommendations": [f"åŸºäºAIåˆ†æï¼Œ{request.symbol}å…·æœ‰æŠ•èµ„ä»·å€¼"]
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è‚¡ç¥¨åˆ†æå¤±è´¥: {str(e)}")

@router.post("/generate/strategy")
async def generate_strategy(request: StrategyGenerationRequest):
    """ç”ŸæˆæŠ•èµ„ç­–ç•¥"""
    try:
        # åŸºäºç”¨æˆ·åå¥½ç”Ÿæˆç­–ç•¥
        strategies = await generate_investment_strategies(request)
        
        return {
            "success": True,
            "data": {
                "strategies": strategies,
                "reasoning": f"åŸºäºæ‚¨çš„é£é™©åå¥½({request.riskTolerance})å’ŒæŠ•èµ„ç›®æ ‡ç”Ÿæˆç­–ç•¥"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç­–ç•¥ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.get("/market/insights")
async def get_market_insights():
    """è·å–å¸‚åœºæ´å¯Ÿ"""
    try:
        insights = await generate_market_insights()
        
        return {
            "success": True,
            "data": insights
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¸‚åœºæ´å¯Ÿå¤±è´¥: {str(e)}")

# æ–°å¢å·¥ä½œæµç”»å¸ƒç›¸å…³APIç«¯ç‚¹

@router.post("/workflow/definition/run")
async def run_workflow_definition(request: WorkflowDefinitionRunRequest, background_tasks: BackgroundTasks):
    """è¿è¡Œå·¥ä½œæµå®šä¹‰"""
    try:
        execution_id = request.execution_id
        workflow_definition = request.workflow_definition
        
        # éªŒè¯å·¥ä½œæµå®šä¹‰
        validation_result = validate_workflow_definition_internal(workflow_definition)
        if not validation_result["valid"]:
            raise HTTPException(status_code=400, detail=f"å·¥ä½œæµå®šä¹‰æ— æ•ˆ: {validation_result['errors']}")
        
        # åˆå§‹åŒ–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€
        workflow_execution_storage[execution_id] = {
            "execution_id": execution_id,
            "workflow_definition": workflow_definition,
            "user_id": request.user_id,
            "context": request.context or {},
            "status": "running",
            "progress": 0,
            "start_time": datetime.now().isoformat(),
            "node_statuses": initialize_node_statuses(workflow_definition.get("nodes", [])),
            "results": {}
        }
        
        # åœ¨åå°æ‰§è¡Œå·¥ä½œæµå®šä¹‰
        background_tasks.add_task(execute_workflow_definition, execution_id, workflow_definition, request.context)
        
        return {
            "success": True,
            "data": {
                "execution_id": execution_id,
                "status": "running",
                "message": "å·¥ä½œæµå®šä¹‰å¼€å§‹æ‰§è¡Œ",
                "node_statuses": workflow_execution_storage[execution_id]["node_statuses"]
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¿è¡Œå·¥ä½œæµå®šä¹‰å¤±è´¥: {str(e)}")

@router.get("/workflow/execution/status/{execution_id}")
async def get_workflow_execution_status(execution_id: str):
    """è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        
        return {
            "success": True,
            "data": {
                "execution_id": execution_id,
                "status": execution["status"],
                "progress": execution["progress"],
                "node_statuses": execution["node_statuses"],
                "results": execution.get("results", {}),
                "current_node": execution.get("current_node"),
                "message": execution.get("message", "")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/workflow/execution/stop/{execution_id}")
async def stop_workflow_execution(execution_id: str):
    """åœæ­¢å·¥ä½œæµæ‰§è¡Œ"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        execution["status"] = "stopped"
        execution["end_time"] = datetime.now().isoformat()
        
        return {
            "success": True,
            "data": {"message": "å·¥ä½œæµæ‰§è¡Œå·²åœæ­¢"}
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åœæ­¢å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")

@router.get("/workflow/execution/results/{execution_id}")
async def get_workflow_execution_results(execution_id: str):
    """è·å–å·¥ä½œæµæ‰§è¡Œç»“æœ"""
    try:
        if execution_id not in workflow_execution_storage:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨")
        
        execution = workflow_execution_storage[execution_id]
        
        return {
            "success": True,
            "data": execution.get("results", {})
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµæ‰§è¡Œç»“æœå¤±è´¥: {str(e)}")

@router.post("/workflow/definition/validate")
async def validate_workflow_definition(request: WorkflowValidationRequest):
    """éªŒè¯å·¥ä½œæµå®šä¹‰"""
    try:
        workflow_definition = request.workflow_definition
        validation_result = validate_workflow_definition_internal(workflow_definition)
        
        return {
            "success": validation_result["valid"],
            "data": {
                "valid": validation_result["valid"],
                "errors": validation_result["errors"],
                "warnings": validation_result.get("warnings", [])
            },
            "message": "éªŒè¯å®Œæˆ" if validation_result["valid"] else "å·¥ä½œæµå®šä¹‰å­˜åœ¨é”™è¯¯"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"éªŒè¯å·¥ä½œæµå®šä¹‰å¤±è´¥: {str(e)}")

# è¾…åŠ©å‡½æ•°
def get_default_agents():
    """è·å–é»˜è®¤æ™ºèƒ½ä½“é…ç½®"""
    return [
        {
            "id": "data-collector",
            "name": "æ•°æ®æ”¶é›†æ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "analyzer",
            "name": "åˆ†ææ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "strategy-generator",
            "name": "ç­–ç•¥ç”Ÿæˆæ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "risk-assessor",
            "name": "é£é™©è¯„ä¼°æ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        },
        {
            "id": "executor",
            "name": "æ‰§è¡Œæ™ºèƒ½ä½“",
            "status": "idle",
            "progress": 0,
            "message": None
        }
    ]

def calculate_progress(agents):
    """è®¡ç®—æ€»ä½“è¿›åº¦"""
    if not agents:
        return 0
    
    total_progress = sum(agent.get("progress", 0) for agent in agents)
    return total_progress // len(agents)

async def execute_workflow(workflow_id: str, query: str, context: Dict[str, Any]):
    """æ‰§è¡Œå·¥ä½œæµ"""
    try:
        workflow = workflow_storage[workflow_id]
        agents = workflow["agents"]
        
        # æ­¥éª¤1: æ•°æ®æ”¶é›†
        await update_agent_status(workflow_id, "data-collector", "running", 0, "æ­£åœ¨æ”¶é›†å¸‚åœºæ•°æ®...")
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        await update_agent_status(workflow_id, "data-collector", "completed", 100, "å¸‚åœºæ•°æ®æ”¶é›†å®Œæˆ")
        
        # æ­¥éª¤2: æ™ºèƒ½åˆ†æ
        await update_agent_status(workflow_id, "analyzer", "running", 0, "æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ...")
        analysis_result = await perform_analysis(query)
        await update_agent_status(workflow_id, "analyzer", "completed", 100, "æ™ºèƒ½åˆ†æå®Œæˆ")
        
        # æ­¥éª¤3: ç­–ç•¥ç”Ÿæˆ
        await update_agent_status(workflow_id, "strategy-generator", "running", 0, "æ­£åœ¨ç”ŸæˆæŠ•èµ„ç­–ç•¥...")
        await asyncio.sleep(2)
        await update_agent_status(workflow_id, "strategy-generator", "completed", 100, "æŠ•èµ„ç­–ç•¥ç”Ÿæˆå®Œæˆ")
        
        # æ­¥éª¤4: é£é™©è¯„ä¼°
        await update_agent_status(workflow_id, "risk-assessor", "running", 0, "æ­£åœ¨è¯„ä¼°é£é™©...")
        await asyncio.sleep(1.5)
        await update_agent_status(workflow_id, "risk-assessor", "completed", 100, "é£é™©è¯„ä¼°å®Œæˆ")
        
        # æ­¥éª¤5: æ‰§è¡Œ
        await update_agent_status(workflow_id, "executor", "running", 0, "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        await asyncio.sleep(1)
        await update_agent_status(workflow_id, "executor", "completed", 100, "æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # å®Œæˆå·¥ä½œæµ
        workflow["status"] = "completed"
        workflow["end_time"] = datetime.now().isoformat()
        workflow["results"] = analysis_result
        
    except Exception as e:
        print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        workflow = workflow_storage.get(workflow_id)
        if workflow:
            workflow["status"] = "error"
            workflow["message"] = str(e)

async def update_agent_status(workflow_id: str, agent_id: str, status: str, progress: int, message: str):
    """æ›´æ–°æ™ºèƒ½ä½“çŠ¶æ€"""
    workflow = workflow_storage.get(workflow_id)
    if workflow:
        agents = workflow["agents"]
        for agent in agents:
            if agent["id"] == agent_id:
                agent["status"] = status
                agent["progress"] = progress
                agent["message"] = message
                if status == "running":
                    agent["startTime"] = datetime.now().isoformat()
                elif status in ["completed", "error"]:
                    agent["endTime"] = datetime.now().isoformat()
                break

async def perform_analysis(query: str):
    """æ‰§è¡Œåˆ†æ"""
    try:
        # è°ƒç”¨ç°æœ‰çš„åˆ†ææœåŠ¡
        result = stock_recommender.recommend_stocks_by_query(query)
        
        return {
            "marketAnalysis": {
                "trend": "éœ‡è¡ä¸Šè¡Œ",
                "sentiment": "è°¨æ…ä¹è§‚",
                "volatility": "ä¸­ç­‰",
                "keyFactors": ["æ”¿ç­–æ”¯æŒ", "ä¸šç»©æ”¹å–„", "èµ„é‡‘æµå…¥"]
            },
            "stockRecommendations": result.get("recommendations", []),
            "keywords": result.get("extracted_keywords", []),
            "summary": f"åŸºäºæŸ¥è¯¢'{query}'çš„åˆ†æç»“æœ"
        }
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        return {
            "marketAnalysis": {
                "trend": "æ•°æ®è·å–ä¸­",
                "sentiment": "ä¸­æ€§",
                "volatility": "æœªçŸ¥",
                "keyFactors": []
            },
            "stockRecommendations": [],
            "summary": "åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        }

async def perform_intelligent_analysis(message: str, context: Dict[str, Any] = None):
    """æ‰§è¡Œæ™ºèƒ½åˆ†æï¼ˆä¸“é—¨ç”¨äºAIåˆ†æçš„æ ¸å¿ƒå‡½æ•°ï¼‰"""
    try:
        print(f"å¼€å§‹æ™ºèƒ½åˆ†æ: {message}")
        
        # å¤„ç†ä¸Šä¸‹æ–‡ä¿¡æ¯
        enhanced_message = message
        if context:
            enhanced_message = enhance_message_with_context(message, context)
            print(f"å¢å¼ºåçš„æ¶ˆæ¯: {enhanced_message}")
        
        # ä½¿ç”¨ç°æœ‰çš„è‚¡ç¥¨æ¨èæœåŠ¡è¿›è¡Œåˆ†æ
        analysis_result = stock_recommender.recommend_stocks_by_query(enhanced_message)
        
        # å¦‚æœæœ‰æ¨èç»“æœï¼Œç”Ÿæˆè¯¦ç»†å›å¤
        if analysis_result and analysis_result.get("recommendations"):
            recommendations = analysis_result["recommendations"][:5]  # å–å‰5ä¸ªæ¨è
            keywords = analysis_result.get("keywords", [])
            
            # ç”Ÿæˆæ™ºèƒ½å›å¤
            response = f"åŸºäºAIåˆ†æï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†ä»¥ä¸‹æŠ•èµ„å»ºè®®ï¼š\n\n"
            
            if keywords:
                response += f"ğŸ” **å…³é”®åˆ†æè¦ç´ **\n"
                for keyword in keywords[:3]:
                    response += f"â€¢ {keyword.get('text', keyword)}\n"
                response += "\n"
            
            response += f"ğŸ“ˆ **æ¨èè‚¡ç¥¨** ({len(recommendations)}åª)\n"
            for i, stock in enumerate(recommendations, 1):
                response += f"**{i}. {stock.get('symbol', 'N/A')} - {stock.get('name', 'æœªçŸ¥')}**\n"
                response += f"â€¢ åŒ¹é…åº¦: {stock.get('matchScore', stock.get('score', 85))}åˆ†\n"
                response += f"â€¢ æ¨èç†ç”±: {stock.get('reason', 'åŸºäºAIåˆ†ææ¨è')}\n"
                if stock.get('sector'):
                    response += f"â€¢ æ‰€å±è¡Œä¸š: {stock.get('sector')}\n"
                response += "\n"
            
            response += "ğŸ’¡ **æŠ•èµ„å»ºè®®**\n"
            response += "â€¢ å»ºè®®åˆ†æ•£æŠ•èµ„ï¼Œæ§åˆ¶å•ä¸€æ ‡çš„æƒé‡\n"
            response += "â€¢ å¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€å’Œæ”¿ç­–å˜åŒ–\n"
            response += "â€¢ è®¾ç½®åˆç†çš„æ­¢æŸç‚¹ä½\n\n"
            response += "éœ€è¦æˆ‘è¯¦ç»†åˆ†ææŸåªå…·ä½“è‚¡ç¥¨å—ï¼Ÿ"
            
            return {
                "response": clean_text(response),
                "analysis": analysis_result,
                "recommendations": recommendations
            }
        else:
            # å¦‚æœæ²¡æœ‰å…·ä½“æ¨èï¼Œæä¾›é€šç”¨åˆ†æ
            response = await generate_general_analysis_response(message)
            return {
                "response": clean_text(response),
                "analysis": {"type": "general", "query": message},
                "recommendations": []
            }
            
    except Exception as e:
        print(f"æ™ºèƒ½åˆ†æå¤±è´¥: {e}")
        return {
            "response": "æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚æˆ‘ä¼šå°½å¿«ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŠ•èµ„åˆ†æã€‚",
            "analysis": {"error": str(e)},
            "recommendations": []
        }

async def generate_general_analysis_response(message: str):
    """ç”Ÿæˆé€šç”¨åˆ†æå›å¤"""
    try:
        # ä½¿ç”¨Qwenåˆ†æå™¨è¿›è¡Œå…³é”®è¯åˆ†æ
        keywords_result = await qwen_analyzer.analyze_keywords(message)
        
        if keywords_result and keywords_result.get("keywords"):
            keywords = keywords_result["keywords"]
            
            response = f"åŸºäºæ‚¨çš„æŸ¥è¯¢ã€Œ{message}ã€ï¼Œæˆ‘è¿›è¡Œäº†ä»¥ä¸‹åˆ†æï¼š\n\n"
            response += "ğŸ” **å…³é”®æŠ•èµ„è¦ç´ è¯†åˆ«**\n"
            
            for keyword in keywords[:5]:
                if isinstance(keyword, dict):
                    text = keyword.get('text', keyword.get('keyword', ''))
                    confidence = keyword.get('confidence', 0)
                    if confidence > 0:
                        response += f"â€¢ {text} (ç›¸å…³åº¦: {int(confidence * 100)}%)\n"
                    else:
                        response += f"â€¢ {text}\n"
                else:
                    response += f"â€¢ {keyword}\n"
            
            response += "\nğŸ“Š **æŠ•èµ„å»ºè®®æ–¹å‘**\n"
            
            # æ ¹æ®å…³é”®è¯æä¾›ç›¸åº”å»ºè®®
            keyword_texts = [k.get('text', k) if isinstance(k, dict) else str(k) for k in keywords]
            keyword_str = ' '.join(keyword_texts).lower()
            
            if any(word in keyword_str for word in ['ç§‘æŠ€', 'æŠ€æœ¯', 'äº’è”ç½‘', 'è½¯ä»¶']):
                response += "â€¢ å…³æ³¨ç§‘æŠ€æ¿å—çš„æŠ•èµ„æœºä¼š\nâ€¢ é‡ç‚¹å…³æ³¨åˆ›æ–°èƒ½åŠ›å¼ºçš„å…¬å¸\nâ€¢ æ³¨æ„ä¼°å€¼åˆç†æ€§\n"
            elif any(word in keyword_str for word in ['é‡‘è', 'é“¶è¡Œ', 'ä¿é™©']):
                response += "â€¢ å…³æ³¨é‡‘èæ¿å—çš„ä»·å€¼æŠ•èµ„æœºä¼š\nâ€¢ é‡ç‚¹å…³æ³¨åˆ†çº¢ç¨³å®šçš„ä¼˜è´¨é“¶è¡Œè‚¡\nâ€¢ æ³¨æ„æ”¿ç­–å½±å“\n"
            elif any(word in keyword_str for word in ['åŒ»è¯', 'åŒ»ç–—', 'ç”Ÿç‰©']):
                response += "â€¢ å…³æ³¨åŒ»è¯æ¿å—çš„é•¿æœŸæŠ•èµ„ä»·å€¼\nâ€¢ é‡ç‚¹å…³æ³¨åˆ›æ–°è¯å’ŒåŒ»ç–—å™¨æ¢°\nâ€¢ æ³¨æ„æ”¿ç­–å’Œå®¡æ‰¹é£é™©\n"
            else:
                response += "â€¢ å»ºè®®å¤šå…ƒåŒ–æŠ•èµ„ï¼Œåˆ†æ•£é£é™©\nâ€¢ å…³æ³¨åŸºæœ¬é¢è‰¯å¥½çš„ä¼˜è´¨å…¬å¸\nâ€¢ ç»“åˆæŠ€æœ¯åˆ†æç¡®å®šä¹°å…¥æ—¶æœº\n"
            
            response += "\nğŸ’¡ å¦‚éœ€å…·ä½“çš„è‚¡ç¥¨æ¨èï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨çš„é£é™©åå¥½å’ŒæŠ•èµ„æœŸé™ã€‚"
            
            return clean_text(response)
        else:
            return clean_text(generate_fallback_response(message))
            
    except Exception as e:
        print(f"é€šç”¨åˆ†æå¤±è´¥: {e}")
        return clean_text(generate_fallback_response(message))

def generate_fallback_response(message: str):
    """ç”Ÿæˆé™çº§å›å¤"""
    response = f"""æˆ‘ç†è§£æ‚¨å…³äºã€Œ{message}ã€çš„å’¨è¯¢ã€‚

ğŸ¯ **æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä»¥ä¸‹æœåŠ¡ï¼š**
â€¢ ä¸ªè‚¡åˆ†æå’Œæ¨è
â€¢ è¡Œä¸šæ¿å—æŠ•èµ„å»ºè®®  
â€¢ æŠ•èµ„ç­–ç•¥åˆ¶å®š
â€¢ é£é™©è¯„ä¼°å’Œç®¡ç†
â€¢ å¸‚åœºè¶‹åŠ¿åˆ†æ

ğŸ’¡ **å»ºè®®æ‚¨å¯ä»¥è¿™æ ·æé—®ï¼š**
â€¢ "æ¨èä¸€äº›ç§‘æŠ€è‚¡"
â€¢ "åˆ†æä¸€ä¸‹é“¶è¡Œæ¿å—"
â€¢ "æˆ‘æƒ³è¦ä½é£é™©çš„æŠ•èµ„å»ºè®®"
â€¢ "å¸®æˆ‘åˆ†æ000001è¿™åªè‚¡ç¥¨"

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŠ•èµ„åˆ†æï¼"""
    return clean_text(response)

async def generate_ai_response(message: str, context: Dict[str, Any] = None):
    """ç”ŸæˆAIå›å¤ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
    try:
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„AIå¯¹è¯é€»è¾‘
        if "å·¥ä½œæµç»“æœ" in message:
            return "åŸºäºå·¥ä½œæµåˆ†æç»“æœï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†è¯¦ç»†çš„æŠ•èµ„å»ºè®®æŠ¥å‘Šã€‚"
        else:
            return f"æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ï¼š{message}ã€‚è®©æˆ‘ä¸ºæ‚¨åˆ†æä¸€ä¸‹ç›¸å…³çš„æŠ•èµ„æœºä¼šã€‚"
    except Exception as e:
        return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"

async def generate_investment_strategies(request: StrategyGenerationRequest):
    """ç”ŸæˆæŠ•èµ„ç­–ç•¥"""
    strategies = []
    
    if request.riskTolerance == "low":
        strategies.append({
            "name": "ç¨³å¥ä»·å€¼æŠ•èµ„ç­–ç•¥",
            "description": "ä¸“æ³¨äºä½ä¼°å€¼ã€é«˜åˆ†çº¢çš„è“ç­¹è‚¡",
            "expectedReturn": "8-12%",
            "riskLevel": "low",
            "stocks": ["000001", "600036", "000002"],
            "allocation": {"000001": 0.4, "600036": 0.3, "000002": 0.3}
        })
    elif request.riskTolerance == "high":
        strategies.append({
            "name": "æˆé•¿è‚¡æŠ•èµ„ç­–ç•¥",
            "description": "å…³æ³¨é«˜æˆé•¿æ€§çš„ç§‘æŠ€å’Œæ–°å…´è¡Œä¸šè‚¡ç¥¨",
            "expectedReturn": "15-25%",
            "riskLevel": "high",
            "stocks": ["000858", "002415", "300059"],
            "allocation": {"000858": 0.4, "002415": 0.3, "300059": 0.3}
        })
    else:
        strategies.append({
            "name": "å‡è¡¡æŠ•èµ„ç­–ç•¥",
            "description": "å¹³è¡¡æˆé•¿æ€§å’Œç¨³å®šæ€§",
            "expectedReturn": "10-18%",
            "riskLevel": "medium",
            "stocks": ["000001", "000858", "600036"],
            "allocation": {"000001": 0.3, "000858": 0.4, "600036": 0.3}
        })
    
    return strategies

def enhance_message_with_context(message: str, context: Dict[str, Any]) -> str:
    """ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯å¢å¼ºæ¶ˆæ¯"""
    enhanced_message = message
    
    # å¤„ç†å¯¹è¯å†å²
    if context.get("conversationHistory"):
        conversation_history = context["conversationHistory"]
        
        # æå–ä¹‹å‰çš„ç”¨æˆ·æŸ¥è¯¢
        previous_queries = [
            msg["content"] for msg in conversation_history 
            if msg.get("type") == "user" and msg.get("content") != message
        ]
        
        if previous_queries:
            # å¦‚æœå½“å‰æ¶ˆæ¯å¾ˆçŸ­æˆ–è€…æ˜¯ç»§ç»­æ€§çš„é—®é¢˜ï¼Œç»“åˆä¹‹å‰çš„æŸ¥è¯¢
            if len(message) < 10 or any(word in message.lower() for word in ['ç»§ç»­', 'è¿˜æœ‰', 'å…¶ä»–', 'è¯¦ç»†', 'æ›´å¤š']):
                last_query = previous_queries[-1] if previous_queries else ""
                enhanced_message = f"åŸºäºä¹‹å‰çš„æŸ¥è¯¢'{last_query}'ï¼Œç”¨æˆ·ç°åœ¨é—®ï¼š{message}"
                print(f"æ£€æµ‹åˆ°ç»§ç»­æ€§å¯¹è¯ï¼Œå¢å¼ºæ¶ˆæ¯: {enhanced_message}")
            
            # å¦‚æœæ˜¯ç›¸å…³çš„æŠ•èµ„é—®é¢˜ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡
            elif any(word in message.lower() for word in ['æ¨è', 'åˆ†æ', 'å»ºè®®', 'è‚¡ç¥¨', 'æŠ•èµ„']):
                recent_topics = extract_topics_from_queries(previous_queries)
                if recent_topics:
                    enhanced_message = f"{message}ã€‚ä¸Šä¸‹æ–‡ï¼šç”¨æˆ·ä¹‹å‰è¯¢é—®è¿‡{', '.join(recent_topics[:2])}ç›¸å…³é—®é¢˜"
                    print(f"æ·»åŠ æŠ•èµ„è¯é¢˜ä¸Šä¸‹æ–‡: {enhanced_message}")
    
    # å¤„ç†ä¹‹å‰çš„æŸ¥è¯¢æ‘˜è¦
    if context.get("previousQueries"):
        previous_queries = context["previousQueries"]
        if previous_queries and len(message) < 15:
            # å¯¹äºç®€çŸ­çš„æ¶ˆæ¯ï¼Œæ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
            enhanced_message = f"{message}ã€‚å‚è€ƒä¹‹å‰çš„æŸ¥è¯¢ï¼š{previous_queries[-1]}"
            print(f"ä¸ºç®€çŸ­æ¶ˆæ¯æ·»åŠ æŸ¥è¯¢ä¸Šä¸‹æ–‡: {enhanced_message}")
    
    # å¤„ç†ç”¨æˆ·åå¥½
    if context.get("userPreferences"):
        preferences = context["userPreferences"]
        risk_tolerance = preferences.get("riskTolerance", "medium")
        trading_experience = preferences.get("tradingExperience", "intermediate")
        
        # ä¸ºæŠ•èµ„ç›¸å…³æŸ¥è¯¢æ·»åŠ ç”¨æˆ·åå¥½ä¿¡æ¯
        if any(word in message.lower() for word in ['æ¨è', 'å»ºè®®', 'é€‰æ‹©', 'æŠ•èµ„']):
            enhanced_message = f"{enhanced_message}ã€‚ç”¨æˆ·é£é™©åå¥½ï¼š{risk_tolerance}ï¼Œäº¤æ˜“ç»éªŒï¼š{trading_experience}"
            print(f"æ·»åŠ ç”¨æˆ·åå¥½ä¸Šä¸‹æ–‡: é£é™©åå¥½={risk_tolerance}, ç»éªŒ={trading_experience}")
    
    return enhanced_message

def extract_topics_from_queries(queries: List[str]) -> List[str]:
    """ä»æŸ¥è¯¢ä¸­æå–æŠ•èµ„è¯é¢˜"""
    topics = []
    
    # å¸¸è§çš„æŠ•èµ„è¯é¢˜å…³é”®è¯
    topic_keywords = {
        "ç§‘æŠ€è‚¡": ["ç§‘æŠ€", "æŠ€æœ¯", "äº’è”ç½‘", "è½¯ä»¶", "èŠ¯ç‰‡", "AI", "äººå·¥æ™ºèƒ½"],
        "é‡‘èè‚¡": ["é“¶è¡Œ", "ä¿é™©", "è¯åˆ¸", "é‡‘è"],
        "åŒ»è¯è‚¡": ["åŒ»è¯", "åŒ»ç–—", "ç”Ÿç‰©", "åˆ¶è¯"],
        "æ–°èƒ½æº": ["æ–°èƒ½æº", "ç”µåŠ¨è½¦", "å…‰ä¼", "é£ç”µ", "é”‚ç”µæ± "],
        "æ¶ˆè´¹è‚¡": ["æ¶ˆè´¹", "é›¶å”®", "é£Ÿå“", "é¥®æ–™"],
        "æˆ¿åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "æˆ¿äº§"],
        "ä»·å€¼æŠ•èµ„": ["ä»·å€¼", "ä½ä¼°å€¼", "åˆ†çº¢", "è“ç­¹"],
        "æˆé•¿æŠ•èµ„": ["æˆé•¿", "é«˜æˆé•¿", "å¢é•¿"],
        "ä½é£é™©æŠ•èµ„": ["ä½é£é™©", "ç¨³å¥", "ä¿å®ˆ", "å®‰å…¨"]
    }
    
    for query in queries:
        query_lower = query.lower()
        for topic, keywords in topic_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                if topic not in topics:
                    topics.append(topic)
                break
    
    return topics

async def generate_market_insights():
    """ç”Ÿæˆå¸‚åœºæ´å¯Ÿ"""
    return {
        "insights": [
            {
                "title": "ç§‘æŠ€è‚¡æŠ•èµ„æœºä¼š",
                "content": "å½“å‰ç§‘æŠ€è‚¡ä¼°å€¼åˆç†ï¼Œæ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§",
                "type": "bullish",
                "confidence": 0.75,
                "timestamp": datetime.now().isoformat()
            },
            {
                "title": "æ–°èƒ½æºæ¿å—å‰æ™¯",
                "content": "æ–°èƒ½æºæ”¿ç­–æŒç»­åˆ©å¥½ï¼Œé•¿æœŸæŠ•èµ„ä»·å€¼æ˜¾è‘—",
                "type": "bullish",
                "confidence": 0.8,
                "timestamp": datetime.now().isoformat()
            },
            {
                "title": "é‡‘èè‚¡ç¨³å¥è¡¨ç°",
                "content": "é“¶è¡Œè‚¡ä¼°å€¼åä½ï¼Œåˆ†çº¢æ”¶ç›Šç¨³å®š",
                "type": "neutral",
                "confidence": 0.65,
                "timestamp": datetime.now().isoformat()
            }
        ],
        "marketSummary": {
            "trend": "éœ‡è¡ä¸Šè¡Œ",
            "sentiment": "è°¨æ…ä¹è§‚",
            "volatility": "ä¸­ç­‰",
            "keyFactors": ["æ”¿ç­–æ”¯æŒ", "ä¸šç»©æ”¹å–„", "èµ„é‡‘æµå…¥", "ä¼°å€¼ä¿®å¤"]
        }
    }

# æ–°å¢å·¥ä½œæµç”»å¸ƒç›¸å…³è¾…åŠ©å‡½æ•°

def initialize_node_statuses(nodes: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€"""
    node_statuses = {}
    
    for node in nodes:
        node_statuses[node["id"]] = {
            "id": node["id"],
            "name": node["name"],
            "type": node["type"],
            "status": "idle",
            "progress": 0,
            "start_time": None,
            "end_time": None,
            "result": None,
            "error": None
        }
    
    return node_statuses

def validate_workflow_definition_internal(workflow_definition: Dict[str, Any]) -> Dict[str, Any]:
    """å†…éƒ¨å·¥ä½œæµå®šä¹‰éªŒè¯å‡½æ•°"""
    errors = []
    warnings = []
    
    try:
        # åŸºæœ¬éªŒè¯
        if not workflow_definition.get("name"):
            errors.append("å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º")
        
        nodes = workflow_definition.get("nodes", [])
        connections = workflow_definition.get("connections", [])
        
        if not nodes:
            errors.append("å·¥ä½œæµå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹")
        
        # èŠ‚ç‚¹éªŒè¯
        node_ids = set()
        for node in nodes:
            if not node.get("id"):
                errors.append("èŠ‚ç‚¹å¿…é¡»æœ‰å”¯ä¸€ID")
                continue
            
            if node["id"] in node_ids:
                errors.append(f"èŠ‚ç‚¹IDé‡å¤: {node['id']}")
            node_ids.add(node["id"])
            
            if not node.get("type"):
                errors.append(f"èŠ‚ç‚¹{node['id']}ç¼ºå°‘ç±»å‹å®šä¹‰")
            
            if not node.get("name"):
                errors.append(f"èŠ‚ç‚¹{node['id']}ç¼ºå°‘åç§°")
        
        # è¿æ¥éªŒè¯
        for connection in connections:
            if not connection.get("sourceId") or not connection.get("targetId"):
                errors.append("è¿æ¥å¿…é¡»æŒ‡å®šæºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹")
                continue
            
            if connection["sourceId"] not in node_ids:
                errors.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„æºèŠ‚ç‚¹: {connection['sourceId']}")
            
            if connection["targetId"] not in node_ids:
                errors.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„ç›®æ ‡èŠ‚ç‚¹: {connection['targetId']}")
        
        # å¾ªç¯ä¾èµ–æ£€æŸ¥
        if has_cyclic_dependency(nodes, connections):
            errors.append("å·¥ä½œæµå­˜åœ¨å¾ªç¯ä¾èµ–")
        
        # è­¦å‘Šæ£€æŸ¥
        if len(nodes) > 10:
            warnings.append("å·¥ä½œæµèŠ‚ç‚¹æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½å½±å“æ‰§è¡Œæ€§èƒ½")
        
        isolated_nodes = find_isolated_nodes(nodes, connections)
        if isolated_nodes:
            warnings.append(f"å‘ç°å­¤ç«‹èŠ‚ç‚¹: {', '.join(isolated_nodes)}")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }
        
    except Exception as e:
        return {
            "valid": False,
            "errors": [f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"],
            "warnings": []
        }

def has_cyclic_dependency(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> bool:
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯ä¾èµ–"""
    try:
        # æ„å»ºé‚»æ¥è¡¨
        graph = {}
        for node in nodes:
            graph[node["id"]] = []
        
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id and target_id and source_id in graph:
                graph[source_id].append(target_id)
        
        # DFSæ£€æŸ¥å¾ªç¯
        visited = set()
        recursion_stack = set()
        
        def has_cycle(node_id: str) -> bool:
            visited.add(node_id)
            recursion_stack.add(node_id)
            
            for neighbor in graph.get(node_id, []):
                if neighbor not in visited:
                    if has_cycle(neighbor):
                        return True
                elif neighbor in recursion_stack:
                    return True
            
            recursion_stack.remove(node_id)
            return False
        
        for node_id in graph:
            if node_id not in visited:
                if has_cycle(node_id):
                    return True
        
        return False
        
    except Exception as e:
        print(f"å¾ªç¯ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}")
        return False

def find_isolated_nodes(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> List[str]:
    """æŸ¥æ‰¾å­¤ç«‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰è¿æ¥çš„èŠ‚ç‚¹ï¼‰"""
    try:
        connected_nodes = set()
        
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id:
                connected_nodes.add(source_id)
            if target_id:
                connected_nodes.add(target_id)
        
        isolated_nodes = []
        for node in nodes:
            if node["id"] not in connected_nodes:
                isolated_nodes.append(node["id"])
        
        return isolated_nodes
        
    except Exception as e:
        print(f"æŸ¥æ‰¾å­¤ç«‹èŠ‚ç‚¹å¤±è´¥: {e}")
        return []

async def execute_workflow_definition(execution_id: str, workflow_definition: Dict[str, Any], context: Dict[str, Any]):
    """æ‰§è¡Œå·¥ä½œæµå®šä¹‰"""
    try:
        execution = workflow_execution_storage[execution_id]
        nodes = workflow_definition.get("nodes", [])
        connections = workflow_definition.get("connections", [])
        
        # è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œé¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰
        execution_order = calculate_execution_order(nodes, connections)
        
        print(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµå®šä¹‰: {execution_id}, èŠ‚ç‚¹æ‰§è¡Œé¡ºåº: {execution_order}")
        
        # æŒ‰é¡ºåºæ‰§è¡ŒèŠ‚ç‚¹
        for i, node_id in enumerate(execution_order):
            node = next((n for n in nodes if n["id"] == node_id), None)
            if not node:
                continue
            
            # æ›´æ–°å½“å‰æ‰§è¡ŒèŠ‚ç‚¹
            execution["current_node"] = node_id
            execution["progress"] = int((i / len(execution_order)) * 90)  # ç•™10%ç»™æœ€ç»ˆå¤„ç†
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            await update_node_status(execution_id, node_id, "running", 0, f"æ­£åœ¨æ‰§è¡Œ{node['name']}...")
            
            # æ‰§è¡ŒèŠ‚ç‚¹
            node_result = await execute_single_node(node, execution, context)
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
            if node_result.get("success", True):
                await update_node_status(execution_id, node_id, "completed", 100, f"{node['name']}æ‰§è¡Œå®Œæˆ")
                execution["node_statuses"][node_id]["result"] = node_result
            else:
                await update_node_status(execution_id, node_id, "error", 0, f"{node['name']}æ‰§è¡Œå¤±è´¥: {node_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                execution["node_statuses"][node_id]["error"] = node_result.get("error")
                # å¦‚æœèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢æ•´ä¸ªå·¥ä½œæµ
                execution["status"] = "error"
                execution["message"] = f"èŠ‚ç‚¹{node['name']}æ‰§è¡Œå¤±è´¥"
                return
            
            # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            await asyncio.sleep(1)
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        final_results = await generate_workflow_final_results(execution_id, workflow_definition, execution)
        
        # å®Œæˆå·¥ä½œæµæ‰§è¡Œ
        execution["status"] = "completed"
        execution["progress"] = 100
        execution["end_time"] = datetime.now().isoformat()
        execution["results"] = final_results
        execution["message"] = "å·¥ä½œæµæ‰§è¡Œå®Œæˆ"
        
        print(f"å·¥ä½œæµå®šä¹‰æ‰§è¡Œå®Œæˆ: {execution_id}")
        
    except Exception as e:
        print(f"å·¥ä½œæµå®šä¹‰æ‰§è¡Œå¤±è´¥: {execution_id}, é”™è¯¯: {e}")
        execution = workflow_execution_storage.get(execution_id)
        if execution:
            execution["status"] = "error"
            execution["message"] = str(e)
            execution["end_time"] = datetime.now().isoformat()

def calculate_execution_order(nodes: List[Dict[str, Any]], connections: List[Dict[str, Any]]) -> List[str]:
    """è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œé¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰"""
    try:
        # æ„å»ºä¾èµ–å›¾
        in_degree = {}
        graph = {}
        
        # åˆå§‹åŒ–
        for node in nodes:
            node_id = node["id"]
            in_degree[node_id] = 0
            graph[node_id] = []
        
        # æ„å»ºå›¾å’Œè®¡ç®—å…¥åº¦
        for connection in connections:
            source_id = connection.get("sourceId")
            target_id = connection.get("targetId")
            if source_id and target_id:
                graph[source_id].append(target_id)
                in_degree[target_id] += 1
        
        # æ‹“æ‰‘æ’åº
        queue = [node_id for node_id, degree in in_degree.items() if degree == 0]
        result = []
        
        while queue:
            current = queue.pop(0)
            result.append(current)
            
            for neighbor in graph[current]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        # å¦‚æœç»“æœé•¿åº¦ä¸ç­‰äºèŠ‚ç‚¹æ•°é‡ï¼Œè¯´æ˜å­˜åœ¨å¾ªç¯ä¾èµ–
        if len(result) != len(nodes):
            print("è­¦å‘Š: æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œä½¿ç”¨èŠ‚ç‚¹å®šä¹‰é¡ºåº")
            return [node["id"] for node in nodes]
        
        return result
        
    except Exception as e:
        print(f"è®¡ç®—æ‰§è¡Œé¡ºåºå¤±è´¥: {e}")
        # é™çº§æ–¹æ¡ˆï¼šæŒ‰èŠ‚ç‚¹å®šä¹‰é¡ºåºæ‰§è¡Œ
        return [node["id"] for node in nodes]

async def update_node_status(execution_id: str, node_id: str, status: str, progress: int, message: str):
    """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€"""
    execution = workflow_execution_storage.get(execution_id)
    if execution and node_id in execution["node_statuses"]:
        node_status = execution["node_statuses"][node_id]
        node_status["status"] = status
        node_status["progress"] = progress
        node_status["message"] = message
        
        if status == "running":
            node_status["start_time"] = datetime.now().isoformat()
        elif status in ["completed", "error"]:
            node_status["end_time"] = datetime.now().isoformat()

async def execute_single_node(node: Dict[str, Any], execution: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
    try:
        node_type = node.get("type")
        node_config = node.get("config", {})
        
        print(f"æ‰§è¡ŒèŠ‚ç‚¹: {node['id']} ({node_type})")
        
        if node_type == "data":
            return await execute_data_node(node, node_config, context)
        elif node_type == "analysis":
            return await execute_analysis_node(node, node_config, context)
        elif node_type == "strategy":
            return await execute_strategy_node(node, node_config, context)
        elif node_type == "risk":
            return await execute_risk_node(node, node_config, context)
        elif node_type == "output":
            return await execute_output_node(node, node_config, context)
        else:
            return await execute_custom_node(node, node_config, context)
            
    except Exception as e:
        print(f"æ‰§è¡ŒèŠ‚ç‚¹å¤±è´¥: {node['id']}, é”™è¯¯: {e}")
        return {
            "success": False,
            "error": str(e),
            "node_id": node["id"]
        }

async def execute_data_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæ•°æ®æ”¶é›†èŠ‚ç‚¹"""
    try:
        data_sources = config.get("dataSources", ["stock_price"])
        time_range = config.get("timeRange", "1y")
        symbols = config.get("symbols", [])
        
        # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†
        await asyncio.sleep(1)
        
        collected_data = {
            "sources": data_sources,
            "timeRange": time_range,
            "symbols": symbols,
            "recordCount": len(symbols) * 252 if symbols else 1000,
            "collectedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": collected_data,
            "message": f"æˆåŠŸæ”¶é›†{len(data_sources)}ä¸ªæ•°æ®æºçš„æ•°æ®"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_analysis_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œåˆ†æèŠ‚ç‚¹"""
    try:
        indicators = config.get("indicators", ["RSI", "MACD"])
        period = config.get("period", 20)
        
        # æ¨¡æ‹Ÿåˆ†æå¤„ç†
        await asyncio.sleep(1.5)
        
        analysis_result = {
            "indicators": indicators,
            "period": period,
            "signals": {
                "bullish": len(indicators) * 2,
                "bearish": len(indicators),
                "neutral": len(indicators) * 3
            },
            "confidence": 0.75,
            "analyzedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": analysis_result,
            "message": f"å®Œæˆ{len(indicators)}ä¸ªæŒ‡æ ‡çš„åˆ†æ"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_strategy_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œç­–ç•¥ç”ŸæˆèŠ‚ç‚¹"""
    try:
        strategy_type = config.get("strategyType", "momentum")
        risk_level = config.get("riskLevel", "medium")
        time_horizon = config.get("timeHorizon", "medium_term")
        
        # æ¨¡æ‹Ÿç­–ç•¥ç”Ÿæˆ
        await asyncio.sleep(2)
        
        strategy_result = {
            "strategyType": strategy_type,
            "riskLevel": risk_level,
            "timeHorizon": time_horizon,
            "recommendations": [
                {
                    "action": "buy",
                    "symbol": "AAPL",
                    "weight": 0.3,
                    "confidence": 0.8
                },
                {
                    "action": "hold",
                    "symbol": "MSFT",
                    "weight": 0.4,
                    "confidence": 0.7
                }
            ],
            "expectedReturn": "12-18%",
            "generatedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": strategy_result,
            "message": f"ç”Ÿæˆ{strategy_type}ç­–ç•¥ï¼ŒåŒ…å«{len(strategy_result['recommendations'])}ä¸ªå»ºè®®"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_risk_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œé£é™©è¯„ä¼°èŠ‚ç‚¹"""
    try:
        risk_metrics = config.get("riskMetrics", ["VaR", "Sharpe"])
        backtest_period = config.get("backtestPeriod", "2y")
        
        # æ¨¡æ‹Ÿé£é™©è¯„ä¼°
        await asyncio.sleep(1.5)
        
        risk_result = {
            "metrics": risk_metrics,
            "backtestPeriod": backtest_period,
            "riskAssessment": {
                "VaR": 0.05,
                "Sharpe": 1.2,
                "MaxDrawdown": 0.15,
                "Volatility": 0.18
            },
            "riskLevel": "medium",
            "assessedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": risk_result,
            "message": f"å®Œæˆ{len(risk_metrics)}ä¸ªé£é™©æŒ‡æ ‡çš„è¯„ä¼°"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_output_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œè¾“å‡ºèŠ‚ç‚¹"""
    try:
        output_format = config.get("outputFormat", "detailed_report")
        include_charts = config.get("includeCharts", True)
        
        # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
        await asyncio.sleep(1)
        
        output_result = {
            "format": output_format,
            "includeCharts": include_charts,
            "report": {
                "title": "AIå·¥ä½œæµåˆ†ææŠ¥å‘Š",
                "summary": "åŸºäºå¤šèŠ‚ç‚¹åˆ†æç”Ÿæˆçš„æŠ•èµ„å»ºè®®æŠ¥å‘Š",
                "sections": ["å¸‚åœºåˆ†æ", "ç­–ç•¥å»ºè®®", "é£é™©è¯„ä¼°", "æ‰§è¡Œå»ºè®®"],
                "generatedAt": datetime.now().isoformat()
            }
        }
        
        return {
            "success": True,
            "data": output_result,
            "message": f"ç”Ÿæˆ{output_format}æ ¼å¼çš„åˆ†ææŠ¥å‘Š"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def execute_custom_node(node: Dict[str, Any], config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œè‡ªå®šä¹‰èŠ‚ç‚¹"""
    try:
        # æ¨¡æ‹Ÿè‡ªå®šä¹‰èŠ‚ç‚¹å¤„ç†
        await asyncio.sleep(1)
        
        custom_result = {
            "nodeId": node["id"],
            "nodeName": node["name"],
            "config": config,
            "processedAt": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "data": custom_result,
            "message": f"å®Œæˆè‡ªå®šä¹‰èŠ‚ç‚¹{node['name']}çš„å¤„ç†"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def generate_workflow_final_results(execution_id: str, workflow_definition: Dict[str, Any], execution: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆå·¥ä½œæµæœ€ç»ˆç»“æœ"""
    try:
        workflow_name = workflow_definition.get("name", "æœªå‘½åå·¥ä½œæµ")
        nodes = workflow_definition.get("nodes", [])
        node_statuses = execution.get("node_statuses", {})
        
        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„ç»“æœ
        node_results = {}
        for node_id, status in node_statuses.items():
            if status.get("result"):
                node_results[node_id] = status["result"]
        
        # ç”Ÿæˆç»¼åˆåˆ†æç»“æœ
        final_results = {
            "workflowName": workflow_name,
            "executionId": execution_id,
            "executionSummary": {
                "totalNodes": len(nodes),
                "completedNodes": len([s for s in node_statuses.values() if s["status"] == "completed"]),
                "failedNodes": len([s for s in node_statuses.values() if s["status"] == "error"]),
                "executionTime": calculate_execution_time(execution)
            },
            "nodeResults": node_results,
            "recommendations": extract_recommendations_from_results(node_results),
            "riskAssessment": extract_risk_assessment_from_results(node_results),
            "marketInsights": extract_market_insights_from_results(node_results),
            "generatedAt": datetime.now().isoformat()
        }
        
        return final_results
        
    except Exception as e:
        print(f"ç”Ÿæˆæœ€ç»ˆç»“æœå¤±è´¥: {e}")
        return {
            "workflowName": workflow_definition.get("name", "æœªå‘½åå·¥ä½œæµ"),
            "executionId": execution_id,
            "error": str(e),
            "generatedAt": datetime.now().isoformat()
        }

def calculate_execution_time(execution: Dict[str, Any]) -> str:
    """è®¡ç®—æ‰§è¡Œæ—¶é—´"""
    try:
        start_time = execution.get("start_time")
        end_time = execution.get("end_time")
        
        if start_time and end_time:
            start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            duration = end_dt - start_dt
            return f"{duration.total_seconds():.1f}ç§’"
        else:
            return "è®¡ç®—ä¸­..."
            
    except Exception as e:
        print(f"è®¡ç®—æ‰§è¡Œæ—¶é—´å¤±è´¥: {e}")
        return "æœªçŸ¥"

def extract_recommendations_from_results(node_results: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–æ¨è"""
    recommendations = []
    
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»ç­–ç•¥èŠ‚ç‚¹æå–æ¨è
                if "recommendations" in data:
                    recommendations.extend(data["recommendations"])
                
                # ä»åˆ†æèŠ‚ç‚¹æå–ä¿¡å·
                elif "signals" in data:
                    signals = data["signals"]
                    if signals.get("bullish", 0) > signals.get("bearish", 0):
                        recommendations.append({
                            "type": "market_signal",
                            "action": "ç§¯æå…³æ³¨",
                            "reason": "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºç§¯æä¿¡å·",
                            "confidence": data.get("confidence", 0.5)
                        })
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ¨èï¼Œç”Ÿæˆé€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append({
                "type": "general",
                "action": "æŒç»­å…³æ³¨",
                "reason": "åŸºäºå·¥ä½œæµåˆ†æç»“æœ",
                "confidence": 0.6
            })
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªæ¨è
        
    except Exception as e:
        print(f"æå–æ¨èå¤±è´¥: {e}")
        return []

def extract_risk_assessment_from_results(node_results: Dict[str, Any]) -> Dict[str, Any]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–é£é™©è¯„ä¼°"""
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»é£é™©èŠ‚ç‚¹æå–é£é™©è¯„ä¼°
                if "riskAssessment" in data:
                    return {
                        "overallRisk": data.get("riskLevel", "medium"),
                        "metrics": data["riskAssessment"],
                        "assessment": "åŸºäºé‡åŒ–é£é™©æ¨¡å‹è¯„ä¼°"
                    }
        
        # é»˜è®¤é£é™©è¯„ä¼°
        return {
            "overallRisk": "medium",
            "metrics": {"VaR": 0.05, "Sharpe": 1.0},
            "assessment": "åŸºäºå·¥ä½œæµç»¼åˆè¯„ä¼°"
        }
        
    except Exception as e:
        print(f"æå–é£é™©è¯„ä¼°å¤±è´¥: {e}")
        return {"overallRisk": "unknown", "assessment": "é£é™©è¯„ä¼°ä¸å¯ç”¨"}

def extract_market_insights_from_results(node_results: Dict[str, Any]) -> List[str]:
    """ä»èŠ‚ç‚¹ç»“æœä¸­æå–å¸‚åœºæ´å¯Ÿ"""
    insights = []
    
    try:
        for node_id, result in node_results.items():
            if result.get("success") and result.get("data"):
                data = result["data"]
                
                # ä»åˆ†æèŠ‚ç‚¹æå–æ´å¯Ÿ
                if "signals" in data:
                    signals = data["signals"]
                    total_signals = sum(signals.values())
                    if total_signals > 0:
                        bullish_pct = signals.get("bullish", 0) / total_signals * 100
                        if bullish_pct > 50:
                            insights.append(f"æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤º{bullish_pct:.0f}%çš„ç§¯æä¿¡å·")
                        elif bullish_pct < 30:
                            insights.append(f"æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºè°¨æ…ä¿¡å·ï¼Œå»ºè®®è§‚æœ›")
                
                # ä»ç­–ç•¥èŠ‚ç‚¹æå–æ´å¯Ÿ
                elif "expectedReturn" in data:
                    insights.append(f"é¢„æœŸæ”¶ç›Šç‡: {data['expectedReturn']}")
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ´å¯Ÿï¼Œæ·»åŠ é€šç”¨æ´å¯Ÿ
        if not insights:
            insights.append("å¸‚åœºå¤„äºæ­£å¸¸æ³¢åŠ¨èŒƒå›´å†…")
            insights.append("å»ºè®®ä¿æŒå¤šå…ƒåŒ–æŠ•èµ„ç­–ç•¥")
        
        return insights[:3]  # æœ€å¤šè¿”å›3ä¸ªæ´å¯Ÿ
        
    except Exception as e:
        print(f"æå–å¸‚åœºæ´å¯Ÿå¤±è´¥: {e}")
        return ["å¸‚åœºåˆ†ææš‚æ—¶ä¸å¯ç”¨"]